
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《概率论与数理统计》陈希孺，中国科学技术大学出版社">
      
      
      
        <link rel="canonical" href="https://eanyang7.github.io/Probability-and-Statistics/courses/4-Parameter-Estimates/3-Excellence-criterion-of-Point-estimation/">
      
      
        <link rel="prev" href="../2-Moment-estimation-maximum-likelihood-estimation-and-Bayesian-estimation/">
      
      
        <link rel="next" href="../4-Interval-estimation/">
      
      
      <link rel="icon" href="../../../cover.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.2">
    
    
      
        <title>4.3 点估计的优良性准则 - 概率论与数理统计</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-GEDRLMN4ML"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-GEDRLMN4ML",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-GEDRLMN4ML",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#43" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="概率论与数理统计" class="md-header__button md-logo" aria-label="概率论与数理统计" data-md-component="logo">
      
  <img src="../../../cover.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            概率论与数理统计
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              4.3 点估计的优良性准则
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/Probability-and-Statistics" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/Probability-and-Statistics
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
  首页

        </a>
      </li>
    
  

      
        
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      
  
  
    
  
  
    
    
      <li class="md-tabs__item md-tabs__item--active">
        <a href="../../1-Probability-of-events/1-What-is-the-probability/" class="md-tabs__link">
          
  
  课程

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%8B%E9%99%88%E5%B8%8C%E5%AD%BA%EF%BC%8C%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E5%87%BA%E7%89%88%E7%A4%BE.pdf" class="md-tabs__link">
        
  
    
  
  PDF

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="概率论与数理统计" class="md-nav__button md-logo" aria-label="概率论与数理统计" data-md-component="logo">
      
  <img src="../../../cover.jpg" alt="logo">

    </a>
    概率论与数理统计
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/Probability-and-Statistics" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/Probability-and-Statistics
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    首页
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            首页
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    简介
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    课程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            课程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    章节
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            章节
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1_1" id="__nav_2_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第1章 事件的概率
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            第1章 事件的概率
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1-Probability-of-events/1-What-is-the-probability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 概率是什么
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1-Probability-of-events/2-Classical-Probability-Calculation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 古典概率计算
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1-Probability-of-events/3-Operation-Conditional-probability-and-independence-of-events/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 事件的运算、条件概率与独立性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1-Probability-of-events/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../1-Probability-of-events/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_2" >
        
          
          <label class="md-nav__link" for="__nav_2_1_2" id="__nav_2_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第2章 随机变量及概率分布
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            第2章 随机变量及概率分布
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2-Random-Variables-and-Probability-Distribution/1-One-dimensional-random-variable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 一维随机变量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2-Random-Variables-and-Probability-Distribution/2-Multidimensional-random-variables-random-vectors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 多维随机变量（随机向量）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2-Random-Variables-and-Probability-Distribution/3-Independence-of-Conditional-probability-distribution-and-random-variable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 条件概率分布与随机变量的独立性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2-Random-Variables-and-Probability-Distribution/4-Probability-Distribution-of-Functions-of-Random-Variables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.4 随机变量的函数的概率分布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2-Random-Variables-and-Probability-Distribution/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2-Random-Variables-and-Probability-Distribution/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../2-Random-Variables-and-Probability-Distribution/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_3" >
        
          
          <label class="md-nav__link" for="__nav_2_1_3" id="__nav_2_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第3章 随机变量的数字特征
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            第3章 随机变量的数字特征
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3-Numerical-Characteristics-of-Random-Variables/1-Mathematica-Expectations-Mean-and-Median/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 数学期望（均值）与中位数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3-Numerical-Characteristics-of-Random-Variables/2-Variance-and-Moment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 方差与矩
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3-Numerical-Characteristics-of-Random-Variables/3-Covariance-and-correlation-coefficient/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 协方差与相关系数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3-Numerical-Characteristics-of-Random-Variables/4-Theorem-of-Large-Numbers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 大数定理和中心极限定理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3-Numerical-Characteristics-of-Random-Variables/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../3-Numerical-Characteristics-of-Random-Variables/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
    
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_4" checked>
        
          
          <label class="md-nav__link" for="__nav_2_1_4" id="__nav_2_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第4章 参数估计
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            第4章 参数估计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../1-Basic-concepts-of-Mathematical-statistics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 数理统计学的基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../2-Moment-estimation-maximum-likelihood-estimation-and-Bayesian-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 矩估计、极大似然估计和贝叶斯估计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    4.3 点估计的优良性准则
  </span>
  

      </a>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../4-Interval-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.4 区间估计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_2_1_5" id="__nav_2_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第5章 假设检验
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            第5章 假设检验
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../5-Hypothesis-Testing/1-Problem-formulation-and-basic-concepts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 问题提法和基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../5-Hypothesis-Testing/2-Important-parameter-inspection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 重要参数检验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../5-Hypothesis-Testing/3-goodness-of-fit-test/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 拟合优度检验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../5-Hypothesis-Testing/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../5-Hypothesis-Testing/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../5-Hypothesis-Testing/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_6" >
        
          
          <label class="md-nav__link" for="__nav_2_1_6" id="__nav_2_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第6章 回归、相关与方差分析
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_6">
            <span class="md-nav__icon md-icon"></span>
            第6章 回归、相关与方差分析
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/1-Basic-concepts-of-regression-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 回归分析基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/2-Univariate-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 一元线性回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/3-Multiple-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.3 多元线性回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/4-Correlation-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.4 相关分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/5-Analysis-of-variance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.5 方差分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../6-Regression-Correlation-and-Analysis-of-Variance/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%8B%E9%99%88%E5%B8%8C%E5%AD%BA%EF%BC%8C%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E5%87%BA%E7%89%88%E7%A4%BE.pdf" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PDF
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  
  
<nav class="md-tags" >
  
    
    
    
      <a href="../../../tags/#" class="md-tag">校订中……</a>
    
  
</nav>


  
    <a href="https://github.com/EanYang7/Probability-and-Statistics/tree/main/docs/courses/4-Parameter-Estimates/3-Excellence-criterion-of-Point-estimation.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/Probability-and-Statistics/tree/main/docs/courses/4-Parameter-Estimates/3-Excellence-criterion-of-Point-estimation.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="43">4.3 点估计的优良性准则<a class="headerlink" href="#43" title="Permanent link">⚓︎</a></h1>
<object data="https://eanyang7.github.io/Probability-and-Statistics/assets/4/4.3.pdf" type="application/pdf" width="700px" height="700px">
    <embed src="https://eanyang7.github.io/Probability-and-Statistics/assets/4/4.3.pdf">
        <p>This browser does not support PDFs. Please download the PDF to view it: <a href="https://eanyang7.github.io/Probability-and-Statistics/assets/4/4.3.pdf">下载 PDF</a>.</p>
    </embed>
</object>
<h1 id="43_1">4.3 点估计的优良性准则<a class="headerlink" href="#43_1" title="Permanent link">⚓︎</a></h1>
<p>从前节的例子中我们絮累看到: 同一个参数往往有不止一种 看来都合理的估计法. 因此,自然会提出其优劣比较的问题.</p>
<p>初一看觉得这个问题很容易回答: 设 <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 和 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 两个估计量都 用于估计 <span class="arithmatex">\(\theta\)</span>, 则看哪一个的误差小, 就哪一个为优. 但是, 由于 <span class="arithmatex">\(\theta\)</span> 本 身末知, 就不知道估计误差有多大, 这还不是最主要的. 主要问题 在于: <span class="arithmatex">\(\hat{\theta}_{1}, \hat{\theta}_{2}\)</span> 之值都与样本有关.一般情况是: 对某些样本, <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 的 误差小于 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 的误差, 而对另一些样本则反之.一个从整体上看不 好的估计, 在个别场合下可能表现很好.反之, 一个很不错的估计, 由于抽到了不易出现的样本, 其表现也可以很差. 如例 1.2 估计学 生学习成绩(以其考分衡量)的问题,大家都会同意: 如抽出 100 个 学生, 以其平均成绩作为估计值, 比以抽出的第一个学生的成绩作 为估计值要好. 但也可以发生这种情况: 所抽第一个学生的成绩很 接近于全校总平均, 而 100 个学生的平均成绩反而与这个总平均 有较大差距.</p>
<p>由此可见, 在考虑估计量的优劣时, 必须从某种整体性能去衡 量它, 而不能看它在个别样本之下的表现如何. 这里所谓“整体性 能”, 有两种意义: 一是指估计量的某种特性, 具有这种特性就是好 的, 否则就是不好的. 如下文要讲的 “无偏性”, 即属于此类.二是指 某种具体的数量性指标. 两个估计量, 指标小者为优. 如下文讲到 的“均方误差”, 即属于此类.应当注意的是:这种比较,归根到底, 也还是相对性的. 具有某种特性的估计是否一定就好? 这在一定</p>
<ul>
<li>174 • 程度上要看问题的具体情况, 不是绝对的. 下文在讲述无偏估计时 还会涉及这一点, 作为比较准则的数量性指标, 也可以有很多种. 很有可能: 在甲指标之下 <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 优于 <span class="arithmatex">\(\hat{\theta}_{2}\)</span>, 而在乙指标下则反之.</li>
</ul>
<p>我们这样说, 当然不是认为优良性准则和估计量的优劣比较 毫无意义. 相反, 这些很有意义, 且是参数估计这个分支学科研究 的中心问题. 我们是想提醒读者, 不要把这些准则绝对化了. 每种 准则在某种情况下都有其局限性.</p>
<h3 id="01-1">0.1. 1 估计量的无偏性<a class="headerlink" href="#01-1" title="Permanent link">⚓︎</a></h3>
<p>设某统计总体的分布包含末知参数 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}, X_{1}, \cdots, X_{n}\)</span> 是 从该总体中抽出的样本, 要估计 <span class="arithmatex">\(g\left(\theta_{1}, \cdots, \theta_{k}\right) . g\)</span> 为一已知函数. 设 <span class="arithmatex">\(\hat{g}\left(X_{1}, \cdots, X_{n}\right)\)</span> 是一个估计量. 如果对任何可能的 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 都 有</p>
<div class="arithmatex">\[
E_{\theta_{1}}, \cdots, \theta_{k}\left[\hat{g}\left(X_{1}, \cdots, X_{n}\right)\right]=g\left(\theta_{1}, \cdots, \theta_{k}\right)
\]</div>
<p>则称 <span class="arithmatex">\(\hat{g}\)</span> 是 <span class="arithmatex">\(g\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 的一个无偏估计量. 记号 <span class="arithmatex">\(E_{\theta_{1}}, \cdots, \theta_{k}\)</span> 是指: 求期 望值时, 是在各样本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 的分布中的参数为 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 时去 做的. 比如, 我说 <span class="arithmatex">\(X_{1}, X_{2}\)</span> 是取自正态总体 <span class="arithmatex">\(N(\theta, 1)\)</span> 的样本, 让计算 和 <span class="arithmatex">\(X_{1}+X_{2}\)</span> 的期望值. 这要看参数值 <span class="arithmatex">\(\theta\)</span> 等于多少: <span class="arithmatex">\(\theta=1\)</span> 时, 期望值 为 <span class="arithmatex">\(2 ; \theta=2.5\)</span> 时, 期望值为 5 . 标出 <span class="arithmatex">\(E_{\theta}\)</span>, 就明白显示是在哪个 <span class="arithmatex">\(\theta\)</span> 值 之下去算期望值, 也表示 <span class="arithmatex">\(\theta\)</span> 值可以流动. 这在定义 3.1 式中尤其有 意义. 因为在参数估计问题中, 我们并不知参数的真值, 它能在一 定范围内流动. 如废品率 <span class="arithmatex">\(p\)</span>, 可在 <span class="arithmatex">\([0,1]\)</span> 内流动. 当比较两个估计量 时, 需要对种种可能的参数值去比较. 故在 <span class="arithmatex">\(E_{\theta_{1}}, \cdots, \theta_{k}\)</span> 这个记号中强 调指出 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 以及其可以流动, 是重要的. 在不致引起混淆 时, 我们也可以简写为 <span class="arithmatex">\(E\)</span>.</p>
<p>估计量的无偏性有两个含义. 第一个含义是没有系统性的偏 差, 不论你用什么样的估计量 <span class="arithmatex">\(\hat{g}\)</span> 去估计 <span class="arithmatex">\(g\)</span>, 总是时而(对某些样本) 偏低, 时而 (对另一些样本) 偏高. 无偏性表示, 把这些正负偏差在 概率上平均起来, 其值为 0 . 比如用一把秤去秤东西, 误差来源有 二: 一是秤本身结构制作上的问题,使它在秤东西时,倾向于给出 偏高或偏低之值, 这属于系统误差. 另一种是操作上和其他随机性 原因,使秤出的结果有误差, 这属于随机误差, 在此,无偏性的要求 相应于科没有系统误差,但随机误差总是存在. 因此,无偏估计不 等于在任何时候都给出正确无误的估计.</p>
<p>另一个含义是由定义 (3.1) 结合大数定理 (见第三章定理 4.1)引伸出来的. 设想每天把这个估计量 <span class="arithmatex">\(\hat{g}\left(X_{1}, \cdots, X_{n}\right)\)</span> 用一次, 第 <span class="arithmatex">\(i\)</span> 天的样本记为 <span class="arithmatex">\(\hat{g}\left(X_{1}^{(i)}, \cdots, X_{n}^{(i)}\right), i=1,2, \cdots, N, \cdots\)</span>. 则按大数 定理, 当 <span class="arithmatex">\(N \rightarrow \infty\)</span> 时, 各次估计值的平均, 即 <span class="arithmatex">\(\sum_{i=1}^{N} \hat{g}\left(X_{1}^{(i)}, \cdots\right.\)</span>, <span class="arithmatex">\(\left.X_{n}^{(i)}\right) / N\)</span>, 依概率收玫到被估计的值 <span class="arithmatex">\(g\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span>. 所以,若估计 量有无偏性,则在大量次数使用取平均时,能以接近于 <span class="arithmatex">\(100 \%\)</span> 的把 握无限逼近被估计的量.如果没有无偏性,则无论使用多少次,其 平均也会与真值保持一定距离一这距离就是系统误差.</p>
<p>由此可见,估计量的无偏性是一种优良的性质.但是,在一个 具体的问题中,无偏性的实际价值如何,还必须结合这问题的具体 情况去考察.如在秤东西那个例中,若你经常去这家商店买东西而 该店用的秤是无系统误差的.这等于说,店里在科上显示的重量， 是你所买的东西的真实重量的无偏估计,则尽管在具体某一次购 买中店里可能少给或多给了你一些, 从长期平均看, 无偏性保证了 双方都不吃亏.在此,无偏性有很现实的意义。</p>
<p>现在设想另一种情况: 工厂每周进原料一批. 在投人使用前, 由实验室对原料中某些成分含量的百分率 <span class="arithmatex">\(p\)</span> 作一估计，根据估计 值 <span class="arithmatex">\(p\)</span> 采取相应的工艺调整措施. 无论 <span class="arithmatex">\(p\)</span> 比真正的 <span class="arithmatex">\(p\)</span> 偏高或偏低,都 会有损于产品质量. 在此, 即使 <span class="arithmatex">\(\bar{p}\)</span> 是 <span class="arithmatex">\(p\)</span> 的无偏估计, 在长期使用中, 估计的正负偏差的效应并不能抵消. 这样 <span class="arithmatex">\(\hat{p}\)</span> 的无偏性就不见得很 有实用意义了.</p>
<p>例 3.1 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从某总体中抽出的样本,则样本均 值 <span class="arithmatex">\(\vec{X}\)</span> 是总体分布均值 <span class="arithmatex">\(\theta\)</span> 的无偏估计.</p>
<p>这是因为,按定义, 每个样本 <span class="arithmatex">\(X_{i}\)</span> 的分布, 与总体分布一样, 因 此其均值 <span class="arithmatex">\(E\left(X_{i}\right)\)</span> 就是 <span class="arithmatex">\(\theta\)</span>, 而</p>
<div class="arithmatex">\[
E(\bar{X})=\sum_{i=1}^{n} E\left(X_{i}\right) / n=n \theta / n=\theta
\]</div>
<p>据此可知: 在正态总体 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 中用 <span class="arithmatex">\(\bar{X}\)</span> 估计 <span class="arithmatex">\(\mu\)</span>, 在指数分布总体中 用 <span class="arithmatex">\(\bar{X}\)</span> 估计 <span class="arithmatex">\(1 / \lambda\)</span>, 在二项分布总体中用 <span class="arithmatex">\(\bar{X} / N\)</span> 估计 <span class="arithmatex">\(p\)</span>, 以及在波哇松分 布总体中用 <span class="arithmatex">\(\bar{X}\)</span> 估计 <span class="arithmatex">\(\lambda\)</span> 等, 都是无偏估计.</p>
<p>例 3.2 由 (1.1) 式定义的样本方差 <span class="arithmatex">\(S^{2}\)</span>, 是总体分布方差 <span class="arithmatex">\(\sigma^{2}\)</span> 的无偏估计.</p>
<p>为证明这一点, 以 <span class="arithmatex">\(a\)</span> 记总体分布均值: <span class="arithmatex">\(E\left(X_{i}\right)=a\)</span>. 也有 <span class="arithmatex">\(E(\bar{X})=a\)</span>, 把 <span class="arithmatex">\(X_{i}-\bar{X}\)</span> 写为 <span class="arithmatex">\(\left(X_{i}-a\right)-(\bar{X}-a)\)</span>, 有</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\sum_{i=1}^{n}\left[\left(X_{i}-a\right)-(\bar{X}-a)\right]^{2} \\
&amp; =\sum_{i=1}^{n}\left(X_{i}-a\right)^{2}-2(\bar{X}-a) \sum_{i=1}^{n}\left(X_{i}-a\right)+n(\bar{X}-a)^{2}
\end{aligned}
\]</div>
<p>注意到 <span class="arithmatex">\(\sum_{i=1}^{n}\left(X_{i}-a\right)=n(\bar{X}-a)\)</span>, 有</p>
<div class="arithmatex">\[
\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\sum_{i=1}^{n}\left(X_{i}-a\right)^{2}-n(\bar{X}-a)^{2}
\]</div>
<p>因 <span class="arithmatex">\(a=\dot{E}\left(X_{i}\right)=E(\bar{X})\)</span>, 有</p>
<div class="arithmatex">\[
\begin{gathered}
E\left(X_{i}-a\right)^{2}=\operatorname{Var}\left(X_{i}\right)=\sigma^{2}, i=1, \cdots, n \\
E(\bar{X}-a)^{2}=\operatorname{Var}(\bar{X})=\sum_{i=1}^{n} \operatorname{Var}\left(X_{i}\right) / n^{2}=n \sigma^{2} / n^{2}=\sigma^{2} / n
\end{gathered}
\]</div>
<p>于是得到</p>
<div class="arithmatex">\[
E\left(S^{2}\right)=\frac{1}{n-1} E\left(\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\right)=\frac{1}{n-1}\left(n \sigma^{2}-n \cdot \sigma^{2} / n\right)=\sigma^{2}
\]</div>
<p>这就说明了 <span class="arithmatex">\(S^{2}\)</span> 是 <span class="arithmatex">\(\sigma^{2}\)</span> 的无偏估计.</p>
<p>这就解释了为什么要在样本二阶中心矩 <span class="arithmatex">\(m_{2}=\sum_{i=1}^{n}\left(X_{i}-\right.\)</span> <span class="arithmatex">\(\bar{X})^{2} / n\)</span> 的基础上, 把分母 <span class="arithmatex">\(n\)</span> 修正为 <span class="arithmatex">\(n-1\)</span> 以得到 <span class="arithmatex">\(S^{2}\)</span>. 这与以前讲 过的一点也相合: 在第二章的附录 <span class="arithmatex">\(B\)</span> 中我们曾讲到 <span class="arithmatex">\(\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\)</span> 的自由度为 <span class="arithmatex">\(n-1\)</span>. 这正好是正确的除数,这件事不是一个巧合.</p>
<p>在这里我们还可以对“自由度”这个概念赋予另一种解释: 一 共有 <span class="arithmatex">\(n\)</span> 个样本, 有 <span class="arithmatex">\(n\)</span> 个自由度. 用 <span class="arithmatex">\(S^{2}\)</span> 估计方差 <span class="arithmatex">\(\sigma^{2}\)</span>, 自由度本应为 <span class="arithmatex">\(n\)</span>. 但总体均值 <span class="arithmatex">\(a\)</span> 也末知, 用 <span class="arithmatex">\(\bar{X}\)</span> 去估计之, 用掉了一个自由度, 故只 剩下 <span class="arithmatex">\(n-1\)</span> 个自由度.</p>
<p>如果总体均值 <span class="arithmatex">\(a\)</span> 已知, 则不用 <span class="arithmatex">\(S^{2}\)</span> 而用 <span class="arithmatex">\(\sum_{i=1}^{n}\left(X_{i}-a\right)^{2} / n\)</span> 去估 计总体方差 <span class="arithmatex">\(\sigma^{2}\)</span> (在 <span class="arithmatex">\(a\)</span> 末知时不能用), 这是 <span class="arithmatex">\(\sigma^{2}\)</span> 的无偏估计, 分母为 <span class="arithmatex">\(n\)</span> 不用改为 <span class="arithmatex">\(n-1\)</span>. 因为此处 <span class="arithmatex">\(n\)</span> 个自由度全保留下了 ( <span class="arithmatex">\(a\)</span> 已知, 不用 估计,没有用去自由度)。</p>
<p>例 3.3 由上例易推知: 用 <span class="arithmatex">\(S\)</span> 去估计总体分布的标准差 <span class="arithmatex">\(\sigma\)</span> (方 差 <span class="arithmatex">\(\sigma^{2}\)</span> 的正平方根), 不是无偏估计. 事实上, 据第三章 (2.2) 式及上 例的结果, 有</p>
<div class="arithmatex">\[
\sigma^{2}=E\left(S^{2}\right)=\operatorname{Var}(S)+(E S)^{2}
\]</div>
<p>由于方差总非负: <span class="arithmatex">\(\operatorname{Var}(S) \geqslant 0\)</span>, 有 <span class="arithmatex">\(\sigma \geqslant E(S)\)</span>. 因而 <span class="arithmatex">\(E(S) \leqslant \sigma\)</span>. 即如 用 <span class="arithmatex">\(S\)</span> 去估计 <span class="arithmatex">\(\sigma\)</span>, 总是系统地偏低. 在一些情况下, 可以通过简单的 调整达到无偏估计. 办法是把 <span class="arithmatex">\(S\)</span> 乘上一个大于 1 的、与样本大小 <span class="arithmatex">\(n\)</span> 有关的因子 <span class="arithmatex">\(c_{n}\)</span>, 得 <span class="arithmatex">\(c_{n} S\)</span>. 适当选择 <span class="arithmatex">\(c_{n}\)</span> 可以使 <span class="arithmatex">\(E\left(c_{n} S\right)=c_{n} E(S)=\)</span> <span class="arithmatex">\(\sigma\)</span>. 对正态分布总体 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 而言, 不难证明 (习题 21)</p>
<div class="arithmatex">\[
c_{n}=\sqrt{\frac{n-1}{2}} \Gamma\left(\frac{n-1}{2}\right) / \Gamma\left(\frac{n}{2}\right)
\]</div>
<p>由 <span class="arithmatex">\(E(S) \leqslant \sigma\)</span> 看出: 在例 2.3 中给出的均匀分布 <span class="arithmatex">\(R\left(\theta_{1}, \theta_{2}\right)\)</span> 中 <span class="arithmatex">\(\theta_{1}\)</span>, <span class="arithmatex">\(\theta_{2}\)</span> 的估计量 (2.2), 即使把 <span class="arithmatex">\(m_{2}\)</span> 政成 <span class="arithmatex">\(S^{2}\)</span>, 也是有偏的 ( <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 偏高, <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 偏低). 可以证明 (习题 22): 能找到常数 <span class="arithmatex">\(c_{n}\)</span>, 使 <span class="arithmatex">\(\bar{X}-c_{n} S\)</span> 和 <span class="arithmatex">\(\bar{X}+c_{n} S\)</span> 分别是 <span class="arithmatex">\(\theta_{1}, \theta_{2}\)</span> 的无偏估计,但 <span class="arithmatex">\(c_{n}\)</span> 的具体数值不易定出来.</p>
<p>例 3.4 我们已经知道: 矩估计不必是无偏的, 极大似然估计 也如此. 事实上, 在例 2.7 中, 我们已求出: 正态总体 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 的 方差 <span class="arithmatex">\(\sigma^{2}\)</span> 的极大似然估计, 就是样本二阶中心矩 <span class="arithmatex">\(m_{2}\)</span>, 而我们已知后 者不是无偏的. 再看一个例子: 例 2.9 中我们找出均匀分布 <span class="arithmatex">\(R(0\)</span>, <span class="arithmatex">\(\theta)\)</span> 中 <span class="arithmatex">\(\theta\)</span> 的极大似然估计是 <span class="arithmatex">\(\theta^{*}=\max \left(X_{1}, \cdots, X_{n}\right)\)</span>. 不用计算即知 <span class="arithmatex">\(\theta^{*}\)</span> 偏低. 因为, 每个样本 <span class="arithmatex">\(X_{i}\)</span> 都在 <span class="arithmatex">\((0, \theta)\)</span> 内, 故其最大值, 即 <span class="arithmatex">\(\theta^{*}\)</span>, 也 在这个区间内. 下面通过计算 <span class="arithmatex">\(E_{\theta}\left(\theta^{*}\right)\)</span> 证明这一点,并找出调整因 子 <span class="arithmatex">\(c_{n}\)</span>, 此例对下面还有用.</p>
<p>先算 <span class="arithmatex">\(\theta^{*}\)</span> 的分布函数 <span class="arithmatex">\(G(x, \theta)\)</span>. 因为 <span class="arithmatex">\(0&lt;\theta^{*}&lt;\theta\)</span>, 有</p>
<div class="arithmatex">\[
G(x, \theta)=0 \text {, 当 } x \leqslant 0 ; G(x, \theta)=1 \text {, 当 } x \geqslant \theta
\]</div>
<p>若 <span class="arithmatex">\(0&lt;x&lt;\theta\)</span>, 则为了事件 <span class="arithmatex">\(\left\{\theta^{*} \leqslant x\right\}\)</span> 发生, 必须 <span class="arithmatex">\(\left\{X_{1} \leqslant x\right\}, \cdots,\left\{X_{n} \leqslant\right.\)</span> <span class="arithmatex">\(x\}\)</span> 这 <span class="arithmatex">\(n\)</span> 个事件同时发生. 由于各样本独立, 且都有均匀分布 <span class="arithmatex">\(R(0\)</span>, <span class="arithmatex">\(\theta)\)</span>, 有 <span class="arithmatex">\(P\left(X_{i} \leqslant x\right)=x / \theta\)</span>, 因而</p>
<div class="arithmatex">\[
G(x, \theta)=(x / \theta)^{n}
\]</div>
<p>对 <span class="arithmatex">\(x\)</span> 求导数, 得到 <span class="arithmatex">\(\theta^{*}\)</span> 的概率密度函数为</p>
<div class="arithmatex">\[
g(x, \theta)=n x^{n-1} / \theta^{n} \text {, 当 } 0&lt;x&lt;\theta \text {; 此外为 } 0
\]</div>
<p>由此得到</p>
<div class="arithmatex">\[
E_{\theta}\left(\theta^{*}\right)=\int_{0}^{\theta} x g(x, \theta) \mathrm{d} x=n \int_{0}^{\theta} x^{n} \mathrm{~d} x / \theta^{n}=\frac{n}{n+1} \theta
\]</div>
<p>看出以 <span class="arithmatex">\(\theta^{*}\)</span> 估计 <span class="arithmatex">\(\theta\)</span> 系统偏低, 且 <span class="arithmatex">\(\frac{n+1}{n} \theta^{*}\)</span> 为 <span class="arithmatex">\(\theta\)</span> 的无偏估计.</p>
<h3 id="02-2">0.2. 2 最小方差无偏估计<a class="headerlink" href="#02-2" title="Permanent link">⚓︎</a></h3>
<p>一个参数往往有不止一个无偏估计, 从这些众多的无偏估计 中,我们想挑出那个最优的. 这牵涉到两个问题: 一是为优良性制 定一个准则, 二是在已定的准则之下, 如何去找到最优者. 这涉及 较深的理论问题,许多内容都超出本课程范围之外, 这里我们只能 作一个很初步的介绍.</p>
<ol>
<li>均方误差, 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从某一带参数 <span class="arithmatex">\(\theta\)</span> 的总体中抽出 的样本, 要佔计 <span class="arithmatex">\(\theta\)</span>. 若我们采用估计量 <span class="arithmatex">\(\hat{\theta}=\hat{\theta}\left(X_{1}, \cdots, X_{n}\right)\)</span>, 则其误 差为 <span class="arithmatex">\(\hat{\theta}\left(X_{1}, \cdots, X_{n}\right)-\theta\)</span>. 这误差随样本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 的具体值而定, 也是随机的, 因而其本身无法取为优良性指标. 我们把它平方以消 除符号, 得 <span class="arithmatex">\(\left(\hat{\theta}\left(X_{1}, \cdots, X_{n}\right)-\theta\right)^{2}\)</span>, 然后取它的均值, 即取</li>
</ol>
<div class="arithmatex">\[
\left.M_{\hat{g}}(\theta)=E_{\theta}\left[\hat{\theta}\left(X_{1}, \cdots, X_{n}\right)-\theta\right)\right]^{2}
\]</div>
<p>作为 <span class="arithmatex">\(\hat{\theta}\)</span> 的误差大小从整体角度的一个衡量. 这个量愈小, 就表示 <span class="arithmatex">\(\hat{\theta}\)</span> 的误差平均讲比较小, 因而也就愈优. <span class="arithmatex">\(M_{\hat{g}}(\theta)\)</span> 就称为估计量 <span class="arithmatex">\(\theta\)</span> 的 “均方误差” (误差平方的平均) . 不言而喻,均方误差小并不能保证 <span class="arithmatex">\(\hat{\theta}\)</span> 在每次使用时一定给出小的误差. 它有时也可以有较大的误差, 但这种情况出现的机会较少.</p>
<p>用均方误差的观点就容易回答前面提到过的一个问题: 用 100 个学生的平均成绩作为全校学生平均成绩的估计,比用抽出 的第一个学生的成绩去估计好. 事实上, 这两个估计分别是 <span class="arithmatex">\(\bar{X}=\)</span> <span class="arithmatex">\(\left(X_{1}+\cdots+X_{100}\right) / 100\)</span> 和 <span class="arithmatex">\(X_{1}\)</span>. 总体分布为正态 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right) . \bar{X}\)</span> 和 <span class="arithmatex">\(X_{1}\)</span> 的均方误差分别为</p>
<div class="arithmatex">\[
E(\bar{X}-\mu)^{2}=\sigma^{2} / 100, E\left(X_{1}-\mu\right)^{2}=\sigma^{2}
\]</div>
<p>故 <span class="arithmatex">\(X_{1}\)</span> 的均方误差是 <span class="arithmatex">\(\bar{X}\)</span> 的 100 倍.</p>
<p>均方误差并不是唯一可供选择的准则. 例如, 平均绝对误差 <span class="arithmatex">\(E_{\theta}\left|\hat{\theta}\left(X_{1}, \cdots, X_{n}\right)-\theta\right|\)</span>, 以及其他许多别的准则, 看来都很合理且 在某些场合下还确有其优点,但是, 由于平方这个函数在数学上最 易处理,使这个准则成为一切准则中应用和研究得最多的.</p>
<p>按第三章 <span class="arithmatex">\((2.2)\)</span> 式,有</p>
<div class="arithmatex">\[
M_{\hat{\theta}}(\theta)=\operatorname{Var}_{\theta}(\hat{\theta})+\left[E_{\theta}(\hat{\theta})-\theta\right]^{2}
\]</div>
<p>即均方误差由两部分构成:一部分是 <span class="arithmatex">\(\operatorname{Var}_{\theta}(\hat{\theta})\)</span>, 即 <span class="arithmatex">\(\hat{\theta}\)</span> 的方差, 表示 <span class="arithmatex">\(\hat{\theta}\)</span> 自身变异的程度,另一部分中, <span class="arithmatex">\(E_{\theta}(\hat{\theta})-\theta\)</span> 表示 <span class="arithmatex">\(\hat{\theta}\)</span> 这个估计量的系 统偏差. 如果 <span class="arithmatex">\(\hat{\theta}\)</span> 为 <span class="arithmatex">\(\theta\)</span> 的无偏估计, 则第二项为 0 , 而这时有</p>
<div class="arithmatex">\[
M_{\hat{\theta}}(\theta)=\operatorname{Var}_{\theta}(\hat{\theta})
\]</div>
<ol>
<li>最小方差无偏估计. 从前面的讨论看到: 若局限于无偏估 计的范围, 且采用均方误差的准则, 则两个无偏估计 <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 和 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 的比 较,归结为其方差的比较: 方差小者为优. 例 3.5 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从均匀分布总体 <span class="arithmatex">\(R(0, \theta)\)</span> 中抽出的 样本. 在例 3.4 中已指出过 <span class="arithmatex">\(\theta\)</span> 的两个无偏估计: <span class="arithmatex">\(\hat{\theta}_{1}=2 \bar{X}, \hat{\theta}_{2}=\)</span> <span class="arithmatex">\(\frac{n+1}{n} \max \left(X_{1}, \cdots, X_{n}\right)\)</span>. 有(参看第三章, 例 2.5)</li>
</ol>
<div class="arithmatex">\[
\operatorname{Var}_{\theta}\left(\hat{\theta}_{1}\right)=4 \operatorname{Var}_{\theta}(\bar{X})=\frac{4}{n} \operatorname{Var}_{\theta}\left(X_{1}\right)=\frac{4}{n} \frac{1}{12} \theta^{2}=\frac{\theta^{2}}{3 n}
\]</div>
<p>为计算 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 的方差, 仍以 <span class="arithmatex">\(\theta^{*}\)</span> 记 <span class="arithmatex">\(\max \left(X_{1}, \cdots, X_{n}\right)\)</span>. 按 <span class="arithmatex">\(\theta^{*}\)</span> 的密度函数 (3.3), 得</p>
<div class="arithmatex">\[
E_{\theta}\left(\theta^{*}\right)=\frac{n}{n+1} \theta, E_{\theta}\left(\theta^{* 2}\right)=n \int_{0}^{\theta} x^{x+1} \mathrm{~d} x / \theta^{n}=\frac{n}{n+2} \theta^{2}
\]</div>
<p>因此</p>
<div class="arithmatex">\[
\operatorname{Var}_{\theta}\left(\theta^{*}\right)=E_{\theta}\left(\theta^{* 2}\right)-\left[E_{\theta}\left(\theta^{*}\right)\right]^{2}=\frac{n}{(n+1)^{2}(n+2)} \theta^{2}
\]</div>
<p>而</p>
<div class="arithmatex">\[
\operatorname{Var}_{\theta}\left(\hat{\theta}_{2}^{*}\right)=\left(\frac{n+1}{n}\right)^{2} \operatorname{Var}_{\theta}\left(\theta^{*}\right)=\frac{1}{n(n+2)} \theta^{2}
\]</div>
<p>当 <span class="arithmatex">\(n&gt;1\)</span> 时, 总有 <span class="arithmatex">\(n(n+2)&gt;3 n\)</span>. 故除非 <span class="arithmatex">\(n=1, \hat{\theta}_{2}\)</span> 的方差总比 <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 的方差为小, 且这一点不论末知参数 <span class="arithmatex">\(\theta\)</span> 取什么值都对. 因此, 在 “方差小者为优”这个准则下, <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 优于 <span class="arithmatex">\(\hat{\theta}_{1}\)</span>, 当 <span class="arithmatex">\(n=1\)</span> 时, <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 与 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 重 合.</p>
<p>如果 <span class="arithmatex">\(\hat{\theta}\)</span> 是 <span class="arithmatex">\(\theta\)</span> 的一个无偏估计, 且它的方差对 <span class="arithmatex">\(\theta\)</span> 的任何可能取 的值, 都比任何其他的无偏估计的方差为小, 或至多等于它, 则在 “方差愈小愈好”这个准则下, <span class="arithmatex">\(\hat{\theta}\)</span> 就是最好的, 它称为 <span class="arithmatex">\(\theta\)</span> 的“最小方 差无偏估计”, 简记为 MVU 佔计 <span class="arithmatex">\({ }^{*}\)</span>.</p>
<p>定义 3.1 设 <span class="arithmatex">\(\hat{\theta}\)</span> 为 <span class="arithmatex">\(g(\theta)\)</span> 之无偏估计. 若对 <span class="arithmatex">\(g(\theta)\)</span> 的任何一个无 偏估计 <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 都有</p>
<div class="arithmatex">\[
\operatorname{Var}_{\theta}(\hat{\theta}) \leqslant \operatorname{Var}_{\theta}\left(\hat{\theta}_{1}\right)
\]</div>
<ul>
<li>MVU 是“最小方差无偏”的英语 Minimum Variance Unbiased 的缩写. 对 <span class="arithmatex">\(\theta\)</span> 的任何可能取的值都成立, 则称 <span class="arithmatex">\(\hat{\theta}\)</span> 为 <span class="arithmatex">\(g(\theta)\)</span> 的一个最小方差无 偏估计(MVU 估计)。</li>
</ul>
<p>从例 3.5 知 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 的方差小于 <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 的方差. 但我们并不能由此就肯 定 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 就是 <span class="arithmatex">\(\theta\)</span> 的 MVU 估计, 因为也可能还存在其他的无偏估计, 其方差比 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 的更小. 那么, 怎样去寻找 MVU 估计呢? 在数理统 计学中给出了一些方法, 我们只能简略地介绍其中的一个. 这个方 法的思想如下: 先研究一下, 在 <span class="arithmatex">\(g(\theta)\)</span> 的一切无偏估计中, 方差最小 能达到多少呢? 如果我们求出了这样一个方差的下界, 则如某个 估计 <span class="arithmatex">\(\hat{\theta}\)</span> 的方差达到这个下界,那它必定就是 MVU 估计.</p>
<ol>
<li>求 MVU 估计的一种方法: 克拉美一劳不等式.</li>
</ol>
<p>我们只考虑单参数的情况. 设总体的概率密度函数或概率函 数 <span class="arithmatex">\(f(x, \theta)\)</span> 只包含一个参数, <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 为从该总体中抽出的样 本, 要估计 <span class="arithmatex">\(g(\theta)\)</span>. 记</p>
<div class="arithmatex">\[
I(\theta)=\int\left[\left(\frac{\partial f(x, \theta)}{\partial \theta}\right)^{2} / f(x, \theta)\right] \mathrm{d} x
\]</div>
<p>这里积分的范围为 <span class="arithmatex">\(x\)</span> 可取的范围. 例如, 对指数分布总体, <span class="arithmatex">\(0&lt;x&lt;\)</span> <span class="arithmatex">\(\infty\)</span>, 对正态总体则 <span class="arithmatex">\(-\infty&lt;x&lt;\infty\)</span>. 如果总体分布是离散的, 则 (3.8) 改为</p>
<div class="arithmatex">\[
I(\theta)=\sum_{i}\left(\frac{\partial f\left(a_{i}, \theta\right)}{\partial \theta}\right)^{2} / f\left(a_{i}, \theta\right)
\]</div>
<p>这里求和 <span class="arithmatex">\(\sum_{i}\)</span> 遍及总体的全部可能值 <span class="arithmatex">\(a_{1}, a_{2}, \cdots\)</span>. 确定计, 我们下 面就连续型的情况去讨论. 对离散型的情况, 只须作相应的修改, 有如把 (3.8)修改为 (3.9).</p>
<p>克拉美一劳不等式: 在一定的条件下, 对 <span class="arithmatex">\(g(\theta)\)</span> 的任一无偏估计 <span class="arithmatex">\(\hat{g}=\hat{g}\left(X_{1}, \cdots, X_{n}\right)\)</span>, 有</p>
<div class="arithmatex">\[
\operatorname{Var}_{\theta}(\hat{g}) \geqslant\left(g^{\prime}(\theta)\right)^{2} /(n I(\theta))
\]</div>
<p><span class="arithmatex">\(n\)</span> 是样本大小.</p>
<p>这个不等式给出了 <span class="arithmatex">\(g(\theta)\)</span> 的无偏估计的方差的一个下界, 即 - 182 • (3.10) 式右边. 如果 <span class="arithmatex">\(g(\theta)\)</span> 的某个无偏估计其方差正好达到了 (3.10) 右端, 则它就是 <span class="arithmatex">\(g(\theta)\)</span> 的 MVU 估计, 这不等式的成立有一 定的条件. 实际上, 在其表述中, 就包含了要求 <span class="arithmatex">\(\partial f(x, \theta) / \partial \theta\)</span> 和 <span class="arithmatex">\(g^{\prime}(\theta)\)</span> 存在的条件,其他的条件将在下文推导中看出.</p>
<p>记</p>
<div class="arithmatex">\[
\begin{aligned}
S &amp; =S\left(X_{1}, \cdots, X_{n}, \theta\right)=\sum_{i=1}^{n} \partial \log f\left(X_{i}, \theta\right) / \partial \theta \\
&amp; =\sum_{i=1}^{n} \frac{\partial f\left(X_{i}, \theta\right)}{\partial \theta} / f\left(X_{i}, \theta\right)
\end{aligned}
\]</div>
<p>因为 <span class="arithmatex">\(f(x, \theta)\)</span> 为密度, 有 <span class="arithmatex">\(\int f(x, \theta) \mathrm{d} x=1\)</span>. 两边对 <span class="arithmatex">\(\theta\)</span> 求导, 并假定 (这就是条件之一) 左边求导可搬到积分号内, 有</p>
<div class="arithmatex">\[
\int \frac{\partial f(x, \theta)}{\partial \theta} \mathrm{d} x=0
\]</div>
<p>因此</p>
<div class="arithmatex">\[
\begin{aligned}
E_{\theta} &amp; {\left[\int \frac{\partial f\left(X_{i}, \theta\right)}{\partial \theta} / f\left(X_{i}, \theta\right)\right] } \\
&amp; =\int\left(\frac{\partial f(x, \theta)}{\partial \theta} / f(x, \theta)\right) f(x, \theta) \mathrm{d} x \\
&amp; =\int\left(\frac{\partial f\left(x_{i}, \theta\right)}{\partial \theta}\right) \mathrm{d} x=0
\end{aligned}
\]</div>
<p>于是, 由 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 的独立性, 有</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{Var}_{\theta}(S) &amp; =\sum_{i=1}^{n} \operatorname{Var}_{\theta}\left(\frac{\partial f\left(X_{i}, \theta\right)}{\partial \theta} / f\left(X_{i}, \theta\right)\right) \\
&amp; =\sum_{i=1}^{n} E_{\theta}\left[\frac{\partial f\left(X_{i}, \theta\right)}{\partial \theta} / f\left(X_{i}, \theta\right)\right]^{2} \\
&amp; =n \int\left[\frac{\partial f(x, \theta)}{\partial \theta} / f\left(x_{i}, \theta\right)\right]^{2} f(x, \theta) \mathrm{d} x=n I(\theta)
\end{aligned}
\]</div>
<p>按第三章定理 3.1 的 <span class="arithmatex">\(2^{\circ}\)</span>, 有</p>
<div class="arithmatex">\[
\left[\operatorname{Cov}_{\theta}(\hat{g}, S)\right]^{2} \leqslant \operatorname{Var}_{\theta}(\hat{g}) \operatorname{Var}_{\theta}(S)=n I(\theta) \operatorname{Var}_{\theta}(\hat{g})
\]</div>
<p>由(3.11) 有 <span class="arithmatex">\(E_{\theta}(S)=0\)</span>. 按第三章 (3.2)式, 有</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{Cov}_{\theta}(\hat{g}, S)= &amp; E_{\theta}(\hat{g} S) \\
= &amp; \int \cdots \int \hat{g}\left(x_{1}, \cdots, x_{n}\right) \sum_{i=1}^{n}\left[\frac{\partial f\left(x_{i}, \theta\right)}{\partial \theta} / f\left(x_{i}, \theta\right)\right] \\
&amp; \cdot \prod_{i=1}^{n} f\left(x_{i}, \theta\right) \cdot \mathrm{d} x_{1} \cdots \mathrm{d} x_{n}
\end{aligned}
\]</div>
<p>由乘积的导数公式可知</p>
<div class="arithmatex">\[
\begin{gathered}
\sum_{i=1}^{n}\left[\frac{\partial f\left(x_{i}, \theta\right)}{\partial \theta} / f\left(x_{i}, \theta\right)\right] \prod_{i=1}^{n} f\left(x_{i}, \theta\right) \\
=\frac{\partial f\left(x_{1}, \theta\right) \cdots f\left(x_{n}, \theta\right)}{\partial \theta}
\end{gathered}
\]</div>
<p>以此代人上式, 并假定对 <span class="arithmatex">\(\theta\)</span> 求偏导数可移至积分号外面 (这又是 一个条件!), 则得</p>
<div class="arithmatex">\[
\operatorname{Cov}_{\theta}(\hat{\mathrm{g}}, \mathrm{S})=\frac{\partial}{\partial \theta} \int \cdots \int \hat{\mathrm{g}}\left(x_{1}, \cdots, x_{n}\right) f\left(x_{1}, \theta\right) \cdots f\left(x_{n}, \theta\right) \mathrm{d} x_{1} \cdots \mathrm{d} x_{n}
\]</div>
<p>但上式右边的积分就是 <span class="arithmatex">\(E_{\theta}(\hat{g})\)</span>, 因 <span class="arithmatex">\(\hat{g}\)</span> 为 <span class="arithmatex">\(g(\theta)\)</span> 的无偏估计, 这积分就 是 <span class="arithmatex">\(g(\theta)\)</span>. 故上式右边为 <span class="arithmatex">\(g^{\prime}(\theta)\)</span>, 因而得到 <span class="arithmatex">\(\operatorname{Cov}_{\theta}(\hat{g}, S)=g^{\prime}(\theta)\)</span>, 以 此代人(3.12), 即得 <span class="arithmatex">\((3.10)\)</span>.</p>
<p>不等式 (3.10) 是瑞典统计学家 <span class="arithmatex">\(H\)</span>. 克拉美和印度统计学家 C. <span class="arithmatex">\(\mathrm{R}\)</span>. 劳在 1945-1946 年各自独立得出的,故文献中一般称为克拉 美一劳不等式:这个不等式在数理统计学中有多方面的应用,此处 求 MVU 估计是其中之一.</p>
<p>顺便提一下: (3.10) 中 <span class="arithmatex">\(I(\theta)\)</span> 这个量的表达式(3.8),最初是英 国统计学家 R.A. 费歇尔在 20 年代提出的, 后人称之为 “费歇尔 信息量”. 此量出现在 (3.10) 中,并非偶然的巧合. 从 (3.10)我们可 以对为什么把 <span class="arithmatex">\(I(\theta)\)</span> 称为 “信息量” 获得一点直观的理解: <span class="arithmatex">\(I(\theta)\)</span> 愈 大, (3.10) 式中的下界愈低, 表示 <span class="arithmatex">\(g(\theta)\)</span> 的无偏估计更有可能达到 较小的方差一一即更有可能被估计得更准确一些. <span class="arithmatex">\(g(\theta)\)</span> 是通过样 本去估计的, <span class="arithmatex">\(g(\theta)\)</span> 能估得更准, 表示样本所含的信息量愈大. 一共 有 <span class="arithmatex">\(n\)</span> 个样本,如把总信息量说成是 (3.10) 右边的分母 <span class="arithmatex">\(n I(\theta)\)</span>, 则 一个样本正好占有信息量 <span class="arithmatex">\(I(\theta), I(\theta)\)</span> 这个量在数理统计学中很重 要,有多方面的应用,但大多超出本课程的范围.</p>
<p>不等式 (3.10) 并不直接给出找 MVU 估计的方法. 它的使用 方式是: 先要由直观或其他途径找出一个可能是最好的无偏估计, 然后计算其方差, 看是否达到了 (3.10) 式右端的界限, 若达到了, 就是 MVU 估计. 同时, 还得仔细验证不等式推导过程中所有的条 件是否全满足, 这有时是不大容易的, 在以下诸例中, 我们都略去 了这步验证.</p>
<p>例 3.6 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 为抽自正态总体 <span class="arithmatex">\(N\left(\theta, \sigma^{2}\right)\)</span> 的样本, <span class="arithmatex">\(\sigma^{2}\)</span> 已知(因而只有一个参数 <span class="arithmatex">\(\theta\)</span> ), 要估计 <span class="arithmatex">\(\theta\)</span>. 本例</p>
<div class="arithmatex">\[
f(x, \theta)=(\sqrt{2 \pi} \sigma)^{-1} \exp \left[-\frac{1}{2 \sigma^{2}}(x-\theta)^{2}\right]
\]</div>
<p>因而</p>
<div class="arithmatex">\[
\begin{aligned}
I(\theta) &amp; =(\sqrt{2 \pi} \sigma)^{-1} \int_{-\infty}^{\infty} \frac{1}{\sigma^{4}}(x-\theta)^{2} \exp \left[-\frac{1}{2 \sigma}(x-\theta)\right]^{2} \mathrm{~d} x \\
&amp; =\frac{1}{\sigma^{4}} \sigma^{2}=\frac{1}{\sigma^{2}}
\end{aligned}
\]</div>
<p>故按不等式 (3.10), <span class="arithmatex">\(\theta\)</span> 的无偏估计的方差, 不能小于 <span class="arithmatex">\(\sigma^{2} / n\)</span>. 而 <span class="arithmatex">\(\bar{X}\)</span> 是 <span class="arithmatex">\(\theta\)</span> 的一个无偏估计, 方差正好是 <span class="arithmatex">\(\sigma^{2} / n\)</span>, 故 <span class="arithmatex">\(\bar{X}\)</span> 就是 <span class="arithmatex">\(\theta\)</span> 的 MVU 估计.</p>
<p>虽然我们是在 <span class="arithmatex">\(\sigma^{2}\)</span> 已知的条件下证得 <span class="arithmatex">\(\bar{X}\)</span> 为 <span class="arithmatex">\(\theta\)</span> 的 MVU 估计,但 不难推知, 这个结论当 <span class="arithmatex">\(\sigma^{2}\)</span> 末知时也对. 证明留给读者 (习题 23).</p>
<p>例 3.7 指数分布的费歇尔信息量 <span class="arithmatex">\(I(\lambda)\)</span> 为</p>
<div class="arithmatex">\[
I(\lambda)=\int_{0}^{\infty}\left(\frac{1}{\lambda}-x\right)^{2} \lambda \mathrm{e}^{-\lambda x} \mathrm{~d} x=\lambda^{-2}
\]</div>
<p>故若要由大小为 <span class="arithmatex">\(n\)</span> 的样本去估计总体均值 <span class="arithmatex">\(g(\lambda)=1 / \lambda\)</span>, 则按 (3.10),1/ <span class="arithmatex">\(\lambda\)</span> 的无偏估计的方差不能小于</p>
<div class="arithmatex">\[
\left[g^{\prime}(\lambda)\right]^{2} /(n I(\lambda))=1 /\left(n \lambda^{2}\right)
\]</div>
<p>而样本均值 <span class="arithmatex">\(\bar{X}\)</span> 是 <span class="arithmatex">\(1 / \lambda\)</span> 的一无偏估计, 方差正好为 <span class="arithmatex">\(1 /\left(n \lambda^{2}\right)\)</span>. 故 <span class="arithmatex">\(\bar{X}\)</span> 是 <span class="arithmatex">\(1 / \lambda\)</span> 的 MVU 估计.</p>
<p>例 3.8 回到例 3.6. 若均值 <span class="arithmatex">\(\theta\)</span> 已知而要估计方差, 则不难证 明: <span class="arithmatex">\(\sum_{i=1}^{n}\left(X_{i}-\theta\right)^{2} / n\)</span> 是 <span class="arithmatex">\(\sigma^{2}\)</span> 的 MVU 估计, 计算留给读者 (在计算费 歇尔信息量时, 注意要把. <span class="arithmatex">\(\sigma^{2}\)</span> 作为一个整体看. 可以引进新参数 <span class="arithmatex">\(\lambda=\sigma^{2}\)</span> 再计算).</p>
<p>如果 <span class="arithmatex">\(\theta, \sigma^{2}\)</span> 都末知而要估计 <span class="arithmatex">\(\sigma^{2}\)</span>, 则可以证明: 样本方差 <span class="arithmatex">\(S^{2}\)</span> 为 <span class="arithmatex">\(\sigma^{2}\)</span> 的 MVU 估计,但这个证明已超出本方法的范围之外.</p>
<p>例 3.9 为估计均匀分布 <span class="arithmatex">\(R(0, \theta)\)</span> 中的参数 <span class="arithmatex">\(\theta\)</span>, 在例 3.5 中引 进过两个无偏估计 <span class="arithmatex">\(\hat{\theta}_{1}=2 \bar{X}\)</span> 和 <span class="arithmatex">\(\hat{\theta}_{2}=\frac{n+1}{n} \max \left(X_{1}, \cdots, X_{n}\right)\)</span>, 并证明 了 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 优于 <span class="arithmatex">\(\hat{\theta}_{1}\)</span>. 事实上可以证明: <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 就是 <span class="arithmatex">\(\theta\)</span> 的 MVU. 但这个结论不 能利用不等式 (3.10) 去证明. 这是因为总体的密度函数并非 <span class="arithmatex">\(\theta\)</span> 的 连续函数. 它有一个间断点: <span class="arithmatex">\(\theta=x\)</span> (注意: 是把 <span class="arithmatex">\(f(x, \theta)\)</span> 中的 <span class="arithmatex">\(x\)</span> 固 定, 作为 <span class="arithmatex">\(\theta\)</span> 的函数时的间断点), 故导数 <span class="arithmatex">\(\partial f(x, \theta) / \partial \theta\)</span> 非处处存在. 证明 <span class="arithmatex">\(\hat{\theta}_{2}\)</span> 为 <span class="arithmatex">\(\theta\)</span> 的 MVU 估计要用另外的方法, 此处不能讲了.</p>
<p>下面举一个离散型总体的例子.</p>
<p>例 3.10 总体分布为二项分布 <span class="arithmatex">\(B(N, p)\)</span>, 概率函数为</p>
<div class="arithmatex">\[
f(x, p)=\left(\begin{array}{l}
N \\
x
\end{array}\right) p^{x}(1-p)^{N-x}, x=0,1, \cdots, N
\]</div>
<p>由此算出费歇尔信息量 (按(3.9)式)</p>
<div class="arithmatex">\[
I(p)=\frac{1}{p^{2}(1-p)^{2}} \sum_{x=0}^{N}(x-N p)^{2}\left(\begin{array}{l}
N \\
x
\end{array}\right) p^{x}(1-p)^{N-x}
\]</div>
<p>右边这个和不是别的, 正是总体方差, 故这个和等于 <span class="arithmatex">\(N p(1-p)\)</span> (第三章例 2.2). 因此</p>
<div class="arithmatex">\[
I(p)=N p^{-1}(1-p)^{-1}
\]</div>
<p>按 (3.10), <span class="arithmatex">\(p\)</span> 的无偏估计 (基于大小为 <span class="arithmatex">\(n\)</span> 的样本) 的方差, 不能小 于 <span class="arithmatex">\(p(1-p) /(n N)\)</span>. 现 <span class="arithmatex">\(\bar{X} / N\)</span> 为 <span class="arithmatex">\(p\)</span> 之一无偏估计,其方差为</p>
<p><span class="arithmatex">\((\bar{X}\)</span> 的方差 <span class="arithmatex">\() / N^{2}=\)</span> 总体方差 <span class="arithmatex">\(/\left(n N^{2}\right)=N p(1-p) /(n N)^{2}\)</span></p>
<div class="arithmatex">\[
=p(1-p) /(n N)
\]</div>
<p>因此, <span class="arithmatex">\(\bar{X} / N\)</span> 就是 <span class="arithmatex">\(p\)</span> 的 MVU 估计.</p>
<p>特别当 <span class="arithmatex">\(N=1\)</span> 时, 得出: “用频率估计概率”, 是 MVU 估计. 在 例 2.13 中, 我们曾求出 <span class="arithmatex">\(p\)</span> 的贝叶斯估计 (2.14), 并指出过它与频 率这个估计比,可能有某些优点. 这就看出: “最小方差无偏”这个 准则也不是绝对的.</p>
<p>例 3.11 仿例 3.10 可以证明: 在波哇松分布 <span class="arithmatex">\(P(\lambda)\)</span> 的总体中 估计 <span class="arithmatex">\(\lambda, \bar{X}\)</span> 是 MVU 估计.证明留给读者.</p>
<h3 id="03-3">0.3. 3 估计量的相合性与渐近正态性<a class="headerlink" href="#03-3" title="Permanent link">⚓︎</a></h3>
<ol>
<li>相合性. 在第三章中我们曾证明大数定理. 这个定理说: 若 <span class="arithmatex">\(X_{1}, X_{2}, \cdots, X_{n}, \cdots\)</span> 独立同分布, 其公共均值为 <span class="arithmatex">\(\theta\)</span>. 记 <span class="arithmatex">\(\bar{X}_{n}=\)</span> <span class="arithmatex">\(\sum_{i=1}^{n} X_{i} / n\)</span>, 则对任给 <span class="arithmatex">\(\varepsilon&gt;0\)</span>, 有</li>
</ol>
<div class="arithmatex">\[
\lim _{n \rightarrow \infty} P\left(\left|\bar{X}_{n}-\theta\right| \geqslant \varepsilon\right)=0
\]</div>
<p>（在证明这个定理时假定了 <span class="arithmatex">\(X_{i}\)</span> 的方差存在有限. 但我们曾指出: 方差存在的条件并非必要).</p>
<p>现在我们可以从估计的观点对 (3.13) 作一个解释. 我们把 <span class="arithmatex">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 看作是从某一总体中抽出的样本. 抽样的目的是估 计该总体的均值 <span class="arithmatex">\(\theta\)</span>. 概率 <span class="arithmatex">\(P\left(\left|\bar{X}_{n}-\theta\right| \geqslant \varepsilon\right)\)</span> 是: “当样本大小为 <span class="arithmatex">\(n\)</span> 时, 样本均值 <span class="arithmatex">\(\bar{X}_{n}\)</span> 这个估计与真值 <span class="arithmatex">\(\theta\)</span> 的偏离达到 <span class="arithmatex">\(\varepsilon\)</span> 这么大或更大” 的可能性. (3.13) 表明: 随着 <span class="arithmatex">\(n\)</span> 的增加, 这种可能性愈来愈小以至 趋于 0 . 这就是说, 只要样本大小 <span class="arithmatex">\(n\)</span> 足够大, 用样本均值去估计总 体均值, 其误差可以任意小. 在数理统计学上, 就把 <span class="arithmatex">\(\bar{X}_{n}\)</span> 称为是 <span class="arithmatex">\(\theta\)</span> 的 “相合估计”. 字面的意思是：随着样本大小的增加, 被估计的量与 估计量逐渐“合”在一起了.</p>
<p>相合性的一般定义就是这个例子的引伸：</p>
<p>定义 3.2 设总体分布依赖于参数 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}, g\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 是 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 之一给定函数. 设 <span class="arithmatex">\(X_{1}, X_{2}, \cdots, X_{n}\)</span> 为自该总体中抽出的 样本, <span class="arithmatex">\(T\left(X_{1}, \cdots, X_{n}\right)\)</span> 是 <span class="arithmatex">\(g\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 的一个估计量. 如果对任给 <span class="arithmatex">\(\varepsilon&gt;0\)</span> 有</p>
<div class="arithmatex">\[
\lim _{n \rightarrow \infty} P_{\theta_{1}}, \cdots, \theta_{k}\left(\left|T\left(X_{1}, \cdots, X_{n}\right)-g\left(\theta_{1}, \cdots, \theta_{k}\right)\right| \geqslant \varepsilon\right)=0
\]</div>
<p>而且这对 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 一切可能取的值都成立, 则称 <span class="arithmatex">\(T\left(X_{1}, \cdots, X_{n}\right)\)</span> 是 <span class="arithmatex">\(g\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 的一个相合估计.</p>
<p>记号 <span class="arithmatex">\(P_{\theta_{1}}, \cdots, \theta_{k}\)</span> 的意义, 表示概率是在参数值为 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 时去 计算的 (参看前面关于记号 <span class="arithmatex">\(E_{\theta_{1}}, \cdots, \theta_{k}\)</span> 的说明). 在讲述大数定理时 我们曾引进过“依概率收敛”的术语. 使用这个术语, 相合性可简单 地描述为: 如果当样本大小无限增加时, 估计量依概率收敛于被估 计的值,则称该估计量是相合估计.</p>
<p>相合性是对一个估计量的最基本的要求.如果一个估计量没 有相合性, 那么, 无论样本大小多大, 我们也不可能把末知参数估 计到任意预定的精度. 这种估计量显然是不可取的.</p>
<p>如同样本均值的相合性那样, 常见的矩估计量的相合性, 都可 以基于大数定理得到证明. 我们再以用二阶中心矩 <span class="arithmatex">\(m_{2}(n)\)</span> <span class="arithmatex">\(=\sum_{i=1}^{n}\left(X_{i}-\bar{X}_{n}\right)^{2} / n\)</span> 为例. 以 <span class="arithmatex">\(a\)</span> 和 <span class="arithmatex">\(\sigma^{2}\)</span> 分别记总体的均值和方差. 注意到</p>
<div class="arithmatex">\[
\begin{aligned}
\sum_{i=1}^{n}\left(X_{i}-a\right)^{2} &amp; =\sum_{i=1}^{n}\left[\left(X_{i}-\bar{X}_{n}\right)+\left(\bar{X}_{n}-a\right)\right]^{2} \\
&amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}_{n}\right)^{2}+n\left(\bar{X}_{n}-a\right)^{2}
\end{aligned}
\]</div>
<p>知</p>
<div class="arithmatex">\[
m_{2}(n)=\frac{1}{n} \sum_{i=1}^{n}\left(X_{i}-a\right)^{2}-\left(\bar{X}_{n}-a\right)^{2}
\]</div>
<p>依大数定理, <span class="arithmatex">\(\sum_{i=1}^{n}\left(X_{i}-a\right)^{2} / n\)</span> 依概率收敛于 <span class="arithmatex">\(E\left(X_{i}-a\right)^{2}=\sigma^{2}\)</span>, 而 <span class="arithmatex">\(\bar{X}_{n}-a\)</span> 依概率收玫于 0 . 故 <span class="arithmatex">\(m_{2}(n)\)</span> 依概率收敛于 <span class="arithmatex">\(\sigma^{2}\)</span>, 即它是总体 方差 <span class="arithmatex">\(\sigma^{2}\)</span> 的相合估计. 因为样本方差与样本二阶中心矩只相差一个 因子 <span class="arithmatex">\(n /(n-1)\)</span>, 而当 <span class="arithmatex">\(n \rightarrow \infty\)</span> 时这个因子趋于 1 , 知样本方差也是 总体方差的相合估计. 这样可以证明: 前面例子中的许多估计都有 相合性.</p>
<p>极大似然估计在很一般的条件下也有相合性. 其证明比较复 杂, 不能在此讨论了.</p>
<ol>
<li>渐近正态性. 估计量是样本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 的函数, 其确切分 布要用第二章 2.4 节的方法去求. 除了若干简单的情况以外, 这常 是难于实现的. 例如, 样本均值可算是最简单的统计量, 它的分布 也不易求得.</li>
</ol>
<p>可是,正如在中心极限定理中所显示的,当 <span class="arithmatex">\(n\)</span> 很大时,和的分 布渐近于正态分布. 理论上可以证明, 这不只是和所独有的, 许多 形状复杂的统计量, 当样本大小 <span class="arithmatex">\(n \rightarrow \infty\)</span> 时, 其分布都渐近于正态分 布. 这称为统计量的“渐近正态性”. 至于哪些统计量具有渐近正态 性, 其确切形式如何, 这都是很深的理论问题,在我们这个课程的 范围内无法细加介绍了.</p>
<p>估计量的相合性和渐近正态性称为估计量的大样本性质，指 的是: 这种性质都是对样本大小 <span class="arithmatex">\(n \rightarrow \infty\)</span> 来谈的. 对一个固定的 <span class="arithmatex">\(n\)</span>, 相合性和渐近正态性都无意义. 与此相对,估计量的无偏性概念是 对固定的样本大小来谈的, 不需要样本大小趋于无穷. 这种性质称 为“小样本性质”. 因此, 大小样本性质之分不在于样本的具体大小 如何, 而在于样本大小趋于无穷与否.</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 21, 2023</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="创建日期">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3h-2Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 21, 2023</span>
  </span>

    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        对当前页面有任何疑问吗？
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5 9v12H1V9h4m4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21H9m0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03V19Z"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 15V3h4v12h-4M15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3h9m0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97V5Z"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              感谢您的反馈！
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              感谢您的反馈！请点击这里<a href="https://github.com/EanYang7/Probability-and-Statistics/issues" target="_blank" rel="noopener">这里</a>提供问题反馈.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


<h2 id="__comments">评论</h2>
<p>登录github的账号后，可以直接在下方评论框中输入。</p>
<p>
  如果想进行更详细的讨论(如排版、上传图片等)，选择一个反应后并点击上方的文字，进入论坛页面。
</p>
<!-- Insert generated snippet here -->
<script
  src="https://giscus.app/client.js"
  data-repo="EanYang7/Probability-and-Statistics"
  data-repo-id="R_kgDOJszf0w"
  data-category="Q&A"
  data-category-id="DIC_kwDOJszf084CXnYR"
  data-mapping="title"
  data-strict="0"
  data-reactions-enabled="1"
  data-emit-metadata="0"
  data-input-position="top"
  data-theme="preferred_color_scheme"
  data-lang="zh-CN"
  crossorigin="anonymous"
  async
></script>
<!-- Synchronize Giscus theme with palette -->
<script>
  var giscus = document.querySelector("script[src*=giscus]");

  /* Set palette on initial load */
  var palette = __md_get("__palette");
  if (palette && typeof palette.color === "object") {
    var theme = palette.color.scheme === "slate" ? "dark" : "light";
    giscus.setAttribute("data-theme", theme);
  }

  /* Register event handlers after documented loaded */
  document.addEventListener("DOMContentLoaded", function () {
    var ref = document.querySelector("[data-md-component=palette]");
    ref.addEventListener("change", function () {
      var palette = __md_get("__palette");
      if (palette && typeof palette.color === "object") {
        var theme = palette.color.scheme === "slate" ? "dark" : "light";

        /* Instruct Giscus to change theme */
        var frame = document.querySelector(".giscus-frame");
        frame.contentWindow.postMessage(
          { giscus: { setConfig: { theme } } },
          "https://giscus.appa"
        );
      }
    });
  });
</script>

                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/EanYang7/cs231n" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.top", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.path", "toc.follow", "content.action.edit", "content.action.view"], "search": "../../../assets/javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>