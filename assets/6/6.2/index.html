
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《概率论与数理统计》陈希孺，中国科学技术大学出版社">
      
      
      
        <link rel="canonical" href="https://eanyang7.github.io/Probability-and-Statistics/assets/6/6.2/">
      
      
      
      
      <link rel="icon" href="../../../cover.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.2">
    
    
      
        <title>6.2 一元线性回归 - 概率论与数理统计</title>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../../stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-GEDRLMN4ML"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-GEDRLMN4ML",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-GEDRLMN4ML",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#62" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="概率论与数理统计" class="md-header__button md-logo" aria-label="概率论与数理统计" data-md-component="logo">
      
  <img src="../../../cover.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            概率论与数理统计
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              6.2 一元线性回归
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/Probability-and-Statistics" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/Probability-and-Statistics
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
  首页

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../courses/1-Probability-of-events/1-What-is-the-probability/" class="md-tabs__link">
          
  
  课程

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%8B%E9%99%88%E5%B8%8C%E5%AD%BA%EF%BC%8C%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E5%87%BA%E7%89%88%E7%A4%BE.pdf" class="md-tabs__link">
        
  
    
  
  PDF

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="概率论与数理统计" class="md-nav__button md-logo" aria-label="概率论与数理统计" data-md-component="logo">
      
  <img src="../../../cover.jpg" alt="logo">

    </a>
    概率论与数理统计
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/Probability-and-Statistics" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/Probability-and-Statistics
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    首页
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            首页
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    简介
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    课程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            课程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    章节
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            章节
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1_1" id="__nav_2_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第1章 事件的概率
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            第1章 事件的概率
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/1-What-is-the-probability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 概率是什么
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/2-Classical-Probability-Calculation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 古典概率计算
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/3-Operation-Conditional-probability-and-independence-of-events/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 事件的运算、条件概率与独立性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_2" >
        
          
          <label class="md-nav__link" for="__nav_2_1_2" id="__nav_2_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第2章 随机变量及概率分布
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            第2章 随机变量及概率分布
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/1-One-dimensional-random-variable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 一维随机变量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/2-Multidimensional-random-variables-random-vectors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 多维随机变量（随机向量）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/3-Independence-of-Conditional-probability-distribution-and-random-variable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 条件概率分布与随机变量的独立性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/4-Probability-Distribution-of-Functions-of-Random-Variables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.4 随机变量的函数的概率分布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_3" >
        
          
          <label class="md-nav__link" for="__nav_2_1_3" id="__nav_2_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第3章 随机变量的数字特征
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            第3章 随机变量的数字特征
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/1-Mathematica-Expectations-Mean-and-Median/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 数学期望（均值）与中位数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/2-Variance-and-Moment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 方差与矩
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/3-Covariance-and-correlation-coefficient/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 协方差与相关系数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/4-Theorem-of-Large-Numbers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 大数定理和中心极限定理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_4" >
        
          
          <label class="md-nav__link" for="__nav_2_1_4" id="__nav_2_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第4章 参数估计
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            第4章 参数估计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/1-Basic-concepts-of-Mathematical-statistics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 数理统计学的基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/2-Moment-estimation-maximum-likelihood-estimation-and-Bayesian-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 矩估计、极大似然估计和贝叶斯估计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/3-Excellence-criterion-of-Point-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 点估计的优良性准则
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/4-Interval-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.4 区间估计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_2_1_5" id="__nav_2_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第5章 假设检验
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            第5章 假设检验
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/1-Problem-formulation-and-basic-concepts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 问题提法和基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/2-Important-parameter-inspection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 重要参数检验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/3-goodness-of-fit-test/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 拟合优度检验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_6" >
        
          
          <label class="md-nav__link" for="__nav_2_1_6" id="__nav_2_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第6章 回归、相关与方差分析
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_6">
            <span class="md-nav__icon md-icon"></span>
            第6章 回归、相关与方差分析
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/1-Basic-concepts-of-regression-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 回归分析基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/2-Univariate-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 一元线性回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/3-Multiple-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.3 多元线性回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/4-Correlation-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.4 相关分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/5-Analysis-of-variance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.5 方差分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%8B%E9%99%88%E5%B8%8C%E5%AD%BA%EF%BC%8C%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E5%87%BA%E7%89%88%E7%A4%BE.pdf" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PDF
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#01-1-beta_0-beta_1" class="md-nav__link">
    <span class="md-ellipsis">
      0.1. 1 \(\beta_{0}\) 和 \(\beta_{1}\) 的点估计一最小二乘法
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#02-2-sigma2" class="md-nav__link">
    <span class="md-ellipsis">
      0.2. 2 残差与误差和方差 \(\sigma^{2}\) 的估计
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#03-3" class="md-nav__link">
    <span class="md-ellipsis">
      0.3. 3 区间估计和预测
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-2-4" class="md-nav__link">
    <span class="md-ellipsis">
      1. 2 .4 假设检验
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. 2 .4 假设检验">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#11-5" class="md-nav__link">
    <span class="md-ellipsis">
      1.1. 5 几个有关问题
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/Probability-and-Statistics/tree/main/docs/assets/6/6.2.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/Probability-and-Statistics/tree/main/docs/assets/6/6.2.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="62">6.2 一元线性回归<a class="headerlink" href="#62" title="Permanent link">⚓︎</a></h1>
<p>本章我们只讨论回归函数为线性函数的情形 (包括能转化为 线性函数的情形)一一称为线性回归. 我们从只含一个自变量 <span class="arithmatex">\(X\)</span> (因变量总是一个, 记为 <span class="arithmatex">\(Y\)</span> ) 的情况开始, 称为一元线性回归. 这个 情况在数学上的处理足够简单, 便于对回归分析的一些概念作进 一步的说明. 这样, 假定回归模型为</p>
<div class="arithmatex">\[
Y=b_{0}+b_{1} X+e
\]</div>
<p>其中 <span class="arithmatex">\(b_{0}, b_{1}\)</span> 为末知参数. <span class="arithmatex">\(b_{0}\)</span> 称为常数项或截距, <span class="arithmatex">\(b_{1}\)</span> 则称为回归系 数, 或更确切地, 称为 <span class="arithmatex">\(Y\)</span> 对 <span class="arithmatex">\(X\)</span> 的回归系数. <span class="arithmatex">\(e\)</span> 为随机误差,如在 6.1 节中已解释过的, 假定</p>
<div class="arithmatex">\[
E(e)=0,0&lt;\operatorname{Var}(e)=\sigma^{2}&lt;\infty
\]</div>
<p>误差方差 <span class="arithmatex">\(\sigma^{2}\)</span> 末知, 在 6.1 节中我们曾解释过这个参数的意义及其 重要性.</p>
<ul>
<li>286 • 现设对模型 (2.1) 中的变量 <span class="arithmatex">\(X, Y\)</span> 进行了 <span class="arithmatex">\(n\)</span> 次独立观察, 得样 本</li>
</ul>
<div class="arithmatex">\[
\left(X_{1}, Y_{1}\right),\left(X_{2}, Y_{2}\right), \cdots,\left(X_{n}, Y_{n}\right)
\]</div>
<p>据(2.1), 这样本的构造可由方程</p>
<div class="arithmatex">\[
Y_{i}=b_{0}+b_{1} X_{i}+e_{i}, i=1, \cdots, n
\]</div>
<p>来描述. 这里 <span class="arithmatex">\(e_{i}\)</span>, 是第 <span class="arithmatex">\(i\)</span> 次观察时随机误差 <span class="arithmatex">\(e\)</span> 所取之值, 它是不能 观察的. 由于各次观察独立及 (2.2) 对随机变量 <span class="arithmatex">\(e_{1}, e_{2}, \cdots, e_{n}\)</span>, 有:</p>
<p><span class="arithmatex">\(e_{1}, \cdots, e_{n}\)</span> 独立同分布，</p>
<div class="arithmatex">\[
E\left(e_{i}\right)=0, \operatorname{Var}\left(e_{i}\right)=\sigma^{2}, i=1, \cdots, n
\]</div>
<p>以后我们还将进一步要求 <span class="arithmatex">\(e_{i}\)</span> 遵从正态分布.</p>
<p>(2.4)与 (2.5)结合, 给出了样本 (2.3) 的概率性质. 它是对理 论模型 (2.1) 进行统计分析推断的依据. 以此之故, 在统计学著作 中, 往往更着重 (2.4) +(2.5), 把它称为一元线性回归模型, 而理 论模型 (2.1) 只起一个背景的作用. 当然, 理解 (2.4) 和 (2.5) 是以 理解 (2.1) 为基础的.</p>
<p>以上的叙述是假定, 回归函数已依据某种考虑选定了一在 此选为线性形式. 在实际工作中, 这当然是一个要研究的问题. 在 某种稀少的场合下, 回归函数的形式可根据某种理论上的结果给 出. 例如, 从物理学知道, 在一定温度 <span class="arithmatex">\((X)\)</span> 的范围内, 一条金属杆之 长 <span class="arithmatex">\((Y)\)</span> 大体上为 <span class="arithmatex">\(X\)</span> 的线性函数. 这时选择线性回归有充分根据. 在多数应用问题中, 不存在这样充分的理论根据, 而在很大的程度 上要依靠数据本身. 例如,若数据(2.3)的散点图呈图 6.1 的形状, 则选取线性回归函数似是妥当的.反之, 若散点图呈现图 6.2(a) 或 6.2(b)的形状,则回归函数似以取为二次多项式或指数函数为 宜. 在实际工作中, 也常使用变量变换法. 即在散点图与直线趋势 差距较大时, 设法对自变量以至因变量进行适当的变换, 使变换后 的散点图更接近于直线, 这样就可以对变换后的新变量进行线性 回归分析, 再回到原变量. 在一元的情况, 由于散点图可资参考, 在 回归函数的选择上就有较大的操作余地. 对多元 (多个自变量)的 情况,问题就麻烦得多,选择余地也较小.</p>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_f50f6ea83c00f0cb59edg-03.jpg?height=386&amp;width=480&amp;top_left_y=344&amp;top_left_x=457" /></p>
<p>(a)</p>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_f50f6ea83c00f0cb59edg-03.jpg?height=382&amp;width=459&amp;top_left_y=346&amp;top_left_x=1027" /></p>
<p>(b)</p>
<p>图 6.2</p>
<p>交代了这些之后, 我们回到起先的出发点- (2.4) 和(2.5). 今后总用 <span class="arithmatex">\(\bar{X}\)</span> 和 <span class="arithmatex">\(\bar{Y}\)</span> 分别记 <span class="arithmatex">\(X_{i}\)</span> 和 <span class="arithmatex">\(Y_{i}\)</span> 的算术平均. 以前我们曾指出: 把自变量 <span class="arithmatex">\(X\)</span> 视为非随机的,故 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span>, 以及 <span class="arithmatex">\(\bar{X}\)</span>, 就简单地是已 知常数. 因此, 可以把模型(2.4)改写为</p>
<div class="arithmatex">\[
Y_{i}=\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)+e_{i}, i=1, \cdots, n
\]</div>
<p>其关系是 :</p>
<div class="arithmatex">\[
\beta_{1}=b_{1}, \beta_{0}=b_{0}+b_{1} \bar{X}
\]</div>
<p>故如估计出了 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span>, 则由 (2.7) 就得到 <span class="arithmatex">\(b_{0}\)</span> 和 <span class="arithmatex">\(b_{1}\)</span> 的估计. 改写为 (2.6) 的好处将在以后见到. 这里注意到一点, 即 <span class="arithmatex">\(\beta_{1}\)</span> 后的因子 <span class="arithmatex">\(X_{i}-\bar{X}\)</span> 对 <span class="arithmatex">\(i=1, \cdots, n\)</span> 求和为 0 . 故把 (2.4) 改写为 <span class="arithmatex">\((2.6)\)</span> 有时称为 模型的“中心化”。</p>
<h3 id="01-1-beta_0-beta_1">0.1. 1 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span> 的点估计一最小二乘法<a class="headerlink" href="#01-1-beta_0-beta_1" title="Permanent link">⚓︎</a></h3>
<p>现在我们要在模型 (2.6) 和 (2.5)之下, 利用数据 (2.3) 去估计 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span>. 假定我们用 <span class="arithmatex">\(\alpha_{0}\)</span> 和 <span class="arithmatex">\(\alpha_{1}\)</span> 去估计 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span>. 我们要定出一个准 则, 以衡量由此所导致的偏差. 我们从预测的眼光来看这个问题, 如用 <span class="arithmatex">\(\alpha_{0}\)</span> 和 <span class="arithmatex">\(\alpha_{1}\)</span>, 则回归函数 <span class="arithmatex">\(\beta_{0}+\beta_{1}(x-\bar{X})\)</span> 将用 <span class="arithmatex">\(\alpha_{0}+\alpha_{1}(x-\bar{X})\)</span> 去 估计之. 利用它在 <span class="arithmatex">\(X_{i}\)</span> 点作预测, 结果为</p>
<div class="arithmatex">\[
\hat{Y}_{i}=\alpha_{0}+\alpha_{1}\left(X_{i}-\bar{X}\right), i=1, \cdots, n
\]</div>
<p>但我们已实际观察到: 在 <span class="arithmatex">\(X=X_{i}\)</span> 处 <span class="arithmatex">\(Y\)</span> 之取值为 <span class="arithmatex">\(Y_{i}\)</span>, 这样就有偏离 <span class="arithmatex">\(Y_{i}-\hat{Y}_{i}, i=1, \cdots, n\)</span>. 我们当然希望这些偏离愈小愈好: 衡量这些 偏离大小的-一个合理的单一指标为它们的平方和 (通过平方去掉 符号的影响, 著简单求和, 则正负偏离抵消了):</p>
<div class="arithmatex">\[
Q\left(\alpha_{0}, \alpha_{1}\right)=\sum_{i=1}^{n}\left(Y_{i}-\hat{Y}_{i}\right)^{2}=\sum_{i=1}^{n}\left[Y_{i}-\alpha_{0}-\alpha_{1}\left(X_{i}-\bar{X}\right)\right]^{2}
\]</div>
<p>甘此考虑得出以下的估计法则 : 找 <span class="arithmatex">\(\alpha_{0}, \alpha_{1}\)</span> 之值, 使 (2.9) 达到最小, 以之作为 <span class="arithmatex">\(\beta_{0}, \beta_{1}\)</span> 的估计. 利用多元函数求极值的方法, 这只要解方 程组</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \frac{\partial Q}{\partial \alpha_{0}}=-2 \sum_{i=1}^{n}\left(Y_{i}-\alpha_{0}-\alpha_{1}\left(X_{i}-\bar{X}\right)\right)=0 \\
&amp; \frac{\partial Q}{\partial \alpha_{1}}=-2 \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left[Y_{i}-\alpha_{0}-\alpha_{1}\left(X_{i}-\bar{X}\right)\right]=0
\end{aligned}
\]</div>
<p>山 (2.10) 解出 <span class="arithmatex">\(\alpha_{0}\)</span>, 将解代人 (2.11), 解出 <span class="arithmatex">\(\alpha_{1}\)</span>. 我们将这解分别记为 <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> :</p>
<div class="arithmatex">\[
\begin{aligned}
\hat{\beta}_{0} &amp; =\bar{Y} \\
\hat{\beta}_{1} &amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right) / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \\
&amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) Y_{i} / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
\end{aligned}
\]</div>
<p>“使 (2.9)达到最小”这个估计方法, 称为“最小二乘法”, 这个重要 的方法一般归功于德国大数学家高斯在 1799-1809 年间的工. 作* 这个方法在数理统计学中有广泛的应用. 其好处之一在于计 算简便, 且如我们即将看到的, 这方法导出的估计颇有些良好的性</p>
<ul>
<li>法国数学家勒让德于1 1805 年发表了这个方法. 高斯南称在 1799 乍开始使用这 个方法。但见诸文字是 1809 年. 质. 其中之一是, 如从公式 (2.12) 和 (2.13) 看到的, 估计量 <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 都是 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 的线性函数, 即形如 <span class="arithmatex">\(c_{n 1} Y_{1}+\cdots+c_{n n} Y_{n}\)</span> 的函 数, 其中 <span class="arithmatex">\(c_{n 1}, \cdots, c_{n n}\)</span> 都是常数 <span class="arithmatex">\({ }^{*}\)</span>.</li>
</ul>
<p>利用模型的假定 (2.6), (2.5)，从公式(2.12)和(2.13) 很容易 推出最小二乘估计 <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 的一些性质:</p>
<p><span class="arithmatex">\(1 . \hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 分别是 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span> 的无偏估计.</p>
<p>事实上, 由 (2.6) 和 (2.5), 知 <span class="arithmatex">\(E\left(Y_{i}\right)=\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)\)</span>. 故</p>
<div class="arithmatex">\[
\begin{aligned}
E\left(\hat{\beta}_{0}\right) &amp; =\frac{1}{n} \sum_{i=1}^{n} E\left(Y_{i}\right)=\frac{1}{n} \sum_{i=1}^{n}\left[\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right]=\beta_{0}\right. \\
E\left(\hat{\beta}_{1}\right) &amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) E\left(Y_{i}\right) / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \\
&amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left[\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)\right] / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \\
&amp; =\beta_{1}
\end{aligned}
\]</div>
<ol>
<li><span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 的方差分别为:</li>
</ol>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{Var}\left(\hat{\beta}_{0}\right) &amp; =\frac{1}{n^{2}} \sum_{i=1}^{n} \operatorname{Var}\left(Y_{i}\right)=n \sigma^{2} / n^{2}=\sigma^{2} / n \\
\operatorname{Var}\left(\hat{\beta}_{1}\right) &amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \operatorname{Var}\left(Y_{i}\right) /\left[\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\right]^{2} \\
&amp; =\sigma^{2} / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
\end{aligned}
\]</div>
<p>这里用到了 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 独立, <span class="arithmatex">\(\operatorname{Var}\left(c Y_{i}\right)=c^{2} \operatorname{Var}\left(Y_{i}\right), \operatorname{Var}\left(c+e_{i}\right)\)</span> <span class="arithmatex">\(=\operatorname{Var}\left(e_{i}\right)=\sigma^{2}, c\)</span> 为常数. 从 (2.15) 式我们得到一点启发. 在第四</p>
<ul>
<li>对 <span class="arithmatex">\(\vec{\beta}_{1}\)</span> 而言, 系数 <span class="arithmatex">\(c_{n 1}, \cdots, c_{n n}\)</span> 与样本值 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 有关. 但此处我们把 <span class="arithmatex">\(X\)</span> 视为非 随机的, 因此它不影响 <span class="arithmatex">\(c_{n 1}, \cdots, c_{n n}\)</span> 为常数这个论断. 若 <span class="arithmatex">\(X\)</span> 也是随机变量, 则情况就变得 复杂. 章中我们已论述过, 在无偏估计中, 方差小者为优, 如今 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 为无偏 估计而其方差与</li>
</ul>
<div class="arithmatex">\[
S_{x}^{2}=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
\]</div>
<p>成反比, 故 <span class="arithmatex">\(S_{x}^{2}\)</span> 愈大愈好. 而要 <span class="arithmatex">\(S_{x}^{2}\)</span> 大, 样本点 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 必须尽量 散开一些. 这意味着当 <span class="arithmatex">\(X\)</span> 之取值可以由我们选定时, 我们不应把 它们取在一小范围内, 而最好让它们跨越较大之范围. 当然, 这也 要有个限度, 不要把试验点取到没有实用意义的区域内去. 因为范 围过大,线性回归与实际回归函数的差距会增加.</p>
<ol>
<li><span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 的协方差为 0 :</li>
</ol>
<div class="arithmatex">\[
\operatorname{Cov}\left(\hat{\beta}_{0}, \hat{\beta}_{1}\right)=0
\]</div>
<p>事实上, <span class="arithmatex">\(\hat{\beta}_{0}-E\left(\hat{\beta}_{0}\right)=\sum_{i=1}^{n}\left(Y_{i}-E Y_{i}\right) / n=\sum_{i=1}^{n}\left(Y_{i}-\beta_{0}-\beta_{1}\left(X_{i}-\right.\right.\)</span> <span class="arithmatex">\(\bar{X})) / n=\sum_{i=1}^{n} e_{i} / n\)</span>, 而</p>
<div class="arithmatex">\[
\begin{aligned}
\hat{\beta}_{1}-E \hat{\beta}_{1} &amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(Y_{i}-E Y_{i}\right) / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \\
&amp; =\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) e_{i} / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
\end{aligned}
\]</div>
<p>于是, 利用 <span class="arithmatex">\(E\left(e_{i} e_{j}\right)=E\left(e_{i}\right) E\left(e_{j}\right)=0\)</span> 当 <span class="arithmatex">\(i \neq j\)</span>, 而 <span class="arithmatex">\(E\left(e_{i}^{2}\right)=\operatorname{Var}\left(e_{i}\right)\)</span> <span class="arithmatex">\(=\sigma^{2}\)</span>, 得</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{Cov}\left(\hat{\beta}_{0}, \hat{\beta}_{1}\right) &amp; =E\left[\left(\hat{\beta}_{0}-E \hat{\beta}_{0}\right)\left(\hat{\beta}_{1}-E \hat{\beta}_{1}\right)\right] \\
&amp; =n^{-1}\left[\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\right]^{-1} \sigma^{2} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)=0
\end{aligned}
\]</div>
<p>这个性质指出: <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 不相关 (见第三章, 定理 3.2 下面的 说明). 它显示了中心化的好处: 如果考虑原模型 (2.1) 中参数 <span class="arithmatex">\(b_{0}\)</span>, <span class="arithmatex">\(b_{1}\)</span> 的最小二乘估计 <span class="arithmatex">\(\hat{b}_{0}, \hat{b}_{1}\)</span> (见下), 则二者并非不相关. 由 <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 不相关一般不能推出它们独立(第三章例 3.1). 但是, 如果 <span class="arithmatex">\(e_{1}, \cdots, e_{n}\)</span> 服从正态分布，则 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 也服从正态分 布. <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 作为 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 的线性函数，也服从正态分布 * (第二. 章例 4.8). 因此在这种情况下, 由 <span class="arithmatex">\(\hat{\beta}_{0}, \hat{\beta}_{1}\)</span> 不相关可推出它们独立 (见第三章 2.3 节末尾).</p>
<p>由 <span class="arithmatex">\(\beta_{0}, \beta_{1}\)</span> 的最小二乘估计 <span class="arithmatex">\(\hat{\beta}_{0}, \hat{\beta}_{1}\)</span>, 通过变换 (2.7), 即得模型 (2.1) 中的 <span class="arithmatex">\(b_{0}, b_{1}\)</span> 的最小二乘佔计分别为</p>
<div class="arithmatex">\[
\hat{b}_{0}=\hat{\beta}_{0}-\hat{b}_{1} \bar{X}=\bar{Y}-\hat{b}_{1} \bar{X}, \hat{b}_{1}=\hat{\beta}_{1}
\]</div>
<p>它们分别是 <span class="arithmatex">\(b_{0}\)</span> 和 <span class="arithmatex">\(b_{1}\)</span> 的无偏估计. 利用上述 <span class="arithmatex">\(\hat{\beta}_{0}, \hat{\beta}_{1}\)</span> 的方差协方差 公式,不难算出 <span class="arithmatex">\(\hat{b}_{0}, \hat{b}_{1}\)</span> 的方差和 <span class="arithmatex">\(\hat{b}_{0}\)</span> 及 <span class="arithmatex">\(\hat{b}_{1}\)</span> 的协方差,细节留给 读者.</p>
<p><span class="arithmatex">\(\hat{\beta}_{0}, \hat{\beta}_{1}\)</span> 还有些更深刻的性质. 例如, 若误差服从正态分布,则 它们分别是 <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 的最小方差无偏估计 (见 4.3 节). 这个事实 的证明超出本书范围之外.</p>
<h3 id="02-2-sigma2">0.2. 2 残差与误差和方差 <span class="arithmatex">\(\sigma^{2}\)</span> 的估计<a class="headerlink" href="#02-2-sigma2" title="Permanent link">⚓︎</a></h3>
<p>仍以 <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 和 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 记 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span> 的最小二乘估计. 则在 <span class="arithmatex">\(X=X_{i}\)</span> 处, 因变量 <span class="arithmatex">\(Y\)</span> 的预测值为 <span class="arithmatex">\(\hat{Y}_{i}=\hat{\beta}_{0}+\hat{\beta}_{1}\left(X_{i}^{*}-\bar{X}\right)\)</span>, 陌 <span class="arithmatex">\(Y\)</span> 的实际观祭值 为 <span class="arithmatex">\(Y_{i}\)</span>, 二者之差</p>
<div class="arithmatex">\[
\delta_{i}=Y_{i}-\hat{Y}_{i}, i=1, \cdots, n
\]</div>
<p>称为“残差”.</p>
<p>残差的作用有二: 一是当模型正确时，即 (2.5) 和 (2.6) 正确</p>
<p>、更确切地, <span class="arithmatex">\(\left(\hat{\beta}_{1}, \hat{\beta}_{1}\right)\)</span> 的联合分住为…维正态分们. 时, 它可以提供误差方差 <span class="arithmatex">\(\sigma^{2}\)</span> 之一估计. 理由很清楚: 用 <span class="arithmatex">\(\hat{Y}_{i}\)</span> 预测 <span class="arithmatex">\(Y_{i}\)</span>, 其精度取决于随机误差的大小, 即误差方差的大小, 误差方差 愈大, 预测愈不易准确, 而残差 (绝对值) 就倾向于取大值. 反之则 倾向于取小值. 往下我们证明</p>
<div class="arithmatex">\[
\hat{\sigma}^{2}=\frac{1}{n-2} \sum_{i=1}^{n} \delta_{i}^{2}
\]</div>
<p>是 <span class="arithmatex">\(\sigma^{2}\)</span> 的一个无偏估计.</p>
<p>为证明这个事实,注意</p>
<div class="arithmatex">\[
Y_{i}-\hat{Y}_{i}=\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)+e_{i}-\hat{\beta}_{0}-\hat{\beta}_{1}\left(X_{i}-\bar{X}\right)
\]</div>
<p>以及</p>
<p><span class="arithmatex">\(\beta_{0}-\hat{\beta}_{0}=\beta_{0}-\bar{Y}=\beta_{0}-\frac{1}{n} \sum_{i=1}^{n}\left(\beta_{0}+\beta_{1}\left(X_{i}-\bar{X}\right)+e_{i}\right)=-\bar{e}\)</span> 其中 <span class="arithmatex">\(\bar{e}=\left(e_{1}+\cdots e_{n}\right) / n\)</span>, 而</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \beta_{1}-\hat{\beta}_{1} \\
= &amp; \beta_{1}-\sum_{j=1}^{n}\left(X_{j}-\bar{X}\right)\left(\beta_{0}+\beta_{1}\left(X_{j}-\bar{X}\right)+e_{j}\right) / \sum_{j=1}^{n}\left(X_{j}-\bar{X}\right)^{2} \\
= &amp; -\sum_{j=1}^{n}\left(X_{j}-\bar{X}\right) e_{j} / \sum_{j=1}^{n}\left(X_{j}-\bar{X}\right)^{2}
\end{aligned}
\]</div>
<p>故</p>
<div class="arithmatex">\[
\delta_{i}=e_{i}-\bar{e}-\left(X_{i}-\bar{X}\right) \sum_{j=1}^{n}\left(X_{j}-\bar{X}\right) e_{j} / \sum_{j=1}^{n}\left(X_{j}-\bar{X}\right)^{2}
\]</div>
<p>平方, 对 <span class="arithmatex">\(i=1, \cdots, n\)</span> 求和, 注意</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; \left.\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) \sum_{j=1}^{n}\left(X_{j}-\bar{X}\right) e_{j} / \sum_{j=1}^{n}\left(X_{j}-\bar{X}\right)^{2}\right]^{2} \\
= &amp; \left(\sum_{j=1}^{n}\left(X_{j}-\bar{X}\right) e_{j}\right)^{2} / \sum_{j=1}^{n}\left(X_{j}-\bar{X}\right)^{2} \\
&amp; \sum_{i=1}^{n}\left(e_{i}-\bar{e}\right)\left(X_{i}-\bar{X}\right)=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) e_{i}
\end{aligned}
\]</div>
<p>即得</p>
<div class="arithmatex">\[
\sum_{i=1}^{n} \delta_{i}^{2}=\sum_{i=1}^{n}\left(e_{i}-\bar{e}\right)^{2}-\left(\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) e_{i}\right)^{2} / \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
\]</div>
<p>因为 <span class="arithmatex">\(e_{1}, \cdots, e_{n}\)</span> 独立同分布, 有均值 0 方差 <span class="arithmatex">\(\sigma^{2}\)</span>, 故据第四章例 3.2 . 及第三章 <span class="arithmatex">\((2.2)\)</span> 式, 有</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; E\left(\sum_{i=1}^{n}\left(e_{i}-\bar{e}\right)^{2}\right)=(n-1) \sigma^{2} \\
&amp; E\left(\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) e_{i}\right)^{2}=\operatorname{Var}\left(\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) e_{i}\right) \\
&amp;=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \operatorname{Var}\left(e_{i}\right) \\
&amp;=\sigma^{2} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}
\end{aligned}
\]</div>
<p>以此代人(2.21), 即得</p>
<div class="arithmatex">\[
E\left(\sum_{i=1}^{n} \delta_{i}^{2}\right)=(n-2) \sigma^{2}
\]</div>
<p>于是证明了 <span class="arithmatex">\(\hat{\sigma}^{2}\)</span> 为 <span class="arithmatex">\(\sigma^{2}\)</span> 的无偏估计.</p>
<p><span class="arithmatex">\(\sum_{i=1}^{n} \delta_{i}^{2}\)</span> 称为残差平方和. 其一重要性质是: 当 <span class="arithmatex">\(e_{i}\)</span> 服从证态分布 <span class="arithmatex">\(N\left(0, \sigma^{2}\right)\)</span> 时, 有</p>
<div class="arithmatex">\[
\sum_{i=1}^{n} \delta_{i}^{2} / \sigma^{2}-\chi_{n-2}^{2}
\]</div>
<p>证明见本章附录 <span class="arithmatex">\(A\)</span>. 注意自由度 <span class="arithmatex">\(n-2\)</span>, 它比样本大小 <span class="arithmatex">\(n\)</span> 少 2 . 这是 因为有两个末知参数 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span> 需要估计, 用掉了两个自由度 (参看 第四章例 3.2 末尾处的说明).</p>
<p>残差平方和有下述便于计算的表达式:</p>
<div class="arithmatex">\[
\begin{aligned}
\sum_{i=1}^{n} \delta_{i}^{2} &amp; =\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}\right)^{2}-\hat{\beta}_{\mathrm{t}} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) Y_{i} \\
&amp; =\sum_{i=1}^{n} Y_{i}^{2}-n \bar{Y}^{2}-\hat{\beta}_{1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) Y_{i}
\end{aligned}
\]</div>
<p>此式之方便在于: 在计算残差平方和时,一般已先算出了回归系数 <span class="arithmatex">\(\beta_{1}\)</span> 的估计 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 及 <span class="arithmatex">\(\bar{Y}\)</span>. 而在算 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 时, 需要算出 <span class="arithmatex">\(\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) Y_{i}\)</span>, 故只 须再计算平方和 <span class="arithmatex">\(\sum_{i=1}^{n} Y_{i}^{2}\)</span> 即可. (2.23) 式证明如下:</p>
<div class="arithmatex">\[
\begin{aligned}
\sum_{i=1}^{n} \delta_{i}^{2} &amp; =\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}-\hat{\beta}_{1}\left(X_{i}-\bar{X}\right)\right)^{2} \\
&amp; =\sum_{i=1}^{n}\left(Y_{i}-\bar{Y}\right)^{2}-2 A+B
\end{aligned}
\]</div>
<p>其中 <span class="arithmatex">\(B=\hat{\beta}_{1}^{2} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}=\hat{\beta}_{1}\left(\hat{\beta}_{1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2}\right)=\hat{\beta}_{1} \sum_{i=1}^{n}\left(X_{i}-\right.\)</span> <span class="arithmatex">\(\bar{X}) Y_{i}\)</span> ，而</p>
<div class="arithmatex">\[
A=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)\left(Y_{i}-\bar{Y}\right) \hat{\beta}_{1}=\hat{\beta}_{1} \sum_{i=1}^{n}\left(X_{i}-\bar{X}\right) Y_{i}
\]</div>
<p>于是得到(2.23)第一式. 由此得出第二式.</p>
<p>残差的另一方面的作用是用以考察模 型中的假定 (即 (2.5) 和 (2.6)) 是否正确. 道理如下: 因为在模型正确时,残差是误差 的一种反映,因误差 <span class="arithmatex">\(e_{1}, \cdots, e_{n}\)</span> 为独立同分 布, 具有“杂乱无章”的性质, 即不应呈现任 何规律性. 因此,残差 <span class="arithmatex">\(\delta_{1}, \cdots, \delta_{n}\)</span> 也应如此. 如果残差 <span class="arithmatex">\(\delta_{1}, \cdots, \delta_{n}\)</span> 呈现出某种规律性,则</p>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_f50f6ea83c00f0cb59edg-10.jpg?height=369&amp;width=466&amp;top_left_y=1483&amp;top_left_x=1246" /></p>
<p>图 6.3 可能是模型中某方面假定与事实不符的征 兆.例如, 若随着 <span class="arithmatex">\(X_{i}\)</span> 增大 <span class="arithmatex">\(\left|\delta_{i}\right|\)</span> 有上升的趋势, 这可能反映模型 (2.1) 中误差 <span class="arithmatex">\(e\)</span> 的方差与 <span class="arithmatex">\(X\)</span> 之值有关且随 <span class="arithmatex">\(X\)</span> 之值上升而增加. 又 如,设想回归函数为二次函数, 则由图 6.3 ( <span class="arithmatex">\(l\)</span> 为经验回归直线) 可 看出, 当 <span class="arithmatex">\(X_{i}\)</span> 很大或很小时, <span class="arithmatex">\(\delta_{i}\)</span> 取正号, 而当 <span class="arithmatex">\(X_{i}\)</span> 为中间值时, <span class="arithmatex">\(\delta_{i}\)</span> 取 负号.如出现这种情况，就可以怀疑线性假定有问题.</p>
<p>这种通过残差去考察回归模型是否正确的作法, 叫做“回归诊 断”. 它已发展为回归分析的一个分支. 本书不能仔细讨论这方面 的问题, 有兴趣的读者可参考陈希瓀、王松桂著《近代回归分析》第 -二章, 及张启锐著《实用回归分析》第四章.</p>
<h3 id="03-3">0.3. 3 区间估计和预测<a class="headerlink" href="#03-3" title="Permanent link">⚓︎</a></h3>
<p>本段我们在 (2.5) 和(2.6) 的基础上加上假定: 误差 <span class="arithmatex">\(e\)</span> 服从正 态分布, 因此, 现在 (2.5) 强化为</p>
<div class="arithmatex">\[
e_{1}, e_{2}, \cdots, e_{n} \text { 独立同分布. } e_{i} \sim N\left(0, \sigma^{2}\right)
\]</div>
<p>先考虑 <span class="arithmatex">\(\hat{\beta}_{1}\)</span>. 前已指出, 它是 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 的线性函数, 有均值 <span class="arithmatex">\(\beta_{1}\)</span> 方差 <span class="arithmatex">\(\sigma^{2} S_{x}^{-2}, S_{x}^{2}\)</span> 见(2.16)式,因此</p>
<div class="arithmatex">\[
\left(\hat{\beta}_{1}-\beta_{1}\right) /\left(\hat{\sigma} S_{x}^{-1}\right) \sim N(0,1)
\]</div>
<p>这个结果尚不能用于 <span class="arithmatex">\(\beta_{1}\)</span> 的区间估计, 因为 <span class="arithmatex">\(\sigma\)</span> 末知, 按 6.2 .2 的结 果, 以 <span class="arithmatex">\(\hat{\sigma}\)</span> (见 2.20) 代替 (2.25) 中的 <span class="arithmatex">\(\sigma\)</span>. 可以证明, 经过这一代替, 正 态分布变为 <span class="arithmatex">\(t\)</span> 分布 (证明见附录 <span class="arithmatex">\(B\)</span> )</p>
<div class="arithmatex">\[
\left(\hat{\beta}_{1}-\beta_{1}\right) /\left(\hat{\sigma} S_{x}^{-1}\right) \sim t_{n-2}
\]</div>
<p>这个结果就可以用来作 <span class="arithmatex">\(\beta_{1}\)</span> 的区间估计或置信上、下界, 因为 <span class="arithmatex">\(\left(\hat{\beta}_{1}-\right.\)</span> <span class="arithmatex">\(\left.\beta_{1}\right) /\left(\hat{\sigma} S_{x}^{-1}\right)\)</span> 起了枢轴变量的作用, 按 4.4 节中的方法, 得到:</p>
<ol>
<li>置信系数为 <span class="arithmatex">\(1-\alpha\)</span> 的 <span class="arithmatex">\(\beta_{1}\)</span> 的置信区间, 为</li>
</ol>
<div class="arithmatex">\[
\left[\hat{\beta}_{1}-\hat{\sigma} S_{x}^{-1} t_{n-2}(\alpha / 2), \hat{\beta}_{1}+\hat{\sigma} S_{x}^{-1} t_{n-2}(\alpha / 2)\right]
\]</div>
<ol>
<li>置信系数为 <span class="arithmatex">\(1-\alpha\)</span> 的 <span class="arithmatex">\(\beta\)</span> 的置信上、下界, 分别为</li>
</ol>
<div class="arithmatex">\[
\hat{\beta}_{1}+\hat{\sigma} S_{x}^{-1} t_{n-2}(\alpha) \text { 和 } \hat{\beta}_{1}-\hat{\sigma} S_{x}^{-1} t_{n-2}(\alpha)
\]</div>
<p>对截距 <span class="arithmatex">\(\beta_{0}\)</span> 也一样做,也可以由下文对回归函数 <span class="arithmatex">\(\beta_{0}+\beta_{1}(x-\bar{X})\)</span> 的 区间估计中,令 <span class="arithmatex">\(x=\bar{X}\)</span> 得到。</p>
<p>对回归函数 <span class="arithmatex">\(m(x)=\beta_{0}+\beta_{1}(x-\bar{X})\)</span>, 其点估计 <span class="arithmatex">\(\hat{m}(x)=\hat{\beta}_{0}+\)</span> <span class="arithmatex">\(\hat{\beta}_{1}(x-\bar{X})\)</span> 也是 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 的线性函数，因此在 <span class="arithmatex">\((2.24)\)</span> 的假定下, 它也服从正态分布, 其均值为 <span class="arithmatex">\(m(x)\)</span>, 而其方差 <span class="arithmatex">\(\lambda(x)\)</span>, 根据 <span class="arithmatex">\((2.24),(2.25)\)</span>, 及 <span class="arithmatex">\(\hat{\beta}_{0}\)</span> 与 <span class="arithmatex">\(\hat{\beta}_{1}\)</span> 独立, 为</p>
<div class="arithmatex">\[
\begin{aligned}
\lambda(x) &amp; =\operatorname{Var}\left(\hat{\beta}_{0}\right)+(x-\bar{X})^{2} \operatorname{Var}\left(\hat{\beta}_{1}\right) \\
&amp; =\sigma^{2}\left(1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)
\end{aligned}
\]</div>
<p>于是得到 <span class="arithmatex">\((\hat{m}(x)-m(x)) / \sqrt{\lambda(x)} \sim N(0,1)\)</span>. <span class="arithmatex">\(\hat{\sigma}\)</span> 代 <span class="arithmatex">\(\sigma\)</span>, 可以证明</p>
<div class="arithmatex">\[
(\hat{m}(x)-m(x)) /\left(\hat{\sigma}\left(1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2}\right) \sim t_{n-2}
\]</div>
<p>由此得出:</p>
<ol>
<li>置信系数为 <span class="arithmatex">\(1-\alpha\)</span> 的 <span class="arithmatex">\(m(x)\)</span> 的置信区间为</li>
</ol>
<div class="arithmatex">\[
\begin{aligned}
&amp; {\left[\hat{m}(x)-\hat{\sigma}\left(1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2} t_{n-2}(\alpha / 2)\right.} \\
&amp; \left.\hat{m}(x)+\hat{\sigma}\left(1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2} t_{n-2}(\alpha / 2)\right]
\end{aligned}
\]</div>
<ol>
<li>置信系数为 <span class="arithmatex">\(1-\alpha\)</span> 的 <span class="arithmatex">\(m(x)\)</span> 的置信上下界, 分别为 <span class="arithmatex">\(\hat{m}(x) \pm\)</span> <span class="arithmatex">\(\hat{\sigma}\left(1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2} t_{n-2}(\alpha)\)</span> (+号为上界).</li>
</ol>
<p>这个区间之长 <span class="arithmatex">\(2 \hat{\sigma}\left(1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2} t_{n-2}(\alpha / 2)\)</span> 与 <span class="arithmatex">\(x\)</span> 有 关. <span class="arithmatex">\(x\)</span> 愈接近 <span class="arithmatex">\(X\)</span> 样本的中心 <span class="arithmatex">\(\bar{X}\)</span>, 则 <span class="arithmatex">\((x-\bar{X})^{2}\)</span> 愈小而区间长度就愈 小. 就是说, 在估计回归函数 <span class="arithmatex">\(m(x)\)</span> 时, 愈靠近样本 <span class="arithmatex">\(X\)</span> 中心点处愈 精确. 这从理论上指明了我们在前面提到过的一点事实: 当我们需 要在自变量 <span class="arithmatex">\(X\)</span> 的某个范围内使用回归方程时, 应当把观察点 <span class="arithmatex">\(X_{1}\)</span>, <span class="arithmatex">\(\cdots, X_{n}\)</span> 尽量取在这个范围内. 如 图 <span class="arithmatex">\(6.4, l\)</span> 为由样本点配出的经验 回归直线, <span class="arithmatex">\(l_{1}\)</span> 和 <span class="arithmatex">\(l_{2}\)</span> 分别是 <span class="arithmatex">\(m(x)\)</span> 的置信区间上、下端随 <span class="arithmatex">\(x\)</span> 变化时 划出的曲线. 在 <span class="arithmatex">\(x\)</span> 轴上的 <span class="arithmatex">\(\bar{X}\)</span> 附近 <span class="arithmatex">\(l_{1}\)</span> 和 <span class="arithmatex">\(l_{2}\)</span> 相距较近, 而当 <span class="arithmatex">\(x\)</span> 离 <span class="arithmatex">\(\bar{X}\)</span> 愈远时, 曲线愈分开. 如图, 在 <span class="arithmatex">\(x\)</span> 轴的 <span class="arithmatex">\(x_{0}\)</span> 处, <span class="arithmatex">\(A\)</span> 点的纵坐标是回</p>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_f50f6ea83c00f0cb59edg-12.jpg?height=574&amp;width=662&amp;top_left_y=1912&amp;top_left_x=1048" />
归函数 <span class="arithmatex">\(m\left(x_{0}\right)\)</span> 的点估计 <span class="arithmatex">\(\hat{m}\left(x_{0}\right)\)</span>, 而 <span class="arithmatex">\(A_{1}, A_{2}\)</span> 点的纵坐标, 则分别是 <span class="arithmatex">\(m\left(x_{0}\right)\)</span> 的置信区间的上、下两端点. 曲线 <span class="arithmatex">\(l_{1}, l_{2}\)</span> 只能在这个意义上 去理解, 而不能说, “理论回归直线落在 <span class="arithmatex">\(l_{1}, l_{2}\)</span> 之间”的概率为 <span class="arithmatex">\(1-\)</span> <span class="arithmatex">\(\alpha\)</span>. 因为, 理论回归直线落在 <span class="arithmatex">\(l_{1}, l_{2}\)</span> 之间, 相当于说对一切 <span class="arithmatex">\(x_{0}\)</span> 同时 成立: <span class="arithmatex">\(m\left(x_{0}\right)\)</span> 落在通过 <span class="arithmatex">\(x_{0}\)</span> 与纵轴平行的直线在 <span class="arithmatex">\(l_{1}, l_{2}\)</span> 截出的两点 的纵坐标之间 <span class="arithmatex">\({ }^{*}\)</span>.</p>
<p>下面来考察 <span class="arithmatex">\(Y\)</span> 的区间预报. 假定要在自变量 <span class="arithmatex">\(X\)</span> 的给定值 <span class="arithmatex">\(x_{0}\)</span> 处预报 <span class="arithmatex">\(Y\)</span> 之值 <span class="arithmatex">\(Y_{0}\)</span>. 前已说过 (见 6.1 节), 就用 <span class="arithmatex">\(\hat{m}\left(x_{0}\right)\)</span> 作为 <span class="arithmatex">\(Y_{0}\)</span> 的 预报值. 考虑差 <span class="arithmatex">\(\eta=Y_{0}-\hat{m}\left(x_{0}\right)\)</span>. 它是 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 和 <span class="arithmatex">\(Y_{0}\)</span> 的线性函 数, 故仍为正态分布. 因 <span class="arithmatex">\(E\left(Y_{0}\right)=m\left(x_{0}\right), E\left[\hat{m}\left(x_{0}\right)\right]=m\left(x_{0}\right)\)</span>, 有 <span class="arithmatex">\(E(\eta)=0\)</span>. 为考虑其方差, 注意 <span class="arithmatex">\(Y_{1}, \cdots, Y_{n}\)</span> 和 <span class="arithmatex">\(Y_{0}\)</span> 独立, 故 <span class="arithmatex">\(\hat{m}\left(x_{0}\right)\)</span> 与 <span class="arithmatex">\(Y_{0}\)</span> 也独立, 因此有</p>
<div class="arithmatex">\[
\begin{aligned}
\operatorname{Var}(\eta) &amp; =\operatorname{Var}\left(Y_{0}\right)+\operatorname{Var}\left(\hat{m}\left(x_{0}\right)\right) \\
&amp; =\sigma^{2}\left(1+1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)
\end{aligned}
\]</div>
<p>仿以前的做法,用 <span class="arithmatex">\(\sigma\)</span> 的估计值 <span class="arithmatex">\(\hat{\sigma}\)</span> 代替 <span class="arithmatex">\(\sigma\)</span>, 得</p>
<div class="arithmatex">\[
\eta /\left(\hat{\sigma}\left(1+1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2}\right) \sim t_{n-2}
\]</div>
<p>于是得到:不等式</p>
<div class="arithmatex">\[
\begin{gathered}
\hat{m}\left(x_{0}\right)-\hat{\sigma}\left(1+1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2} t_{n-2}\left(\frac{\alpha}{2}\right) \leqslant Y_{0} \\
\leqslant \hat{m}\left(x_{0}\right)+\hat{\sigma}\left(1+1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2} t_{n-2}\left(\frac{\alpha}{2}\right)
\end{gathered}
\]</div>
<p>其左右两端 (所构造的区间) 就是 <span class="arithmatex">\(Y_{0}\)</span> 的置信系数为 <span class="arithmatex">\(1-\alpha\)</span> 的区间 预测. 应注意的是: 与以前我们讲过的区间估计不同,此处的 <span class="arithmatex">\(Y_{0}\)</span> 并不是一个末知的参数, 其本身也有随机性.</p>
<ul>
<li>理论上可以证明:把 <span class="arithmatex">\(l_{1}, l_{2}\)</span> 之间夹出的区域放大一点, 即把 <span class="arithmatex">\(l_{1}\)</span> 往上推一点, <span class="arithmatex">\(l_{2}\)</span> 往 下推一点, 就可以满足这要求, 具体说, 应以方程为 <span class="arithmatex">\(y=\hat{m}(x) \pm \hat{\sigma}\left(1 / n+(x-\bar{X})^{2} S_{x}^{2}\right)\)</span> <span class="arithmatex">\(\left(2 F_{2, n} \cdot 2(\alpha)\right)^{\frac{1}{2}}\)</span> 的曲线代替 <span class="arithmatex">\(l_{1}, l_{2}\left(l_{1}\right.\)</span> 为 + 号 <span class="arithmatex">\()\)</span>. 由第二章习题 29 可知, 这个范围比 (2.28) 规定的范围宽一些. 比较 (2.27) 和 (2.28), 我们看出 <span class="arithmatex">\(m\left(x_{0}\right)\)</span> 的区间估计与 <span class="arithmatex">\(Y_{0}\)</span> 的 区间预测的另一点不同之处: <span class="arithmatex">\(m\left(x_{0}\right)\)</span> 的区间估计之长为 <span class="arithmatex">\(2 \hat{\sigma}(1 / n\)</span> <span class="arithmatex">\(\left.+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2} t_{n-2}(\alpha / 2)\)</span>. 当 <span class="arithmatex">\(n\)</span> 很大时, <span class="arithmatex">\(\hat{\sigma}\)</span> 接近于 <span class="arithmatex">\(\sigma, t_{n-2}\)</span> ( <span class="arithmatex">\(\alpha / 2)\)</span> 接近 <span class="arithmatex">\(u_{\alpha / 2}\)</span>, 这两部分保持有界 <span class="arithmatex">\({ }^{*}\)</span>, 另一个因子中, <span class="arithmatex">\(1 / n \rightarrow 0\)</span>. 另 一个因子, 只要试验点 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 不过分集中于一处, 以使 <span class="arithmatex">\(\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} \rightarrow \infty\)</span>, 就可以证明 <span class="arithmatex">\((x-\bar{X})^{2} / S_{x}^{2} \rightarrow 0(\)</span> 习题 <span class="arithmatex">\(5(\mathrm{~b}))\)</span>. 这 样, 上述区间之长将随 <span class="arithmatex">\(n \rightarrow \infty\)</span> 而趋于 <span class="arithmatex">\(0 . Y_{0}\)</span> 的区间预测则不然, 其长度表达式中含因子 <span class="arithmatex">\(\left(1+1 / n+(x-\bar{X})^{2} / S_{x}^{2}\right)^{1 / 2}\)</span>. 随着 <span class="arithmatex">\(n \rightarrow\)</span> <span class="arithmatex">\(\infty\)</span>, 其值总大于 1 , 故不论你有多少样本, 区间预测的精度㐺有一 个界限，这个道理我们在前面已解释过: 预测问题中包含了一个无 法克服的随机误差项.</li>
</ul>
<h2 id="1-2-4">1. 2 .4 假设检验<a class="headerlink" href="#1-2-4" title="Permanent link">⚓︎</a></h2>
<p>最有兴趣的假设检验问题是: 检验原假设</p>
<div class="arithmatex">\[
H_{0}: \beta_{1}=c
\]</div>
<p>其中 <span class="arithmatex">\(c\)</span> 是一个给定的常数, 对立假设为 <span class="arithmatex">\(H_{0} \vdots \beta_{1} \neq c\)</span>. 尤其是 <span class="arithmatex">\(c=0\)</span> 的 情况. 因为, <span class="arithmatex">\(\beta_{1}=0\)</span> 表示回归函数 <span class="arithmatex">\(m(x)\)</span> 为一常数 <span class="arithmatex">\(\beta_{0}\)</span>, 与 <span class="arithmatex">\(x\)</span> 无关. 如 果 <span class="arithmatex">\(H_{0}: \beta_{1}=0\)</span> 被接受了, 则意味着我们接受如下的说法: 所选定的 自变量 <span class="arithmatex">\(X\)</span> 其实对因变量 <span class="arithmatex">\(Y\)</span> 无影响,故研究二者之间的关系也就没 有意义了。</p>
<p>(2.29)的检验很容易利用 (2.26) 作出:</p>
<p><span class="arithmatex">\(\varphi\)</span> : 当 <span class="arithmatex">\(\left|\hat{\beta}_{1}-c\right| \leqslant \hat{\sigma} S_{x} t_{n-2}(\alpha / 2)\)</span> 时接受 <span class="arithmatex">\(H_{0}\)</span>, 不然就否定 <span class="arithmatex">\(H_{0}\)</span></p>
<p>这个检验 <span class="arithmatex">\(\varphi\)</span> 有水平 <span class="arithmatex">\(\alpha\)</span>. 单边假设 <span class="arithmatex">\(\beta_{1} \leqslant c\)</span>, 或 <span class="arithmatex">\(\beta_{1} \geqslant c\)</span> 的检验地类似地 作出.</p>
<ul>
<li>由于 <span class="arithmatex">\(\hat{\sigma}\)</span> 是随机的, 它只是在“䧇櫭率收敛”的意义上接近 <span class="arithmatex">\(\sigma\)</span>, 故 <span class="arithmatex">\(\hat{\sigma}\)</span> 也有很小的可能 性远远偏离 <span class="arithmatex">\(\sigma\)</span>,甚至变得很大. 只是当 <span class="arithmatex">\(n\)</span> 很大时这种机会很小. 对截距 <span class="arithmatex">\(\beta_{0}\)</span> 的检验也类似地作出. 例如, <span class="arithmatex">\(\beta_{0}=0\)</span> 的假设意味着 回归直线通过原点,我们把细节留给读者.</li>
</ul>
<p>例 1.1 从某大学男生中随机抽取 10 名,测得其身高(米)和 体重 (公斤) 的数值为</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; (1.71,65),(1.63,63),(1.84,70),(1.90,75),(1.58,60) \\
&amp; (1.60,55),(1.75,64),(1.78,69),(1.80,65),(1.64,58)
\end{aligned}
\]</div>
<p>以身高 <span class="arithmatex">\(X\)</span> 为自变量, 并把它看成非随机的,而以体重 <span class="arithmatex">\(Y\)</span> 为因变 量. 假定回归为线性的. 算出</p>
<div class="arithmatex">\[
\begin{aligned}
\bar{X}= &amp; (1.71+1.63+\cdots+1.64) / 10=1.723 \\
\bar{Y}= &amp; (65+63+\cdots+58) / 10=64.4 \\
S_{x}^{2}= &amp; (1.71-1.723)^{2}+\cdots+(1.64-1.723)^{2} \\
= &amp; 0.1062 \\
\sum_{i=1}^{10} &amp; \left(X_{i}-\bar{X}\right) Y_{i}=(1.71-1.723) \times 65+\cdots \\
&amp; +(1.64-1.723) \times 58=5.268
\end{aligned}
\]</div>
<p>由 (2.12), (2.13), 得出 <span class="arithmatex">\(\beta_{0}\)</span> 和 <span class="arithmatex">\(\beta_{1}\)</span> 的最小二乘估计值分别为</p>
<div class="arithmatex">\[
\hat{\beta}_{0}=64.4, \hat{\beta}_{1}=5.268 / 0.1062=49.6
\]</div>
<p>经验回归方程为</p>
<div class="arithmatex">\[
y=64.4-49.6(x-1.723)=-21.06+49.6 x
\]</div>
<p>当 <span class="arithmatex">\(x=1.62\)</span> 时 <span class="arithmatex">\(Y=59.29\)</span>. 这有两个解释, 一是对身高为 1.62 米 的学生, 其平均体重的点估计为 59.29 公厅; 二是如随机抽到一个 学生量出其身高为 1.62 米, 则以 59.29 公斤为其体重的预测值.</p>
<p>可按 (2.23) 式计算残差平方和. 为此算出</p>
<div class="arithmatex">\[
\sum_{i=1}^{10}\left(Y_{i}-\bar{Y}\right)^{2}=(65-64.4)^{2}+\cdots+(58-64.4)^{2}=316.4
\]</div>
<p>因此按 (2.23)式算出</p>
<div class="arithmatex">\[
\sum_{i=1}^{10} \delta_{i}^{2}=316.4-49.6 \times 5.268=54.39
\]</div>
<p>由此得出误差方差 <span class="arithmatex">\(\sigma^{2}\)</span> 的估计值</p>
<div class="arithmatex">\[
\hat{\sigma}^{2}=54.39 /(10-2)=6.799, \hat{\sigma}=2.61
\]</div>
<p>取 <span class="arithmatex">\(\alpha=0.05\)</span>. 查 <span class="arithmatex">\(t\)</span> 分布表, 得 <span class="arithmatex">\(t_{n-2}(\alpha / 2)=t_{8}(0.025)=2.306\)</span></p>
<p>于是用 (2.27) 和 (2.28), 得到回归函数 <span class="arithmatex">\(m(x)=\beta_{0}+\beta_{1}(x-\)</span> <span class="arithmatex">\(\bar{X}\)</span> 的置信区间, 以及在 <span class="arithmatex">\(x\)</span> 点处 <span class="arithmatex">\(Y\)</span> 的取值 <span class="arithmatex">\(y\)</span> 的预测区间, 分别为 (置信系数都是 0.95 )</p>
<p><span class="arithmatex">\(-21.06+49.6 x-2.61\left(0.1+\frac{(x-1.723)^{2}}{0.1062}\right)^{1 / 2} \times 2.306 \leqslant m(x)\)</span></p>
<p><span class="arithmatex">\(\leqslant-21.06+49.6 x+2.61\left(0.1+\frac{(x-1.723)^{2}}{0.1062}\right)^{1 / 2} \times 2.306\)</span> 以及</p>
<p><span class="arithmatex">\(-21.06+49.6 x-2.61\left(1.1+\frac{(x-1.723)^{2}}{0.1062}\right)^{1 / 2} \times 2.306 \leqslant y\)</span></p>
<p><span class="arithmatex">\(\leqslant-21.06+49.6 x+2.61\left(1.1+\frac{(x-1.723)^{2}}{0.1062}\right)^{1 / 2} \times 2.306\)</span> 对 <span class="arithmatex">\(x=1.62\)</span>,上述两个区间分别是</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; -21.06+49.6 x \times 1.62 \pm 2.691=[56.6,62.0] \\
&amp; -21.06+49.6 x \times 1.62 \pm 6.343=[53.0,65.6]
\end{aligned}
\]</div>
<p>可见, 预测的精度比估计回归函数的精度差得多.</p>
<p>再考虑假设 (2.29) 的检验. 在此例中, 取 <span class="arithmatex">\(c=0\)</span> 是没有意义的. 因为体重明摆着与身高有关, 如检验假设 <span class="arithmatex">\(\beta_{1}=0\)</span>, 即使接受了, 我 们也只能归因于样本大小 <span class="arithmatex">\(n\)</span> 太小, 也不大会认为 <span class="arithmatex">\(\beta_{1}=0\)</span> 真可以被 接受. 可以考虑的假设是 <span class="arithmatex">\(c\)</span> 取一个合理的数字, 例如 <span class="arithmatex">\(c=50,40\)</span> 之 类. “ <span class="arithmatex">\(c=50\)</span> ”这个假设可理解为:在另一城市一所大学曾作过较大 规模的测量, 在那里比较确切地估出 <span class="arithmatex">\(\beta_{1}=50\)</span>. 现在换了一个城市, 情况有无改变? 由于这样一种提法, 且 50 这个数字先天地有一定 的根据, 在并无比较显著的证据的情况下, 我们不愿轻易地认为 50 这个数字不适用于这间大学. 因此, 取一个较小的水平, 例如 <span class="arithmatex">\(\alpha\)</span> <span class="arithmatex">\(=0.05\)</span>, 就要算比较恰当了. 具体检验可按 <span class="arithmatex">\((2.30)\)</span>. 算出</p>
<div class="arithmatex">\[
\hat{\sigma} S_{x} t_{n-2}(\alpha / 2)=2.61 \times \sqrt{0.1062} \times 2.306=1.96
\]</div>
<p>令 <span class="arithmatex">\(\left|\hat{\beta}_{1}-c\right|=|49.6-50|=0.4&lt;1.96\)</span>, 故应接受原假设 <span class="arithmatex">\(\beta_{1}=50\)</span>. 如原假设为 <span class="arithmatex">\(\beta_{1}=52\)</span>, 则被否定了.</p>
<p>现在有这样的问题: 一方面用我们的数据估出 <span class="arithmatex">\(\beta_{1}\)</span> 为 49.6 , 另 一方面, 按以往资料可以接纳 <span class="arithmatex">\(\beta_{1}=50\)</span>, 应取何者为好? 这就要分 析情况，如果以往资料可以认为是与当前资料同质的, 比方说, 两 校都是在全国范围招生,其学生的地域构成大体接近,则有充分理 由认为, 当前的 <span class="arithmatex">\(\beta_{1}\)</span> 与以往的 <span class="arithmatex">\(\beta_{1}\)</span> 应差不多. 考虑到以往的 <span class="arithmatex">\(\beta_{1}\)</span> 是依 据大量数据算出, 而当前的 <span class="arithmatex">\(\beta_{1}\)</span> 只根据 10 个数据, 我们觉得, 取以 往的 <span class="arithmatex">\(\beta_{1}\)</span> 也许更合适 (如果 <span class="arithmatex">\(\beta_{1}=50\)</span> 被否定, 自又当别论). 反之, 如 两校都是地方性的, 其学生来源以本地居多, 而两地身高体重在关 系上又有差别,则我们就可能倾向于采用当前值了.</p>
<p>这个例子也许并不十分典型, 但有关的考虑对其他应用问题 也是适用的. 统计学是一种帮助我们对数据进行分析的工具, 其应 用不能脱离对实际问题的背景的考虑. 不加区别地机械地使用公 式,难免导致与实际背离的结果.</p>
<h3 id="11-5">1.1. 5 几个有关问题<a class="headerlink" href="#11-5" title="Permanent link">⚓︎</a></h3>
<p>以上我们对一元线性回归(且随机误差服从正态分布的情况) 的统计分析作了较仔细的论述. 在这一段中, 我们提出几点在使用 这些方法时值得注意的事情.</p>
<ol>
<li>回归系数的解释问题</li>
</ol>
<p>设想我们建立了回归方程</p>
<div class="arithmatex">\[
y=a+b x
\]</div>
<p>一般地把回归系数 <span class="arithmatex">\(b\)</span> 的意义解释为: 当自变量 <span class="arithmatex">\(X\)</span> 增加或减少 1 单 位时,平均地说, <span class="arithmatex">\(Y\)</span> 增加或减少 <span class="arithmatex">\(b\)</span> 单位. 这个解释对不对? 我们 说,也对也不对,要看具体情况而定.</p>
<p>首先一个问题是 <span class="arithmatex">\(X\)</span> 的变化区间, 在实际应用中,真正的回归 方程一般总是与线性方程有一定的偏离. 在不很大的范围内,这种 偏离也许不很大, 不致对应用造成影响。一般总是在这个意义上, 我们把回归方程认定为线性的.</p>
<p>日后在应用中,如果自变量值 <span class="arithmatex">\(x\)</span> 超出了上述范围,则回归方 程 (2.31) 可能已不再成立. 这时 <span class="arithmatex">\(X\)</span> 增加 1 单位是否使 <span class="arithmatex">\(Y\)</span> 平均增 加 <span class="arithmatex">\(b\)</span> 单位的论断, 也就不能成立了. 例如, 若 <span class="arithmatex">\(X\)</span> 为每亩施肥量而 <span class="arithmatex">\(Y\)</span> 为每亩的产量. 可以相信, 在 <span class="arithmatex">\(X\)</span> 的一个合理的范围内, <span class="arithmatex">\(Y\)</span> 的平均值 大致随 <span class="arithmatex">\(X\)</span> 线性地增长. 但一超出一定的范围, 例如施肥量过大时, 进一步增加施肥不仅不能导致增产, 反而可能导致减产.</p>
<p>就是自变量之值处在合理的范围内时, 回归系数意义的解释 仍可能有问题. 分两种情况来讨论.一种情况是 <span class="arithmatex">\(X\)</span> 之值在试验中 可由人指定 (如上述施肥量). 这时, 只要在日后的应用中情况与你 建立回归方程时大体相同一一这主要指的是 <span class="arithmatex">\(X\)</span> 以外的因素对 <span class="arithmatex">\(Y\)</span> 的影响要相当, 则上述解释, 即 <span class="arithmatex">\(X\)</span> 增减 1 单位时 <span class="arithmatex">\(Y\)</span> 平均增减 <span class="arithmatex">\(b\)</span> 单 位, 是正确的, 否则就不见得正确. 仍拿上面那个例子来说, 设想在 建立方程 (2.31) 而进行的试验中, 所用的田地都是底肥很不充足 的, 而日后你把它用到底肥很充足的田地上; 或者, 在试验中用的 是深耕 (这对肥料吸收有利), 而日后用到浅耕的田地上, 则结果就 不见得正确了.</p>
<p>如果自变量 <span class="arithmatex">\(X\)</span> 是与 <span class="arithmatex">\(Y\)</span> 一起观察所得, 而不能事先由人控制, 则情况更加复杂. 在这种情况下, 除了满足 <span class="arithmatex">\(X\)</span> 必须处在合理范围 内这个限制外，还必须注意， <span class="arithmatex">\(X\)</span> 值必须是在“自然而然地”产生而 不是人为地制造出来的情况下, 上述解释才有效。举一个极端的例 子. 设把 <span class="arithmatex">\(X\)</span> 作为体重而 <span class="arithmatex">\(Y\)</span> 作为身高, 则在 <span class="arithmatex">\(X\)</span> 一定的范围内, 仍可 建立线性回归方程 (2.31), 比方说, <span class="arithmatex">\(\dot{b}=0.02\)</span>. 这意味着体重每增 减 1 公斤, 身高平均约增长 2 厘米. 假如你观察一个正在长身体的 青年人, 在某时刻你量得他体重 <span class="arithmatex">\(X\)</span> 为 52 公斤, 身高 158 厘米. 过 若干时候他体重长到 54 公斤, 你预测他身高 162 厘米左右, 这个 用法正确. 因为你只是一个被动的观察者, 并末设法去影响这个进 程. 反之, 如果你用强力减肥法使一个胖子在两星期内体重下降 5 公斤, 而预测他身高将下降 10 厘米左右, 则恐怕不见得正确. 因为 <span class="arithmatex">\(X\)</span> 值的改变出于你人为的干预, 违反了 <span class="arithmatex">\(X, Y\)</span> 之间的关系的自然 进程. 再举一个例子: 统计资料显示人的文化水平的提高导致出生 率降低. 但如某个国家孤立地进行提高人的文化水平的工作, 就不 一定能导致出生率预期的降低. 这是因为人口出生率是由一系列 的经济社会和文化习惯等条件决定的. 单抽出文化水平这个因子, 其实是将它作为一个综合因子来看待. 故如它的改变确实是显示 了这种综合条件的改善, 则应有利于出生率的降低. 反之, 如果其 他条件 (经济、社会等) 并无改变甚至有了恶化,而只孤立地提高文 化这个因子,则背离了建立回归方程的前提了.</p>
<ol>
<li>回归方程的外推</li>
</ol>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_f50f6ea83c00f0cb59edg-19.jpg?height=388&amp;width=503&amp;top_left_y=871&amp;top_left_x=274" /></p>
<p>图 6.5</p>
<p>所谓外推, 就是在建立回归方程时 所用的自变量数据的范围之外去使用回 归方程 (如果在自变量数据的范围之内 使用,就叫做内揷).一般都是不主张对 回归方程作外推使用的,原因我们在以 前已提过了, 即理论上回归方程一般并 非严格的直线. 例如, 回归方程是曲线 <span class="arithmatex">\(l\)</span>, 如果你在 <span class="arithmatex">\(a \leqslant x \leqslant b\)</span> 这个范围内使用, 则直线 <span class="arithmatex">\(l_{1}\)</span> 可充分好地代表它, 但如外推至 <span class="arithmatex">\(c\)</span> 点, 则与实际情况有 较大的差距了(图 6.5).</p>
<p>当然,也不能说外推在任何情况下都不行, 在某种很特殊的情 况下, 回归方程为线性这一点有充分的理论根据, 这时外推应不致 导致太大的偏差. 其次, 如外推距离不太远, 问题一般也不会很大. 在没有把握而情况允许时, 可以做一些试验, 以考察一下回归方程 在拟应用的范围内符合的程度如何.</p>
<ol>
<li>回归方程不可逆转使用</li>
</ol>
<p>在自变量 <span class="arithmatex">\(X\)</span> 和因变量 <span class="arithmatex">\(Y\)</span> 都是随机的场合, 往往可以把其中任 一个取为自变量. 人的身高体重就是一个例子. 这时就存在两个回 归方程, 如都为线性的,则分别有形状</p>
<div class="arithmatex">\[
y=a+b x, \quad x=c+d y
\]</div>
<p>有趣的是, 这两个方程并不一致. 意思是, 若你把 (2.32) 的第一个 方程 <span class="arithmatex">\(y=a+b x\)</span> 对 <span class="arithmatex">\(x\)</span> 解出得 <span class="arithmatex">\(x=-a / b+y / b\)</span>, 则这方程不一定就 是 (2.32)第二个方程, 对实际数据配出的经验回归直线, 也是这个 情况. 设有了数据 <span class="arithmatex">\(\left(X_{1}, Y_{1}\right), \cdots,\left(X_{n}, Y_{n}\right)\)</span>, 把 <span class="arithmatex">\(X\)</span> 作为自变量配出 回归方程 (用最小二乘法, 下同) <span class="arithmatex">\(y=\hat{a}+\hat{b} x\)</span>, 与把 <span class="arithmatex">\(Y\)</span> 作为自变量配 出的回归方程 <span class="arithmatex">\(x=\hat{c}+\hat{d} y\)</span> 不一定相同, 目一般不相同.</p>
<p>因此,在人的身高 <span class="arithmatex">\((X)\)</span> 体重 <span class="arithmatex">\((Y)\)</span> 这个例子中,如你的目的是通 过身高预测体重,则你应取 <span class="arithmatex">\(Y\)</span> 为因变量, 以建立回归方程 <span class="arithmatex">\(y=a+\)</span> <span class="arithmatex">\(b x\)</span>. 如果什么时候你忽然需要通过体重预测身高, 则你并不能利 用上述方程去作,而必须从头做起, 取 <span class="arithmatex">\(X\)</span> 为因变量, 用最小二乘法 配出方程 <span class="arithmatex">\(x=c+d y\)</span>. 后一方程用于从 <span class="arithmatex">\(y\)</span> 预测 <span class="arithmatex">\(x\)</span>.</p>
<p>表面上看这一点颇使人感到难以理解,细想之下, 道理其实不 难. 为方便计, 设 <span class="arithmatex">\((X, Y)\)</span> 的联合分布为二维正态分布 <span class="arithmatex">\(N\left(a, b, \sigma_{1}^{2}\right.\)</span>, <span class="arithmatex">\(\left.\sigma_{2}^{2}, \rho\right)\)</span>, 则如在第 2 章 (见该章 (3.10) 式) 中所证明的, <span class="arithmatex">\(Y\)</span> 对 <span class="arithmatex">\(X\)</span> 的回 归方程为</p>
<div class="arithmatex">\[
(y-b)=\rho \sigma_{2} \sigma_{1}^{-1}(x-a)
\]</div>
<p>而 <span class="arithmatex">\(X\)</span> 对 <span class="arithmatex">\(Y\)</span> 的回归方程则为</p>
<div class="arithmatex">\[
(x-a)=\rho \sigma_{1} \sigma_{2}^{-1}(y-b)
\]</div>
<p>除非 <span class="arithmatex">\(\rho^{2}=1\)</span>, 即 <span class="arithmatex">\(X, Y\)</span> 之间有严格的线性关系, (2.33) 与(2.34) 不 一样, 因为, 由 <span class="arithmatex">\((2.33)\)</span> 得 <span class="arithmatex">\((x-a)=p^{-1} \sigma_{1} \sigma_{2}^{-1}(y-b)\)</span>, 除非 <span class="arithmatex">\(\rho^{2}=1\)</span>, 这与 (2.34) 不同. 这样看来, 理论上这二者本不一致. 因此, 由数据 所配出两个经验回归方程,也不会一致了.</p>
<p>这个论点从理论上说清楚了问题. 但在直观上, 人们可能仍觉 得有些难以理解. 为说明这-…点, 考察这样一个情况: 相关系数 <span class="arithmatex">\(\rho&gt;0\)</span> 但很小. 这时, <span class="arithmatex">\(X, Y\)</span> 有些关系, 但关系很微弱: 一者的变化只 引起另一者很小的变化. 因此, 在两个回归关系 <span class="arithmatex">\(y=a+b x\)</span> 和 <span class="arithmatex">\(x=\)</span> <span class="arithmatex">\(c+d y\)</span> 中, 系数 <span class="arithmatex">\(b, d\)</span> 都很接近 0 . 这样二者就必然不一致了. 因由 <span class="arithmatex">\(y=a+b x\)</span> 得出 <span class="arithmatex">\(x=a_{1}+b_{1} y\)</span>, 其中 <span class="arithmatex">\(b_{1}=b^{-1} \cdot b_{1}\)</span> 很大, 因为 <span class="arithmatex">\(b\)</span> 很 小,故 <span class="arithmatex">\(b_{1}\)</span> 不可能与 <span class="arithmatex">\(d\)</span> 一致.</p>
<p>但应注意: 我们强调回归方程不能逆转使用是指用于预测而 言, 如用于控制则另当别论. 比如, 建立了 <span class="arithmatex">\(Y\)</span> 对 <span class="arithmatex">\(X\)</span> 的回归少 <span class="arithmatex">\(j\)</span> 程 <span class="arithmatex">\(y=\)</span> <span class="arithmatex">\(a+b x\)</span>. 为要把 <span class="arithmatex">\(Y\)</span> 之值控制在 <span class="arithmatex">\(y_{0}\)</span> 使其误差尽琶小, 自变量 <span class="arithmatex">\(X\)</span> 应取 何值? 那要从 <span class="arithmatex">\(y_{0}=a+b x\)</span> 解出 <span class="arithmatex">\(x=\left(y_{0}-a\right) / b\)</span>. 当然, 用于控制的 情况应当是自变量 <span class="arithmatex">\(X\)</span> 之值能由人选择时, 这时不存在作 <span class="arithmatex">\(X\)</span> 对 <span class="arithmatex">\(Y\)</span> 之回归的问题.</p>
<ol>
<li>在本节的讨论中,我们都是在自变量 <span class="arithmatex">\(X\)</span> 为非随机的假定 下进行的. 而在应用中, 又不时遇到 <span class="arithmatex">\(X\)</span> 也是随机的情况, 而我们也 就当作 <span class="arithmatex">\(X\)</span> 为非随机,仍使用本节导出的公式,这样做在理论上到 底可以不可以?</li>
</ol>
<p>这问题的仔细分析比较复杂, 不能在这里详细给出了. 我们只 指出两点: 一是若 <span class="arithmatex">\((X, Y)\)</span> 的联合分布为二维正态 <span class="arithmatex">\(N\left(a, b, \sigma_{1}^{2}, \sigma_{2}^{2}\right.\)</span>, <span class="arithmatex">\(\rho\)</span> ), 则有关回归系数的点估计, 区间估计, 回归函数的区间估计与 区间预测, 回归系数的检验等公式, 全都合用, 但 <span class="arithmatex">\(\hat{\beta}_{1}, \hat{\beta}_{1}\)</span> 的方差公 式已不适用 <span class="arithmatex">\(\left(\hat{\beta}_{1}\right.\)</span> 的方差表达式中含 <span class="arithmatex">\(X_{i}\)</span>, 因此处 <span class="arithmatex">\(X_{i}\)</span> 也是随机变量, 这是不可以的). <span class="arithmatex">\(\hat{\sigma}^{2}\)</span> 仍是模型 (2.1) 中的误差 <span class="arithmatex">\(e\)</span> 的方差的无偏估 计, 但这个方差应是给定 <span class="arithmatex">\(X\)</span> 时 <span class="arithmatex">\(Y\)</span> 的条件分布之方差, 即 <span class="arithmatex">\(\sigma_{2}^{2}(1-\)</span> <span class="arithmatex">\(\rho^{2}\)</span> )(见第二章 (3.9)式). 因此在这一场合, <span class="arithmatex">\(X\)</span> 为随机变量并不影 响方法的使用. 我们之所以能不顾 <span class="arithmatex">\(X\)</span> 是否随机而使用本节导出的 公式, 主要就是基于这个理由.二是若 <span class="arithmatex">\((X, Y)\)</span> 的分布不是正态时, 虽说回归系数点估计的公式仍可用,但其他一切已不再成立了.</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 21, 2023</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="创建日期">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3h-2Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 21, 2023</span>
  </span>

    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        对当前页面有任何疑问吗？
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5 9v12H1V9h4m4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21H9m0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03V19Z"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 15V3h4v12h-4M15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3h9m0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97V5Z"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              感谢您的反馈！
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              感谢您的反馈！请点击这里<a href="https://github.com/EanYang7/Probability-and-Statistics/issues" target="_blank" rel="noopener">这里</a>提供问题反馈.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/EanYang7/cs231n" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.top", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.path", "toc.follow", "content.action.edit", "content.action.view"], "search": "../../javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>