
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="《概率论与数理统计》陈希孺，中国科学技术大学出版社">
      
      
      
        <link rel="canonical" href="https://eanyang7.github.io/Probability-and-Statistics/assets/4/4.2/">
      
      
      
      
      <link rel="icon" href="../../../cover.jpg">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.2">
    
    
      
        <title>4.2 矩估计、极大似然估计和贝叶斯估计 - 概率论与数理统计</title>
      
    
    
      <link rel="stylesheet" href="../../stylesheets/main.50c56a3b.min.css">
      
        
        <link rel="stylesheet" href="../../stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../stylesheets/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-GEDRLMN4ML"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-GEDRLMN4ML",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-GEDRLMN4ML",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#42" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="概率论与数理统计" class="md-header__button md-logo" aria-label="概率论与数理统计" data-md-component="logo">
      
  <img src="../../../cover.jpg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            概率论与数理统计
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              4.2 矩估计、极大似然估计和贝叶斯估计
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为暗黑模式"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="切换为暗黑模式" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="切换为浅色模式"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="切换为浅色模式" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/EanYang7/Probability-and-Statistics" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/Probability-and-Statistics
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-grid">
    <ul class="md-tabs__list">
      
        
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../.." class="md-tabs__link">
          
  
  首页

        </a>
      </li>
    
  

      
        
  
  
  
    
    
      
  
  
  
    
    
      
  
  
  
    
    
      <li class="md-tabs__item">
        <a href="../../../courses/1-Probability-of-events/1-What-is-the-probability/" class="md-tabs__link">
          
  
  课程

        </a>
      </li>
    
  

    
  

    
  

      
        
  
  
  
    <li class="md-tabs__item">
      <a href="../../../%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%8B%E9%99%88%E5%B8%8C%E5%AD%BA%EF%BC%8C%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E5%87%BA%E7%89%88%E7%A4%BE.pdf" class="md-tabs__link">
        
  
    
  
  PDF

      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="概率论与数理统计" class="md-nav__button md-logo" aria-label="概率论与数理统计" data-md-component="logo">
      
  <img src="../../../cover.jpg" alt="logo">

    </a>
    概率论与数理统计
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/EanYang7/Probability-and-Statistics" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    EanYang7/Probability-and-Statistics
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_1" >
        
          
          <label class="md-nav__link" for="__nav_1" id="__nav_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    首页
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_1">
            <span class="md-nav__icon md-icon"></span>
            首页
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    简介
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  <span class="md-ellipsis">
    课程
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            课程
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
      
      
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1" id="__nav_2_1_label" tabindex="">
            
  
  <span class="md-ellipsis">
    章节
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1">
            <span class="md-nav__icon md-icon"></span>
            章节
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_1" >
        
          
          <label class="md-nav__link" for="__nav_2_1_1" id="__nav_2_1_1_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第1章 事件的概率
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_1_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_1">
            <span class="md-nav__icon md-icon"></span>
            第1章 事件的概率
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/1-What-is-the-probability/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.1 概率是什么
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/2-Classical-Probability-Calculation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.2 古典概率计算
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/3-Operation-Conditional-probability-and-independence-of-events/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    1.3 事件的运算、条件概率与独立性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/1-Probability-of-events/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_2" >
        
          
          <label class="md-nav__link" for="__nav_2_1_2" id="__nav_2_1_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第2章 随机变量及概率分布
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_2">
            <span class="md-nav__icon md-icon"></span>
            第2章 随机变量及概率分布
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/1-One-dimensional-random-variable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.1 一维随机变量
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/2-Multidimensional-random-variables-random-vectors/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.2 多维随机变量（随机向量）
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/3-Independence-of-Conditional-probability-distribution-and-random-variable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.3 条件概率分布与随机变量的独立性
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/4-Probability-Distribution-of-Functions-of-Random-Variables/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    2.4 随机变量的函数的概率分布
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/2-Random-Variables-and-Probability-Distribution/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_3" >
        
          
          <label class="md-nav__link" for="__nav_2_1_3" id="__nav_2_1_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第3章 随机变量的数字特征
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_3">
            <span class="md-nav__icon md-icon"></span>
            第3章 随机变量的数字特征
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/1-Mathematica-Expectations-Mean-and-Median/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.1 数学期望（均值）与中位数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/2-Variance-and-Moment/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.2 方差与矩
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/3-Covariance-and-correlation-coefficient/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.3 协方差与相关系数
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/4-Theorem-of-Large-Numbers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    3.4 大数定理和中心极限定理
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/3-Numerical-Characteristics-of-Random-Variables/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_4" >
        
          
          <label class="md-nav__link" for="__nav_2_1_4" id="__nav_2_1_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第4章 参数估计
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            第4章 参数估计
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/1-Basic-concepts-of-Mathematical-statistics/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.1 数理统计学的基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/2-Moment-estimation-maximum-likelihood-estimation-and-Bayesian-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.2 矩估计、极大似然估计和贝叶斯估计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/3-Excellence-criterion-of-Point-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.3 点估计的优良性准则
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/4-Interval-estimation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    4.4 区间估计
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/4-Parameter-Estimates/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_5" >
        
          
          <label class="md-nav__link" for="__nav_2_1_5" id="__nav_2_1_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第5章 假设检验
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_5">
            <span class="md-nav__icon md-icon"></span>
            第5章 假设检验
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/1-Problem-formulation-and-basic-concepts/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.1 问题提法和基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/2-Important-parameter-inspection/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.2 重要参数检验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/3-goodness-of-fit-test/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    5.3 拟合优度检验
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/5-Hypothesis-Testing/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    
    
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_1_6" >
        
          
          <label class="md-nav__link" for="__nav_2_1_6" id="__nav_2_1_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    第6章 回归、相关与方差分析
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_2_1_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2_1_6">
            <span class="md-nav__icon md-icon"></span>
            第6章 回归、相关与方差分析
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/1-Basic-concepts-of-regression-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.1 回归分析基本概念
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/2-Univariate-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.2 一元线性回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/3-Multiple-linear-regression/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.3 多元线性回归
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/4-Correlation-analysis/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.4 相关分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/5-Analysis-of-variance/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    6.5 方差分析
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附录
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/exercises/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    习题
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/6-Regression-Correlation-and-Analysis-of-Variance/answers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    答案
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../courses/appendix/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    附表
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../../%E3%80%8A%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1%E3%80%8B%E9%99%88%E5%B8%8C%E5%AD%BA%EF%BC%8C%E4%B8%AD%E5%9B%BD%E7%A7%91%E5%AD%A6%E6%8A%80%E6%9C%AF%E5%A4%A7%E5%AD%A6%E5%87%BA%E7%89%88%E7%A4%BE.pdf" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    PDF
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#01-1" class="md-nav__link">
    <span class="md-ellipsis">
      0.1. 1 参数的点估计问题
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#02-2" class="md-nav__link">
    <span class="md-ellipsis">
      0.2. 2 矩估计法
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#03-3" class="md-nav__link">
    <span class="md-ellipsis">
      0.3. 3 极大似然估计法
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#04-4" class="md-nav__link">
    <span class="md-ellipsis">
      0.4. 4 贝叶斯法
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
    <a href="https://github.com/EanYang7/Probability-and-Statistics/tree/main/docs/assets/4/4.2.md" title="编辑此页" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
    </a>
  
  
    
      
    
    <a href="https://github.com/EanYang7/Probability-and-Statistics/tree/main/docs/assets/4/4.2.md" title="查看本页的源代码" class="md-content__button md-icon">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0 8a5 5 0 0 1-5-5 5 5 0 0 1 5-5 5 5 0 0 1 5 5 5 5 0 0 1-5 5m0-12.5C7 4.5 2.73 7.61 1 12c1.73 4.39 6 7.5 11 7.5s9.27-3.11 11-7.5c-1.73-4.39-6-7.5-11-7.5Z"/></svg>
    </a>
  


<h1 id="42">4.2 矩估计、极大似然估计和贝叶斯估计<a class="headerlink" href="#42" title="Permanent link">⚓︎</a></h1>
<h3 id="01-1">0.1. 1 参数的点估计问题<a class="headerlink" href="#01-1" title="Permanent link">⚓︎</a></h3>
<p>设有一个统计总体, 以 <span class="arithmatex">\(f\left(x, \theta_{1}, \cdots, \theta_{k}\right)\)</span> 记其概率密度函数 (若 总体分布为连续型的), 或其概率函数 (若总体分布为离散型的), 以后, 为避免每次重复交代这两种情况, 我们约定称 <span class="arithmatex">\(f\left(x, \theta_{1}, \cdots\right.\)</span>, <span class="arithmatex">\(\left.\theta_{k}\right)\)</span> 为“总体分布”, 其具体含义视其为连续型或离散型而定. 这分 布包含 <span class="arithmatex">\(k\)</span> 个末知参数 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span>. 例如对正态总体 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span>, 有 <span class="arithmatex">\(\theta_{1}\)</span> <span class="arithmatex">\(=\mu, \theta_{2}=\sigma^{2}\)</span>, 而</p>
<ul>
<li>158 •</li>
</ul>
<div class="arithmatex">\[
f\left(x, \theta_{1}, \theta_{2}\right)=\left(\sqrt{2 \pi \theta_{2}}\right)^{-1} \exp \left(-\frac{1}{2 \theta_{2}}\left(x-\theta_{1}\right)^{2}\right),-\infty&lt;x&lt;\infty
\]</div>
<p>苃总体有二项分布 <span class="arithmatex">\(B(n, p)\)</span>, 则 <span class="arithmatex">\(\theta_{1}=p\)</span>, 而</p>
<div class="arithmatex">\[
f\left(x, \theta_{1}\right)=\left(\begin{array}{l}
n \\
x
\end{array}\right) \theta_{1}^{x}\left(1-\theta_{1}\right)^{n-x}, x=0,1, \cdots, n
\]</div>
<p>当 <span class="arithmatex">\(k=1\)</span>, 即只有一个参数时, 就用 <span class="arithmatex">\(\theta\)</span> 代替 <span class="arithmatex">\(\theta_{1}\)</span>.</p>
<p>参数估计问题的一般提法是: 设有了从总体中抽出的样本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> (在 4.1 节 4.1 .3 段中已说明过, 当不作特殊申明时, 样 本就是指独立随机样本, 即 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 独立同分布, 其公共分布就 是总体分布), 要依据这些样本去对参数 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 的末知值作出 估计. 当然,我们也可以只要求什计 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 中的一部分,或估计 它们的某个已知函数 <span class="arithmatex">\(g\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span>. 例如, 为要估计 <span class="arithmatex">\(\theta_{1}\)</span>, 我们需要 构造出适当的统计量 <span class="arithmatex">\(\hat{\theta}_{1}=\hat{\theta}_{1}\left(X_{1}, \cdots, X_{n}\right)\)</span>. 每当有了样本 <span class="arithmatex">\(X_{1}, \cdots\)</span>, <span class="arithmatex">\(X_{n}\)</span>, 就代人函数 <span class="arithmatex">\(\hat{\theta}_{1}\left(X_{1}, \cdots, X_{n}\right)\)</span> 算出一个值, 用来作为 <span class="arithmatex">\(\theta_{1}\)</span> 的估计 值. 为着这样的特定目的而构造的统计量 <span class="arithmatex">\(\hat{\theta}_{1}\)</span>, 叫做 ( <span class="arithmatex">\(\theta_{1}\)</span> 的) 估计量. 由于末知参数 <span class="arithmatex">\(\theta_{1}\)</span> 是数轴上的一个点,用 <span class="arithmatex">\(\hat{\theta}_{1}\)</span> 去估计 <span class="arithmatex">\(\theta_{1}\)</span>, 等于用一个 点去估计另一个点, 所以这样的估计叫做点估计, 以别于将在 4.4 节讨论的区间估计。</p>
<p>在本节中我们要讨论几种常用的点估计方法, 这些方法大多 是基于某种直观上的考虑. 同一个参数往往可以用若干个看来都 合理的方法去估计. 因此有一个判断优劣的问题, 这就要为估计量 的优劣制定准则, 进而研究在某种准则下寻找最优估计量的问题. 这就是参数估计这个数理统计学分支的重要内容. 这些概念将在 以后作更具体的解释.</p>
<h3 id="02-2">0.2. 2 矩估计法<a class="headerlink" href="#02-2" title="Permanent link">⚓︎</a></h3>
<p>矩估计法是 <span class="arithmatex">\(\mathrm{K}\)</span>. 皮尔逊在上世纪末到本世纪初的一系列文章 中引进的. 这个方法的思想很简单: 设总体分布为 <span class="arithmatex">\(f\left(x, \theta_{1}, \cdots\right.\)</span>, <span class="arithmatex">\(\theta_{k}\)</span> ), 则它的矩 (原点矩和中心矩都可以, 此处以原点矩为例)</p>
<div class="arithmatex">\[
\begin{gathered}
\alpha_{m}=\int_{-\infty}^{\infty} x^{m} f\left(x, \theta_{1}, \cdots, \theta_{k}\right) \mathrm{d} x \\
\left(\text { 或 } \sum_{i} x_{i}^{m} f\left(x_{i}, \theta_{i}, \cdots, \theta_{k}\right)\right)
\end{gathered}
\]</div>
<p>依赖于 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span>. 另一方面, 至少在样本大小 <span class="arithmatex">\(n\)</span> 较大时, <span class="arithmatex">\(\alpha_{m}\)</span> 又应 接近于样本原点矩 <span class="arithmatex">\(\alpha_{m}\)</span>. 于是</p>
<div class="arithmatex">\[
\alpha_{m}=\alpha_{m}\left(\theta_{1}, \cdots, \theta_{k}\right) \approx a_{m}=\sum_{i=1}^{n} X_{i}^{m} / n
\]</div>
<p>取 <span class="arithmatex">\(m=1, \cdots, k\)</span>, 并让上面的近似式改成等式, 就得到一个方程组 :</p>
<div class="arithmatex">\[
\alpha_{m}\left(\theta_{1}, \cdots, \theta_{k}\right)=\alpha_{m}, m=1, \cdots, k
\]</div>
<p>解此方程组, 得其根 <span class="arithmatex">\(\hat{\theta}_{i}=\hat{\theta}_{i}\left(X_{1}, \cdots, X_{n}\right), i=1, \cdots, k\)</span>. 就以 <span class="arithmatex">\(\hat{\theta}_{i}\)</span> 作为 <span class="arithmatex">\(\theta_{i}\)</span> 的估计. <span class="arithmatex">\(i=1, \cdots, k\)</span>. 如果要估计的是 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 的某函数 <span class="arithmatex">\(g\left(\theta_{1}\right.\)</span>, <span class="arithmatex">\(\left.\cdots, \theta_{k}\right)\)</span>, 则用 <span class="arithmatex">\(\hat{g}=\hat{g}\left(X_{1}, \cdots, X_{n}\right)=g\left(\hat{\theta}_{1}, \cdots, \hat{\theta}_{k}\right)\)</span> 去估计它. 这样定 出的估计量就叫做矩估计.</p>
<p>我们来举几个例子说明这个方法.</p>
<p>例 2.1 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从正态总体 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 中抽出的样 本, 要估计 <span class="arithmatex">\(\mu\)</span> 和 <span class="arithmatex">\(\sigma^{2} . \mu\)</span> 是总体的一阶原点矩, 按矩估计, 用样本一 阶原点矩即样本均值 <span class="arithmatex">\(\bar{X}\)</span> 去估计之. <span class="arithmatex">\(\sigma^{2}\)</span> 是总体方差, 即总体二阶中 心矩, 可用样本二阶中心矩 <span class="arithmatex">\(m_{2}\)</span> 去估计.一般,在估计方差时常用 样本方差 <span class="arithmatex">\(s^{2}\)</span> 而不用 <span class="arithmatex">\(m_{2}\)</span>, 即对矩估计作了一定的修正. 这种修正的 理由将在下节中指出。</p>
<p>如果要估计的是标准差 <span class="arithmatex">\(\sigma\)</span>, 则由 <span class="arithmatex">\(\sigma=\sqrt{\sigma^{2}}\)</span>, 按矩估计法, 它可 以用 <span class="arithmatex">\(\sqrt{m_{2}}\)</span> 去估计,一般用 <span class="arithmatex">\(\sqrt{s^{2}}=s\)</span> 去估计, 或者还作点修正（见下 节). 又当 <span class="arithmatex">\(\mu \neq 0\)</span> 时 (特别在 <span class="arithmatex">\(\mu&gt;0\)</span> 时, 在有些问题中 <span class="arithmatex">\(\mu\)</span> 虽末知, 但事 先可知 <span class="arithmatex">\(\mu&gt;0\)</span>. 如例 <span class="arithmatex">\(1.2, \mu\)</span> 是该校大学生的平均成绩, 它必须大于 <span class="arithmatex">\(0), \sigma / \mu\)</span> 称为总体的变异系数一一变异系数是以均值为单位去衡 量的总体的标准差. 在有些问题中, 反映变异程度的标准差意义如 何, 要看总体均值 <span class="arithmatex">\(\mu\)</span> 而定. 比如一大群人收入的标准差为 50 元. 若其平均工资只有 70 元, 则这个变异程度可算很大了. 但若平均 1. 资为 850 元, 则这变异程度不算大. 所以, 变异系数 <span class="arithmatex">\(\sigma / \mu\)</span> 不过是 一定意义下的“相对误差”. 按矩法, 为估计 <span class="arithmatex">\(\sigma / \mu\)</span>, 可用 <span class="arithmatex">\(\sqrt{m_{2}} / \bar{X}\)</span>, 一 般用 <span class="arithmatex">\(s / \bar{X}\)</span>.</p>
<p>例 2.2 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从指数分布总体中抽出的样本, 要 估计参数 <span class="arithmatex">\(\lambda\)</span> 的倒数 <span class="arithmatex">\(1 / \lambda\)</span>. 前已指出: <span class="arithmatex">\(1 / \lambda\)</span> 就是总体分布的均值, 故 按矩法, 就用 <span class="arithmatex">\(\bar{X}\)</span> 去估计之. 如要估计的是参数 <span class="arithmatex">\(\lambda\)</span> 本身, 就用 <span class="arithmatex">\(1 \bar{X}\)</span>.</p>
<p>另一方面,如在第三章例 2.5 中指出的, 指数分布的方差为</p>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_7e8dd5fb16c87aa50015g-04.jpg?height=83&amp;width=1527&amp;top_left_y=832&amp;top_left_x=276" />
<span class="arithmatex">\(s)\)</span> 去估计. 这个估计与 <span class="arithmatex">\(\bar{X}\)</span> 哪个更好? 这就是需要研究的问题, 见下 节。</p>
<p>例 2.3 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从区间 <span class="arithmatex">\(\left[\theta_{1}, \theta_{2}\right]\)</span> 上均匀分布的总体 中抽出的样本,要估计 <span class="arithmatex">\(\theta_{1}, \theta_{2}\)</span>.</p>
<p>前已指出 (见第三章例 1.3 和例 2.5). 这总体分布的均值、方 差分别为 <span class="arithmatex">\(\left(\theta_{1}+\theta_{2}\right) / 2\)</span> 和 <span class="arithmatex">\(\left(\theta_{2}-\theta_{1}\right)^{2} / 12\)</span>. 因此按矩法, 建立方程</p>
<div class="arithmatex">\[
\bar{X}=\left(\theta_{1}+\theta_{2}\right) / 2, m_{2}=\left(\theta_{2}-\theta_{1}\right)^{2} / 12
\]</div>
<p>得出 <span class="arithmatex">\(\theta_{1}, \theta_{2}\)</span> 的解 <span class="arithmatex">\(\hat{\theta}_{1}, \hat{\theta}_{2}\)</span> 分别为</p>
<div class="arithmatex">\[
\hat{\theta}_{1}=\bar{X}-\sqrt{3 m_{2}}, \hat{\theta}_{2}=\bar{X}+\sqrt{3 m_{2}}
\]</div>
<p>也可以用 <span class="arithmatex">\(s\)</span> 代替 <span class="arithmatex">\(\sqrt{m_{2}}\)</span>.</p>
<p>例 2.4 在第三章 <span class="arithmatex">\((2.8),(2.9)\)</span> 式中曾定义了分布的偏度系 数 <span class="arithmatex">\(\beta_{1}=\frac{\mu_{3}}{\mu_{2}^{3 / 2}}\)</span> 及峰度系数 <span class="arithmatex">\(\beta_{2}=\frac{\mu_{4}}{\mu_{2}^{2}}\)</span> (或 <span class="arithmatex">\(\beta_{2}-3\)</span> ), 并阐述了它的意义. 根 据矩法, 这些量可分别用 <span class="arithmatex">\(\frac{m_{3}}{m_{2}^{3 / 2}}\)</span> 和 <span class="arithmatex">\(\frac{m_{4}}{m_{2}^{2}}\)</span> 去估计之.</p>
<p>本例与前几例不同之处在于: 它并不要求总体分布有特定的 参数形式, 如正态分布, 指数分布之类. 总体分布为任何分布都可 以, 只要其三阶 (对 <span class="arithmatex">\(\beta_{1}\)</span> ) 或四阶 (对 <span class="arithmatex">\(\beta_{2}\)</span> ) 矩存在就行. 凡是被估计的 对象能直接用矩表达出来时, 都属于这种情况, 其中最重要的例子 是均值方差. 只要总体分布的均值方差存在, 则总可以用样本均值 <span class="arithmatex">\(\bar{X}\)</span> 或样本方差 <span class="arithmatex">\(S^{2}\)</span> 去估计之, 而不论其分布有如何的形式. 不过, 在 总体分布已知有某种参数形式时, 总体的均值方差也可以有比 <span class="arithmatex">\(\bar{X}\)</span> 或 <span class="arithmatex">\(S^{2}\)</span> 更好的估计(见后面有关的例子).</p>
<p>例 2.5 设总体有二项分布 <span class="arithmatex">\(B(N, p), X_{1}, \cdots, X_{n}\)</span> 为从该总 体中抽出的样本. 要估计 <span class="arithmatex">\(p\)</span>, 矩估计为 <span class="arithmatex">\(\bar{X} / N\)</span>.</p>
<p>例 2.6 设总体有波哇松分布 <span class="arithmatex">\(P(\lambda), X_{1}, \cdots, X_{n}\)</span> 为从该总体 中抽出的样本, 要估计 <span class="arithmatex">\(\lambda\)</span>.</p>
<p>由于 <span class="arithmatex">\(\lambda\)</span> 是总体分布的均值, 按矩估计法, 用样本均值 <span class="arithmatex">\(\bar{X}\)</span> 去估计 之; 另一方面, <span class="arithmatex">\(\lambda\)</span> 也是总体分布的方差, 故按矩法, 也可以用 <span class="arithmatex">\(m_{2}\)</span> 或 <span class="arithmatex">\(S^{2}\)</span> 去估计. 这又有一个优劣的问题. 对本例及例 2.2 来说, 在合理 的准则下, 都可以证明用样本均值 <span class="arithmatex">\(\bar{X}\)</span> 为优. 在一般情况下通常总是 采取这样的原则: 能用低阶矩处理的就不用高阶矩。</p>
<h3 id="03-3">0.3. 3 极大似然估计法<a class="headerlink" href="#03-3" title="Permanent link">⚓︎</a></h3>
<p>设总体有分布 <span class="arithmatex">\(f\left(X ; \theta_{1}, \cdots, \theta_{k}\right), X_{1}, \cdots, X_{n}\)</span> 为自这总体中抽 出的样本, 则样本 <span class="arithmatex">\(\left(X_{1}, \cdots, X_{n}\right)\)</span> 的分布 (即其概率密度函数或概率 函数) 为</p>
<div class="arithmatex">\[
f\left(X_{1} ; \theta_{1}, \cdots, \theta_{k}\right) f\left(X_{2} ; \theta_{1}, \cdots, \theta_{k}\right) \cdots f\left(X_{n} ; \theta_{1}, \cdots, \theta_{k}\right)
\]</div>
<p>记之为 <span class="arithmatex">\(L\left(X_{1}, \cdots, X_{n} ; \theta_{1}, \cdots, \theta_{k}\right)\)</span>.</p>
<p>固定 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 而看作是 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 的函数时, <span class="arithmatex">\(L\)</span> 是一个概率 密度函数或概率函数, 可以这样理解: 若 <span class="arithmatex">\(L\left(Y_{1}, \cdots, Y_{n} ; \theta_{1}, \cdots, \theta_{k}\right)\)</span> <span class="arithmatex">\(&gt;L\left(X_{1}, \cdots, X_{n} ; \theta_{1}, \cdots, \theta_{k}\right)\)</span>, 则在观察时出现 <span class="arithmatex">\(\left(Y_{1}, \cdots, Y_{n}\right)\)</span> 这个点 的可能性, 要比出现 <span class="arithmatex">\(\left(X_{1}, \cdots, X_{n}\right)\)</span> 这个点的可能性大. 把这件事反 过来说, 可以这样想: 当已观察到 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 时, 若 <span class="arithmatex">\(L\left(X_{1}, \cdots, X_{n}\right.\)</span>; <span class="arithmatex">\(\left.\theta^{\prime}{ }_{1}, \cdots, \theta^{\prime}{ }_{k}\right)&gt;L\left(X_{1}, \cdots, X_{n} ; \theta^{\prime \prime}{ }_{1}, \cdots, \theta_{k}^{\prime \prime}\right)\)</span>, 则被估计的参数 <span class="arithmatex">\(\left(\theta_{1}\right.\)</span>, <span class="arithmatex">\(\left.\cdots, \theta_{k}\right)\)</span> 是 <span class="arithmatex">\(\left(\theta_{1}^{\prime}, \cdots, \theta_{k}^{\prime}\right)\)</span> 的可能性, 要比它是 <span class="arithmatex">\(\left(\theta_{1}^{\prime \prime}, \cdots, \theta_{k}^{\prime \prime}\right)\)</span> 的可能性大.</p>
<p>当 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 固定而把 <span class="arithmatex">\(L\)</span> 看作 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 的函数时,它称为 “似然函数”. 这名称的意义, 可根据上述分析得到理解: 这函数对 不同的 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 的取值, 反映了在观察结果 <span class="arithmatex">\(\left(X_{1}, \cdots, X_{n}\right)\)</span> 已知的 条件下, <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 的各种值的“似然程度”. 注意这里有些像贝叶 斯公式中的推理 (见第一章 (3.18) 式): 把观察值 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 看成 结果而参数值 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 看成是导致这结果的原因. 现已有了结 果, 要反过来推算各种原因的概率. 这里参数 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 有一定的 值 (虽然末知), 并非事件或随机变量, 无概率可言, 于是就改用“似 然”这个词。</p>
<p>从上述分析就自然地导致如下的方法: 应该用似然程度最大 的那个点 <span class="arithmatex">\(\left(\theta_{1}^{*}, \cdots, \theta_{k}^{*}\right)\)</span>, 即满足条件</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; L\left(X_{1}, \cdots, X_{n} ; \theta_{1}^{*}, \cdots, \theta_{k}^{*}\right) \\
&amp; \quad=\max _{\theta_{1}, \cdots, \theta_{k}} L\left(X_{1}, \cdots, X_{n} ; \theta_{1}, \cdots, \theta_{k}\right)
\end{aligned}
\]</div>
<p>的 <span class="arithmatex">\(\left(\theta_{1}^{*}, \cdots, \theta_{k}^{*}\right)\)</span> 去作为 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 的估计值, 因为在已得样本 <span class="arithmatex">\(X_{1}\)</span>, <span class="arithmatex">\(\cdots, X_{n}\)</span> 条件下, 这个 “看来最像” 是真参数值. 这个估计 <span class="arithmatex">\(\left(\theta_{1}^{*}, \cdots\right.\)</span>, <span class="arithmatex">\(\left.\theta_{k}^{*}\right)\)</span> 就叫做 <span class="arithmatex">\(\left(\theta_{1}, \cdots, \theta_{k}\right)\)</span> 的 “极大似然估计”. 如果要估计的是 <span class="arithmatex">\(g\left(\theta_{1}\right.\)</span>, <span class="arithmatex">\(\left.\cdots, \theta_{k}\right)\)</span>, 则 <span class="arithmatex">\(g\left(\theta_{1}^{*}, \cdots, \theta_{k}^{*}\right)\)</span> 是它的极大似然估计.</p>
<p>因为</p>
<div class="arithmatex">\[
\log L=\sum_{i=1}^{n} \log f\left(X_{i} ; \theta_{1}, \cdots, \theta_{k}\right)
\]</div>
<p>且为使 <span class="arithmatex">\(L\)</span> 达到最大, 只须使 <span class="arithmatex">\(\log L\)</span> 达到最大, 故在 <span class="arithmatex">\(f\)</span> 对 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 存 在连续的偏导数时, 可建立方程组 (称为似然方程组):</p>
<div class="arithmatex">\[
\frac{\partial \log L}{\partial \theta_{i}}=0, i=1, \cdots, \dot{k}
\]</div>
<p>如果这方程组有唯一的解, 又能验证它是一个极大值点, 则它必是 使 <span class="arithmatex">\(L\)</span> 达到最大之点, 即极大似然估计. 在几个常见的重要例子中 这一点不难验证. 可是, 在较复杂的场合, 方程组 (2.5) 可以有不止 一组解, 求出这些解很费计算, 且不易判定那一个使 <span class="arithmatex">\(L\)</span> 达到最大.</p>
<p>有时, 函数 <span class="arithmatex">\(f\)</span> 并不对 <span class="arithmatex">\(\theta_{1}, \cdots, \theta_{k}\)</span> 可导, 甚至 <span class="arithmatex">\(f\)</span> 本身也不连续,这 时方程组 (2.5) 就无法用, 必须回到原始的定义 2.3.</p>
<p>现举一些例子来说明求极大似然估计的过程.</p>
<p>例 2.7 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从正态总体 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 中抽出的样 本, 则似然函数为</p>
<div class="arithmatex">\[
\begin{aligned}
L &amp; =\prod_{i=1}^{n}\left[\left(\sqrt{2 \pi \sigma^{2}}\right)^{-1} \exp \left(-\frac{1}{2 \sigma^{2}}\left(X_{i}-\mu\right)^{2}\right)\right] \\
\log L &amp; =-\frac{n}{2} \log (2 \pi)-\frac{n}{2} \log \left(\sigma^{2}\right)-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}
\end{aligned}
\]</div>
<p>求方程组 (2.5) (把 <span class="arithmatex">\(\sigma^{2}\)</span> 作为一个整体看):</p>
<div class="arithmatex">\[
\begin{gathered}
\frac{\partial \log L}{\partial \mu}=\frac{1}{\sigma^{2}} \sum_{i=1}^{n}\left(X_{i}-\mu\right)=0 \\
\frac{\partial \log L}{\partial\left(\sigma^{2}\right)}=-\frac{n}{2 \sigma^{2}}+\frac{1}{2 \sigma^{4}} \sum_{i=1}^{n}\left(X_{i}-\mu\right)^{2}=0
\end{gathered}
\]</div>
<p>由第一式得出 <span class="arithmatex">\(\mu\)</span> 的解为</p>
<div class="arithmatex">\[
\mu^{*}=\sum_{i=1}^{n} X_{i} / n=\bar{X}
\]</div>
<p>以此代入第二式的 <span class="arithmatex">\(\mu\)</span>,得到 <span class="arithmatex">\(\sigma^{2}\)</span> 的解为</p>
<div class="arithmatex">\[
\sigma^{* 2}=\sum_{i=1}^{n}\left(X_{i}-\bar{X}\right)^{2} / n=m_{2}
\]</div>
<p>我们看到: <span class="arithmatex">\(\mu\)</span> 与 <span class="arithmatex">\(\sigma^{2}\)</span> 的极大似然估计 <span class="arithmatex">\(\mu^{*}\)</span> 和 <span class="arithmatex">\(\sigma^{* 2}\)</span>, 与其矩估计完全一 样. 在本例中, 容易肯定 <span class="arithmatex">\(\left(\mu^{*}, \sigma^{* 2}\right)\)</span> 确是使似然函数 <span class="arithmatex">\(L\)</span> 达得最大值 之点. 因为, 似然方程组只有唯一的根 <span class="arithmatex">\(\left(\mu^{*}, \sigma^{* 2}\right)\)</span>, 而这个点不可 能是 <span class="arithmatex">\(L\)</span> 的极小值点. 因为, 由 <span class="arithmatex">\(L\)</span> 的表达式 (2.6) 可知, 当 <span class="arithmatex">\(|\mu| \rightarrow \infty\)</span> 或 <span class="arithmatex">\(\sigma^{2} \rightarrow 0\)</span> 时, <span class="arithmatex">\(L\)</span> 趋向于 0 , 而 <span class="arithmatex">\(L\)</span> 在每个点处都大于 0 . 以下几个例 子都可以按照这个方式去验证, 我们就不一一重复了.</p>
<p>例 2.8 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从指数分布总体中抽出的样本, 求 参数 <span class="arithmatex">\(\lambda\)</span> 的极大似然估计.</p>
<p>有</p>
<div class="arithmatex">\[
L=\prod_{i=1}^{n}\left(\lambda \mathrm{e}^{-\lambda x_{i}}\right)
\]</div>
<p>故</p>
<div class="arithmatex">\[
\log L=n \log \lambda-\lambda \sum_{i=1}^{n} X_{i}
\]</div>
<p>解方程</p>
<div class="arithmatex">\[
\frac{\partial \log L}{\partial \lambda}=\frac{n}{\lambda}-\sum_{i=1}^{n} X_{i}=0
\]</div>
<p>得 <span class="arithmatex">\(\lambda\)</span> 的极大似然估计为</p>
<div class="arithmatex">\[
\lambda^{*}=n / \sum_{i=1}^{n} X_{i}=1 / \bar{X}
\]</div>
<p>仍与其矩估计一样. 但是在这里, 极大似然估计只有一个, 而如在 例 2.2 中所指出的, <span class="arithmatex">\(\lambda\)</span> 的矩估计依使用不同阶的矩, 可以有几个.</p>
<p>例 2.9 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是从均匀分布 <span class="arithmatex">\(R(0, \theta)\)</span> 的总体中抽出 的样本, 求 <span class="arithmatex">\(\theta\)</span> 的极大似然估计.</p>
<p><span class="arithmatex">\(X_{i}\)</span> 的密度函数为 <span class="arithmatex">\(1 / \theta\)</span>, 当 <span class="arithmatex">\(0&lt;X_{i}&lt;\theta\)</span>, 此外为 0 . 故似然函数 <span class="arithmatex">\(L\)</span> 为</p>
<div class="arithmatex">\[
L= \begin{cases}\theta^{-n}, &amp; \text { 当 } 0&lt;X_{i}&lt;\theta, i=1, \cdots, n \\ 0, &amp; \text { 其他情况 }\end{cases}
\]</div>
<p>对固定的 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span>, 此函数为 <span class="arithmatex">\(\theta\)</span> 的间断函数,故无法使用似然方 程 (2.5). 但此例不难直接用最初的定义 2.3 去解决: 为使 <span class="arithmatex">\(L\)</span> 达到 最大, <span class="arithmatex">\(\theta\)</span> 必须尽量小, 但又不能太小以致 <span class="arithmatex">\(L\)</span> 为 0 . 这界线就在 <span class="arithmatex">\(\theta^{*}=\)</span> <span class="arithmatex">\(\max \left(X_{1}, \cdots, X_{n}\right)\)</span> 处: 当 <span class="arithmatex">\(\theta \geqslant \theta^{*}\)</span> 时, <span class="arithmatex">\(L\)</span> 大于 0 且为 <span class="arithmatex">\(\theta^{-n}\)</span>. 当 <span class="arithmatex">\(\theta&lt;\theta^{*}\)</span> 时, <span class="arithmatex">\(L\)</span> 为 0 . 故唯一使 <span class="arithmatex">\(L\)</span> 达到最大的 <span class="arithmatex">\(\theta\)</span> 值, 即 <span class="arithmatex">\(\theta\)</span> 的极大似然估计, 为 <span class="arithmatex">\(\theta^{*}\)</span>.</p>
<p>如果用矩估计法, 则因总体分布的均值为 <span class="arithmatex">\(\theta / 2, \theta\)</span> 的矩估计为 <span class="arithmatex">\(\hat{\theta}=2 \bar{X}\)</span>. 这两个估计的优劣比较将在后面讨论.</p>
<p>例 2.10 再考虑例 2.5, 有</p>
<div class="arithmatex">\[
\begin{gathered}
L=\prod_{i=1}^{n}\left[\left(\begin{array}{l}
N \\
X_{i}
\end{array}\right) p^{\left.X_{i}(1-p)^{N-X_{i}}\right]}\right. \\
\log L=\sum_{i=1}^{n} \log \left(\begin{array}{l}
N \\
X_{i}
\end{array}\right)+\sum_{i=1}^{n} X_{i} \log p+\sum_{i=1}^{n}\left(N-X_{i}\right) \log (1-p)
\end{gathered}
\]</div>
<p>作方程</p>
<div class="arithmatex">\[
\frac{\partial \log L}{\partial p}=\frac{1}{p} \sum_{i=1}^{n} X_{i}-\left(n N-\sum_{i=1}^{n} X_{i}\right) \frac{1}{1-p}=0
\]</div>
<p>此方程之解, 即 <span class="arithmatex">\(p\)</span> 的极大似然估计, 为 <span class="arithmatex">\(p^{*}=\bar{X} / N\)</span>, 与矩估计相 同.</p>
<p>例 2.11考虑例 2.6. 容易证明: <span class="arithmatex">\(\lambda\)</span> 的极大似然估计 <span class="arithmatex">\(\lambda^{*}=\bar{X}\)</span>, 与短估计相同.</p>
<p>在我们所举的这些例子中（这些例子都是在应用上最常见 的),矩估计与极大似然估计在多数情况下一致。这更多地是一种 巧合, 并非一般情形. 有意思的是: 在这些例子中这两种估计方法 结果一致,说明这些估计是良好的. 这一点当然还需要一定的理论 证明.</p>
<p>也有这样的情况, 用这两个估计方法都行不通或不易实行.下 面是一个例子.</p>
<p>例 2.12 设总体分布有密度函数</p>
<div class="arithmatex">\[
f(x, \theta)=\frac{1}{\pi\left[1+(x-\theta)^{2}\right]},-\infty&lt;x&lt;\infty
\]</div>
<p>这分布包含一个参数 <span class="arithmatex">\(\theta, \theta\)</span> 可取任何实数值. 这分布叫柯西分布, 其密度作为 <span class="arithmatex">\(x\)</span> 的函数, 关于 <span class="arithmatex">\(\theta\)</span> 点对称. 故 <span class="arithmatex">\(\theta\)</span> 是这个分布的中位数 （见第三章 3.1.4).</p>
<p>现设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 为自这总体中抽出的样本, 要估计 <span class="arithmatex">\(\theta\)</span>. 由于</p>
<div class="arithmatex">\[
\int_{-\infty}^{\infty}|x| f(x, \theta) \mathrm{d} x=\infty
\]</div>
<p>柯西分布的一阶矩也不存在, 更不用说更高阶的矩了. 因此, 矩估 计无法使用. 若用极大似然法,则将得出方程</p>
<div class="arithmatex">\[
\sum_{i=1}^{n} \frac{X_{i}-\theta}{1+\left(X_{i}-\theta\right)^{2}}=0
\]</div>
<p>这方程有许多根且求根不容易. 因此, 对本例而言, 极大似然法也 不是理想的方法.</p>
<p>为估计参数 <span class="arithmatex">\(\theta\)</span>, 有一个较简单易行但看来合理的方法可用.这 个方法是基于 <span class="arithmatex">\(\theta\)</span> 是总体分布的中位数这个事实. 既如此,我们就 要设法在样本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 中找一种对应于中位数的东西.这个思 想其实在矩估计法中就已用过，因为总体矩在样本中的对应物就 是样本矩. 现在把 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 按由小到大排成一列:</p>
<div class="arithmatex">\[
X_{(1)} \leqslant X_{(2)} \leqslant \cdots \leqslant X_{(n)}
\]</div>
<p>它们称为次序统计量. 既然中位数是 “居中”的意思, 我们就在样本 中找居中者:</p>
<div class="arithmatex">\[
\hat{m}=\left\{\begin{array}{l}
X_{((n+1) / 2)}, \text { 当 } n \text { 为奇数时 } \\
\left(X_{(n / 2)}+X_{(n / 2+1)}\right) / 2, \text { 当 } n \text { 为偶数时 }
\end{array}\right.
\]</div>
<p>当 <span class="arithmatex">\(n\)</span> 为奇数时, 有一个居中者为 <span class="arithmatex">\(X_{((n+1) / 2)}\)</span>; 若 <span class="arithmatex">\(n\)</span> 为偶然, 就没有 一个居中者, 就把两个最居中者取平均, 这样定义的 <span class="arithmatex">\(\hat{m}\)</span> 叫作“样本 中位数”. 我们就拿 <span class="arithmatex">\(\hat{m}\)</span> 作为 <span class="arithmatex">\(\theta\)</span> 的估计.</p>
<p>就正态总体 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 而言, <span class="arithmatex">\(\mu\)</span> 也是总体的中位数,故 <span class="arithmatex">\(\mu\)</span> 也可 以用样本中位数去估计. 从这些例子中, 我们看出一点: 统计推断 问题的解, 往往可以从许多看来都合理的途径去考虑,并无一成不 变的方法,不同解固然有优劣之分, 但这种优劣也是相对于一定的 准则而言. 并无绝对的价值.下述情况也并非不常见: 估计甲在某 一准则下优于乙, 而乙又在另一准则下优于甲.</p>
<p>极大似然估计法的思想,始于高斯的误差理论,到 1912 年由 R. A. 费歇尔在一篇论文中把它作为一个一般的估计方法提出 来. 自 20 年代以来,费歇尔自己及许多统计学家对这一估计法进 行了大量的研究. 总的结论是: 在各种估计方法中, 相对说它一般 更为优良, 但在个别情况下也给出很不理想的结果. 与矩估计法不 同, 极大似然估计法要求分布有参数的形式. 比方说, 如对总体分 布毫无所知而要估计其均值方差, 极大似然法就无能为力.</p>
<h3 id="04-4">0.4. 4 贝叶斯法<a class="headerlink" href="#04-4" title="Permanent link">⚓︎</a></h3>
<p>贝叶斯学派是数理统计学中的一大学派. 在这一段中,我们简 略地介绍一下这个学派处理统计问题的基本思想.</p>
<p>拿我们目前讨论的点估计问题来说，无论你用矩估计也好，用 极大似然估计或其他方法也好,在我们心目中, 末知参数 <span class="arithmatex">\(\theta\)</span> 就简 单地是一个末知数, 在抽取样本之前, 我们对 <span class="arithmatex">\(\theta\)</span> 没有任何了解, 所 有的信息全来自样本.</p>
<p>贝叶斯学派则不然, 它的出发点是: 在进行抽样之前, 我们已 对 <span class="arithmatex">\(\theta\)</span> 有一定的知识, 叫做先验知识. 这里 “先验” 的意思并非先验 论, 而只是表示这种知识是“在试验之先”就有了的,也有人把它叫 做验前知识, 即“在试验之前”的意思。</p>
<p>贝叶斯学派进一步要求:这种先验知识必须用 <span class="arithmatex">\(\theta\)</span> 的某种概率 分布表达出来,这概率分布就叫做 <span class="arithmatex">\(\theta\)</span> 的“先验分布”或“验前分 布”. 这个分布总结了我们在试验之前对末知参数 <span class="arithmatex">\(\theta\)</span> 的知识.</p>
<p>举一个例子. 设某工厂每日生产一大批某种产品,我们想要估 计当日的废品率 <span class="arithmatex">\(\theta\)</span>. 该厂在以前已生产过很多批产品,如果过去的 检验有记录在,则它确实提供了关于废品率 <span class="arithmatex">\(\theta\)</span> 的一种有用信息, 据此可以画出 <span class="arithmatex">\(\theta\)</span> 的密度曲线, 如图 4.1(a), (b).</p>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_7e8dd5fb16c87aa50015g-11.jpg?height=368&amp;width=420&amp;top_left_y=1261&amp;top_left_x=544" /></p>
<p>(a)</p>
<p><img alt="" src="https://cdn.mathpix.com/cropped/2023_07_12_7e8dd5fb16c87aa50015g-11.jpg?height=377&amp;width=411&amp;top_left_y=1262&amp;top_left_x=1051" /></p>
<p>(b)</p>
<p>图 4.1</p>
<p>图中 <span class="arithmatex">\(h(\theta)\)</span> 表示 <span class="arithmatex">\(\theta\)</span> 的密度函数, <span class="arithmatex">\(0 \leqslant \theta \leqslant 1\)</span>. (a)表示一个较好的 情况: <span class="arithmatex">\(h(\theta)\)</span> 在 <span class="arithmatex">\(\theta=0\)</span> 附近很大而当 <span class="arithmatex">\(\theta\)</span> 增加时,下降很快.这表示该 厂以往的废品率通常都很低. (b)则表示一个不大好的情况: 比较 大的废品率出现的比率相当高. 容易理解: 这种关于 <span class="arithmatex">\(\theta\)</span> 的历史知 识 (即先验知识), 在当前估计废品率 <span class="arithmatex">\(\theta\)</span> 时, 应适当地加以使用而 不应弃之不顾.这种思想与我们日常处事的习惯符合 : 当我们面临 一个问题时, 除考虑当前的情况外, 往往还要注意以往的先例和经 验。</p>
<p>问题就来了: 如果这个工厂以往没有记录,或甚至是一个新开 工的工厂, 该怎么办? 怎样去获得上文所指的先验密度 <span class="arithmatex">\(h(\theta)\)</span> ? 贝 叶斯统计的一个基本要求是: 你必须设法去定出这样一个 <span class="arithmatex">\(h(\theta)\)</span>, 甚至出于你自己的主观认识 “也可以, 这要成为问题中一个必备 的要素. 正是在这一点上, 贝叶斯统计遭到不少的反对和批评, 而 一个初接触这个问题的人，也容易这样想: “这怎么行? 我没有根 据怎么能凭主观想像去定出一个先验密度 <span class="arithmatex">\(h(\theta)\)</span> ”. 关于这一点, 贝 叶斯学派的信奉者有自己的一套说法, 这问题非三言两语能说清 楚. 本书作者有一篇通俗形式的文章 (见《数理统计与应用概率》 1990 年第四期, p. 389-400), 其中对这个问题及有关问题作了仔 细说明, 有兴趣的读者可以参考.</p>
<p>现在我们转到下一个问题: 已定下了先验密度之后, 怎样去得 出参数 <span class="arithmatex">\(\theta\)</span> 的估计.</p>
<p>设总体有概率密度 <span class="arithmatex">\(f(X, \theta)\)</span> (或概率函数,若总体分布为离散 的), 从这总体抽样本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span>, 则这样本的密度为 <span class="arithmatex">\(f\left(X_{1}, \theta\right) \cdots f\)</span> <span class="arithmatex">\(\left(X_{n}, \theta\right)\)</span>. 它可视为在给定 <span class="arithmatex">\(\theta\)</span> 值时 <span class="arithmatex">\(\left(X_{1}, \cdots, X_{n}\right)\)</span> 的密度，根据第二章 (3.5) 式及该式下的一段说明, <span class="arithmatex">\(\left(\theta, X_{1}, \cdots, X_{n}\right)\)</span> 的联合密度为</p>
<div class="arithmatex">\[
h(\theta) f\left(X_{1}, \theta\right) \cdots f\left(X_{n}, \theta\right)
\]</div>
<p>由此,算出 <span class="arithmatex">\(\left(X_{1}, \cdots, X_{n}\right)\)</span> 的边缘密度为</p>
<div class="arithmatex">\[
p\left(X_{1}, \cdots, X_{n}\right)=\int h(\theta) f\left(X_{1}, \theta\right) \cdots f\left(X_{n}, \theta\right) \mathrm{d} \theta
\]</div>
<p>积分的范围, 要看参数 <span class="arithmatex">\(\theta\)</span> 的范围而定. 如上例 <span class="arithmatex">\(\theta\)</span> 为废品率, 则 <span class="arithmatex">\(0 \leqslant \theta\)</span> <span class="arithmatex">\(\leqslant 1\)</span>. 若 <span class="arithmatex">\(\theta\)</span> 为指数分布中的参数 <span class="arithmatex">\(\lambda\)</span>, 则 <span class="arithmatex">\(0&lt;\theta&lt;\infty\)</span>, 等等. 由(2.10), 再 根据第二章的公式 (3.4), 得到在给定 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 的条件下, <span class="arithmatex">\(\theta\)</span> 的 条件密度为</p>
<div class="arithmatex">\[
h\left(\theta \mid X_{1}, \cdots, X_{n}\right)=h(\theta) f\left(X_{1}, \theta\right) \cdots f\left(X_{n}, \theta\right) / p\left(X_{1}, \cdots, X_{n}\right)
\]</div>
<p>照贝叶斯学派的观点, 这个条件密度代表了我们现在 (即在取得样 本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 后) 对 <span class="arithmatex">\(\theta\)</span> 的知识, 它综合了 <span class="arithmatex">\(\theta\)</span> 的先验信息 (以 <span class="arithmatex">\(h(\theta)\)</span> 反 映) 与由样本带来的信息. 通常把 (2.11) 称为 <span class="arithmatex">\(\theta\)</span> 的 “后验 (或验后)</p>
<ul>
<li>就是说, 这里允许使用主观概率, 见第一章 1.1 节 密度”, 因为他是在做了试验以后才取得的.</li>
</ul>
<p>如果把上述过程和我们在第一章中讲过的贝叶斯公式相比, 就可以理解: 现在我们所做的, 可以说不过是把贝叶斯公式加以 “连续化”而已,看下表中的比较。</p>
<table>
<thead>
<tr>
<th style="text-align: center;"></th>
<th style="text-align: center;">问 题</th>
<th style="text-align: center;">先验知识</th>
<th style="text-align: center;">当前知识</th>
<th style="text-align: center;">后验 (现在) 知识</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align: center;">闪叶斯公式</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{array}{l}\text { 事 件 } B_{1}, \cdots, B_{n} \\ \text { 中那一个发生了? }\end{array}\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{array}{l}P\left(B_{1}\right), \\ \cdots, P\left(B_{n}\right)\end{array}\)</span></td>
<td style="text-align: center;">事件 <span class="arithmatex">\(A\)</span> 发生了</td>
<td style="text-align: center;"><span class="arithmatex">\(\begin{array}{l}P\left(B_{1} \mid A\right), \cdots, \\ P\left(B_{n} \mid A\right)\end{array}\)</span></td>
</tr>
<tr>
<td style="text-align: center;">此处的问题</td>
<td style="text-align: center;"><span class="arithmatex">\(\theta=?\)</span></td>
<td style="text-align: center;"><span class="arithmatex">\(h(\theta)\)</span></td>
<td style="text-align: center;">样本 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span></td>
<td style="text-align: center;">后猃密度 (2.11)</td>
</tr>
</tbody>
</table>
<p>由这里我们就理解到: 为什么一个看来不起眼的贝叶斯公式会有 如此大的影响. 这一点我们在第一章中已有所论述了.</p>
<p>贝叶斯学派的下一个重要观点是: 在得出后验分布 (2.11)后, 对参数 <span class="arithmatex">\(\theta\)</span> 的任何统计推断, 都只能基于这个后验分布. 至于具体 如何去使用它, 可以结合某种准则一起去进行, 统计学家也有一定 的自由度. 拿此处讨论的点估计问题来说, 一个常用的方法是: 取 后验分布 (2.11) 的均值作为 <span class="arithmatex">\(\theta\)</span> 的估计.</p>
<p>还有一点需要说明一下: 按上文, <span class="arithmatex">\(h(\theta)\)</span> 必须是一个密度函数, 即必须满足 <span class="arithmatex">\(h(\theta) \geqslant 0, \int h(\theta) \mathrm{d} \theta=1\)</span> 这两个条件. 但在有些情况 下, <span class="arithmatex">\(h(\theta) \geqslant 0\)</span>, 但 <span class="arithmatex">\(\int h(\theta) \mathrm{d} \theta\)</span> 不为 1 甚至为 <span class="arithmatex">\(\infty\)</span>, 不过积分 (2.10) 仍有 限, 这时, 由 (2.11) 定义的 <span class="arithmatex">\(h\left(\theta \mid X_{1}, \cdots, X_{n}\right)\)</span> 作为 <span class="arithmatex">\(\theta\)</span> 的函数, 仍满足 密度函数的条件. 这就是说, 即使这样的 <span class="arithmatex">\(h(\theta)\)</span> 取为先验密度也无 妨. 当然, 由于 <span class="arithmatex">\(\int h(\theta) \mathrm{d} \theta\)</span> 不为 1 , 它已失去了密度函数的通常的概 率意义. 这样的 <span class="arithmatex">\(h(\theta)\)</span> 通常称为“广义先验密度”。</p>
<p>例 2.13 作 <span class="arithmatex">\(n\)</span> 次独立试验, 每次观察某事件 <span class="arithmatex">\(A\)</span> 是否发生, <span class="arithmatex">\(A\)</span> 在每次试验中发生的概率为 <span class="arithmatex">\(p\)</span>, 要依据试验结果去估计 <span class="arithmatex">\(p\)</span>.</p>
<p>这问题我们以往就“用频率估计概率”的方法去处理 (这也是 它的矩估计与极大似然估计). 这方法不用 <span class="arithmatex">\(p\)</span> 的先验知识. 现在我 们用贝叶斯统计的观点来处理这个问题.</p>
<p>引进 <span class="arithmatex">\(X_{i}=1\)</span> 或 0 ,视第 <span class="arithmatex">\(i\)</span> 次试验时 <span class="arithmatex">\(A\)</span> 发生与否而定, <span class="arithmatex">\(i=1, \cdots\)</span>, <span class="arithmatex">\(n \cdot P\left(X_{i}=1\right)=p, P\left(X_{i}=0\right)=1-p\)</span>. 因此 <span class="arithmatex">\(\left(X_{1}, \cdots, X_{n}\right)\)</span> 的概率函 数为 <span class="arithmatex">\(p^{x}(1-p)^{n-x}, X=\sum_{i=1}^{n} X_{i}\)</span>. 取 <span class="arithmatex">\(p\)</span> 的先验密度 <span class="arithmatex">\(h(p)\)</span>, 则 <span class="arithmatex">\(p\)</span> 的 后验密度为</p>
<div class="arithmatex">\[
\begin{aligned}
&amp; h\left(p \mid X_{1}, \cdots, X_{n}\right) \\
= &amp; h(p) p^{x}(1-p)^{n-x} / \int_{0}^{1} h(p) p^{x}(1-P)^{n-x} \mathrm{~d} p, 0 \leqslant p \leqslant 1
\end{aligned}
\]</div>
<p>此分布的均值为</p>
<div class="arithmatex">\[
\begin{aligned}
\widetilde{p} &amp; =\widetilde{p}\left(X_{1}, \cdots, X_{n}\right)=\int_{0}^{1} p h\left(P \mid X_{1}, \cdots, X_{n}\right) \mathrm{d} p \\
&amp; =\int_{0}^{1} h(p) p^{x+1}(1-p)^{n-x} \mathrm{~d} p / \int_{0}^{1} h(p) p^{x}(1-p)^{n-x} \mathrm{~d} p
\end{aligned}
\]</div>
<p><span class="arithmatex">\(\tilde{p}\)</span> 就是 <span class="arithmatex">\(p\)</span> 在先验分布 <span class="arithmatex">\(h(p)\)</span> 之下的贝叶斯估计.</p>
<p>如何选择 <span class="arithmatex">\(h(p)\)</span> ? 贝叶斯本人曾提出“同等无知”的原则，即 事先认为 <span class="arithmatex">\(p\)</span> 取 <span class="arithmatex">\([0,1]\)</span> 内一切值都有同等可能, 就是说取 <span class="arithmatex">\([0,1]\)</span> 内均 匀分布 <span class="arithmatex">\(R(0,1)\)</span> 作为 <span class="arithmatex">\(p\)</span> 的先验分布. 这时 <span class="arithmatex">\(h(p)=1\)</span> 当 <span class="arithmatex">\(0 \leqslant p \leqslant 1\)</span>, 而 (2.12) 中的两个积分都可以用 <span class="arithmatex">\(\beta\)</span> 函数表出 (见第二章 (4.22) 式). 由此得</p>
<div class="arithmatex">\[
\tilde{p}=\beta(X+2, n-X+1) / \beta(X+1, n-X+1)
\]</div>
<p>根据 <span class="arithmatex">\(\beta\)</span> 函数与 <span class="arithmatex">\(\Gamma\)</span> 函数的关系式 <span class="arithmatex">\((4.25)\)</span>, 以及当 <span class="arithmatex">\(k\)</span> 为自然数时 <span class="arithmatex">\(\Gamma(k)=(k-1) !\)</span>, 由 <span class="arithmatex">\((2.13)\)</span> 不难得到</p>
<div class="arithmatex">\[
\widetilde{p}=(X+1) /(n+2)
\]</div>
<p>这个估计与频率 <span class="arithmatex">\(X / n\)</span> 有些差别, 当 <span class="arithmatex">\(n\)</span> 很大时不显著, 而在 <span class="arithmatex">\(n\)</span> 很小 时颇为显著.从一个角度看, 当 <span class="arithmatex">\(n\)</span> 相当小时, 用贝叶斯估计 (2.14) 比用 <span class="arithmatex">\(X / n\)</span> 更合理. 因为当 <span class="arithmatex">\(n\)</span> 很小时, 试验结果可能出现 <span class="arithmatex">\(X=0\)</span> 或 <span class="arithmatex">\(X=n\)</span> 的情况. 这时, 依 <span class="arithmatex">\(X / n\)</span> 应把 <span class="arithmatex">\(p\)</span> 估计为 0 或 1 , 这就太极端了 (我们不能仅根据在少数几次试验中 <span class="arithmatex">\(A\)</span> 会不出现或全出现, 就判 定它为不可能或必然). 若按 (2.14), 则在这两种情况下分别给出 估计值 <span class="arithmatex">\(1 /(n+2)\)</span> 和 <span class="arithmatex">\((n+1) /(n+2)\)</span>. 这就留有一定的余地.</p>
<p>这个“同等无知”的原则, 又称贝旪斯原则, 被广泛用到一些其 他的情况. 不过随着所估计的参数的范围和性质的不同, 该原则的 具体表现形式也不同.例如,为估计正态分布 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 中的 <span class="arithmatex">\(\mu\)</span>,同 等无知原则给出一个广义先验密度 <span class="arithmatex">\(h(\mu) \equiv 1\)</span>. 若估计 <span class="arithmatex">\(\sigma\)</span>, 则应取 <span class="arithmatex">\(h(\sigma)=\sigma^{-1}(\sigma&gt;0)\)</span>. 若估计指数分布中的 <span class="arithmatex">\(\lambda\)</span>, 则取 <span class="arithmatex">\(h(\lambda)=\lambda^{-1}(\lambda\)</span> <span class="arithmatex">\(&gt;0)\)</span>. 这些都是广义先验密度. 其所以这样做的理由, 不能在此处 细谈了.</p>
<p>这个原则也受到一些批评, 其中最有力的批评是其不确定性. 理由是: 拿本例的 <span class="arithmatex">\(p\)</span> 来说, 若对 <span class="arithmatex">\(p\)</span> 同等无知, 则对 <span class="arithmatex">\(p^{2}\)</span> (或 <span class="arithmatex">\(p^{3}, p^{4}, \cdots\)</span> 等)也应是同等无知, 因而也可以把 <span class="arithmatex">\(p^{2}\)</span> 的密度函数取为 <span class="arithmatex">\(R(0,1)\)</span> 的密度. 这时不难算出 <span class="arithmatex">\(p\)</span> 的密度将为 <span class="arithmatex">\(h(p)=2 p\)</span> (当 <span class="arithmatex">\(0 \leqslant p \leqslant 1\)</span>, 其 外为 0 ), 与本例所给不一致. 另外, 不言而喻, 同等无知的原则是 一个在确实没有什么信息时, 不得已而采用的办法. 在实际问题 中, 有时是存在更确实的信息的,如本段开始讲到的那个估计废品 率的情况. 又如,估计一个基本上均匀的铜板在投掷时出现正面的 概率 <span class="arithmatex">\(p\)</span>. 我们有理由事先肯定 <span class="arithmatex">\(p\)</span> 离 <span class="arithmatex">\(1 / 2\)</span> 不远. 这时, 可考虑取一个 适当的数 <span class="arithmatex">\(\varepsilon&gt;0\)</span>, 而把 <span class="arithmatex">\(p\)</span> 的先验分布取为 <span class="arithmatex">\([1 / 2-\varepsilon, 1 / 2+\varepsilon]\)</span> 内的均 匀分布. 这肯定比用同等无知的原则效果要好, 尤其是在试验次数 <span class="arithmatex">\(n\)</span> 不大时.</p>
<p>例 2.14 设 <span class="arithmatex">\(X_{1}, \cdots, X_{n}\)</span> 是自正态总体 <span class="arithmatex">\(N(\theta, 1)\)</span> 中抽出的样 本. 为估计 <span class="arithmatex">\(\theta\)</span>, 给出 <span class="arithmatex">\(\theta\)</span> 的先验分布为正态分布 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\left(\mu, \sigma^{2}\right.\)</span> 当然 都已知). 求 <span class="arithmatex">\(\theta\)</span> 的贝叶斯估计. 在本例中有</p>
<div class="arithmatex">\[
\begin{aligned}
h(\theta) &amp; =(\sqrt{2 \pi} \sigma)^{-1} \exp \left[-\frac{1}{2 \sigma^{2}}(\theta-\mu)^{2}\right] \\
f(x, \theta) &amp; =(\sqrt{2 \pi})^{-1} \exp \left[-\frac{1}{2}(x-\theta)^{2}\right] .
\end{aligned}
\]</div>
<p>故按公式 (2.11) 知, <span class="arithmatex">\(\theta\)</span> 的后验密度为</p>
<div class="arithmatex">\[
h\left(\theta \mid X_{1}, \cdots, X_{n}\right)=\exp \left[-\frac{1}{2 \sigma^{2}}(\theta-\mu)^{2}-\frac{1}{2} \sum_{i=1}^{n}\left(X_{i}-\theta\right)^{2}\right] / I
\]</div>
<p>其中 <span class="arithmatex">\(I\)</span> 是一个与 <span class="arithmatex">\(\theta\)</span> 无关而只与 <span class="arithmatex">\(\mu, \sigma, X_{1}, \cdots, X_{n}\)</span> 有关的数. 简单的 代数计算表明</p>
<div class="arithmatex">\[
-\frac{1}{2 \sigma^{2}}(\theta-\mu)^{2}-\frac{1}{2} \sum_{i=1}^{n}\left(X_{i}-\theta\right)^{2}=-\frac{1}{2 \eta^{2}}(\theta-t)^{2}+J
\]</div>
<p>其中</p>
<div class="arithmatex">\[
\begin{gathered}
t=\left(n \bar{X}+\mu / \sigma^{2}\right) /\left(n+1 / \sigma^{2}\right) \\
\eta^{2}=1 /\left(n+1 / \sigma^{2}\right)
\end{gathered}
\]</div>
<p>而 <span class="arithmatex">\(J\)</span> 与 <span class="arithmatex">\(\theta\)</span> 无关. 以(2.16)代人 <span class="arithmatex">\((2.15)\)</span>, 得</p>
<div class="arithmatex">\[
h\left(\theta \mid X_{1}, \cdots, X_{n}\right)=I_{1} \exp \left[-\frac{1}{2 \eta^{2}}(\theta-t)^{2}\right]
\]</div>
<p>这里 <span class="arithmatex">\(I_{1}=I e^{J}\)</span> 与 <span class="arithmatex">\(\theta\)</span> 无关. <span class="arithmatex">\(I_{1}\)</span> 不必直接算, 因为, <span class="arithmatex">\(h\left(\theta \mid X_{1}, \cdots, X_{n}\right)\)</span> 作 为 <span class="arithmatex">\(\theta\)</span> 的函数是一个概率密度函数, 它必须满足条件</p>
<div class="arithmatex">\[
\int_{-\infty}^{\infty} h\left(\theta \mid X_{1}, \cdots, X_{n}\right) \mathrm{d} \theta=1
\]</div>
<p>这就决定了 <span class="arithmatex">\(I_{1}=(\sqrt{2 \pi} \eta)^{-1}\)</span>. 因此, <span class="arithmatex">\(\theta\)</span> 的后验分布就是正态分布 <span class="arithmatex">\(N\left(t, \eta^{2}\right)\)</span>, 其均值 <span class="arithmatex">\(t\)</span> 就是 <span class="arithmatex">\(\theta\)</span> 的贝叶斯估计 <span class="arithmatex">\(\tilde{\theta}\)</span> :</p>
<div class="arithmatex">\[
\tilde{\theta}=t=\frac{n}{n+1 / \sigma^{2}} \bar{X}+\frac{1 / \sigma^{2}}{n+1 / \sigma^{2}} \mu
\]</div>
<p>把 <span class="arithmatex">\(\tilde{\theta}\)</span> 写成 (2.19)的形状很有意思. 设想两个极端情况: 一个是 只有样本信息而毫无先验信息, 这就是我们以前讨论的情况, 这时 用样本均值 <span class="arithmatex">\(\bar{X}\)</span> 去估计 <span class="arithmatex">\(\theta\)</span>. 另一个是只有先验信息 <span class="arithmatex">\(N\left(\mu, \sigma^{2}\right)\)</span> 而没有 样本. 这时, 我们只好用先验分布的均值 <span class="arithmatex">\(\mu\)</span> 作为 <span class="arithmatex">\(\theta\)</span> 的估计. 由 (2.19)式看出 : 当两种信息都存在时, <span class="arithmatex">\(\theta\)</span> 的估计为二者的折裔. 它 是上述两个极端情况下的估计 <span class="arithmatex">\(\bar{X}\)</span> 和 <span class="arithmatex">\(\mu\)</span> 的加权平均, 权之比为 <span class="arithmatex">\(n: 1\)</span> / <span class="arithmatex">\(\sigma^{2}\)</span>. 这个比值很合理: <span class="arithmatex">\(n\)</span> 为样本数目, <span class="arithmatex">\(n\)</span> 愈大, 样本信息愈多, <span class="arithmatex">\(\bar{X}\)</span> 的 权就该更大. 对 <span class="arithmatex">\(\mu\)</span> 而言, 其重要性则要看 <span class="arithmatex">\(\sigma^{2}\)</span> 的大小. <span class="arithmatex">\(\sigma^{2}\)</span> 愈大, 表示 先验信息愈不肯定 ( <span class="arithmatex">\(\theta\)</span> 在 <span class="arithmatex">\(\mu\)</span> 周围的散布很大). 反之, <span class="arithmatex">\(\sigma^{2}\)</span> 很小时, 仅 根据先验信息, 已有很大把握肯定 <span class="arithmatex">\(\theta\)</span> 在 <span class="arithmatex">\(\mu\)</span> 附近不远处. 因此, <span class="arithmatex">\(\mu\)</span> 的 权应与 <span class="arithmatex">\(\sigma^{2}\)</span> 成反比. 公式 (2.19)恰好体现了上述分析. 目前在国际统计界及应用统计工作者中, 贝叶斯学派已有很 大影响. 其原因在于它确实有一些别的方法所不具备的优点. 这些 在今后我们还将看到. 在我国, 贝叶斯方法也开始受到重视并得到 一些应用. 对把数理统计学方法作为一种工具的应用工作者来说, 对这个学派的方法有必要有一定的了解.</p>







  
    
  
  
    
  


  <aside class="md-source-file">
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="最后更新">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1-2.1-2M12.5 7v5.2l4 2.4-1 1L11 13V7h1.5M11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2v1.8Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 21, 2023</span>
  </span>

    
    
      
  <span class="md-source-file__fact">
    <span class="md-icon" title="创建日期">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3h-2Z"/></svg>
    </span>
    <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date">December 21, 2023</span>
  </span>

    
    
    
  </aside>


  



  <form class="md-feedback" name="feedback" hidden>
    <fieldset>
      <legend class="md-feedback__title">
        对当前页面有任何疑问吗？
      </legend>
      <div class="md-feedback__inner">
        <div class="md-feedback__list">
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page was helpful" data-md-value="1">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M5 9v12H1V9h4m4 12a2 2 0 0 1-2-2V9c0-.55.22-1.05.59-1.41L14.17 1l1.06 1.06c.27.27.44.64.44 1.05l-.03.32L14.69 8H21a2 2 0 0 1 2 2v2c0 .26-.05.5-.14.73l-3.02 7.05C19.54 20.5 18.83 21 18 21H9m0-2h9.03L21 12v-2h-8.79l1.13-5.32L9 9.03V19Z"/></svg>
            </button>
          
            <button class="md-feedback__icon md-icon" type="submit" title="This page could be improved" data-md-value="0">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 15V3h4v12h-4M15 3a2 2 0 0 1 2 2v10c0 .55-.22 1.05-.59 1.41L9.83 23l-1.06-1.06c-.27-.27-.44-.64-.44-1.06l.03-.31.95-4.57H3a2 2 0 0 1-2-2v-2c0-.26.05-.5.14-.73l3.02-7.05C4.46 3.5 5.17 3 6 3h9m0 2H5.97L3 12v2h8.78l-1.13 5.32L15 14.97V5Z"/></svg>
            </button>
          
        </div>
        <div class="md-feedback__note">
          
            <div data-md-value="1" hidden>
              
              
                
              
              感谢您的反馈！
            </div>
          
            <div data-md-value="0" hidden>
              
              
                
              
              感谢您的反馈！请点击这里<a href="https://github.com/EanYang7/Probability-and-Statistics/issues" target="_blank" rel="noopener">这里</a>提供问题反馈.
            </div>
          
        </div>
      </div>
    </fieldset>
  </form>


                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  回到页面顶部
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/EanYang7/cs231n" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.top", "navigation.tracking", "navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.path", "toc.follow", "content.action.edit", "content.action.view"], "search": "../../javascripts/workers/search.f886a092.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../javascripts/bundle.d7c377c4.min.js"></script>
      
        <script src="../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>